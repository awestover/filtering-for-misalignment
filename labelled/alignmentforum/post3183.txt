Notation note, [ ] are for lists, ( ) are for functions. Note that many of the words and symbols I am using are made up. When this maths is better understood, someone should reinvent the notation. My notation isn't that great, but its hard to make good notation when you are still working out what you want to describe. A theory (of my new type, not standard maths) T is formally defined to be, T = [ ψ , ρ , Ξ , t y p e , a r i t y ] Where ψ = { s 1 , s 2 , . . . } are the theories symbols. These can be arbitrary mathematical objects. Ξ = { Ξ 1 , Ξ 2 , . . . } is the set of types, also arbitrary. t y p e : ψ → Ξ is a function. a r i t y : ψ → ∪ ∞ i = 0 Ξ × Ξ × ⋯ × Ξ      i Is also a function. An expression E in a theory is defined recursively, it consists of a pair E = [ s , v 1 , v 2 , ⋯ , v n ] . Here s ∈ ψ and ∀ 1 ≤ i ≤ n : v i is an expression. Let a r i t y ( s ) = [ x 1 , x 2 , . . . x m ] Sometimes we will write t y p e ( E ) , what we really mean is t y p e ( s ) , and a r i t y ( E ) = a r i t y ( s ) We write s y m b o l ( E ) = s when we want to refer to  just s and ignore v 1 , . . . , v n Expressions have the restriction  that m = n the number of elements of Ξ that s is mapped to is the same as the number of  other expressions. We also insist that for all i , t y p e ( v i ) = x i The base case happens when a r i t y ( s ) = [ ] the empty list. All expressions are strictly finite mathematical objects. There are no self referential expressions. Expressions can be written s ( v 1 , . . . , v n ) We can define equality between expressions e = s ( v 1 , . . . ) and f = t ( w 1 , . . . ) recursively by saying e = f iff s y m b o l ( e ) = s y m b o l ( f ) and forall i : v i = w i The distinction between expressions e , f is defined recursively. e − f = [ e , f ] if s y m b o l ( e ) ≠ s y m b o l ( f ) e − f = [ e , f ] if ∃ i ≠ j ∈ N : v i ≠ w i a n d v j ≠ w j e − f = N o n e if e = f e − f = v i − w i if ∃ 1 i : v i ≠ w i These can be uniquely expressed as strings made up of Ξ ∪ { ′ ( ′ , ′ , ′ , ′ ) ′ } Lets define V ( n ) = V ( Ξ n ) to be  the set of all possible expressions of type Ξ n . A function f : V ( n 1 ) × . . . V ( n t ) → V ( m ) is called basic if it is constant, or it is the projection function ( so f ( e 1 , . . . e t ) = e k for fixed k ≤ t ) or f can be expressed as f ( e 1 , . . . e t ) = s ( v 1 , . . . v n ) where s is constant and each v i is a basic function of e 1 , . . . e t . Note you can cross as much extra junk into f as you like and ignore it. If f ( e 1 , e 2 ) is basic, so is g ( e 1 , e 3 , e 2 , e 4 ) = f ( e 1 , e 2 ) . Basic functions can be said to have t y p e ( f ) = Ξ m and a r i t y ( f ) = [ Ξ n 1 , . . . Ξ n t ] Basic functions can be defined in the style of f ( α , β ) = s 1 ( c 1 , α , s 2 ( α , β ) ) Finally, ρ = { [ f 1 , g 1 ] , [ f 2 , g 2 ] , ⋯ } where f i and g i are basic functions with the same domains and codomains. t y p e ( v i ) = t y p e ( w i ) We write x ( α ) ≡ y ( z ( α ) ) to mean that the pair of basic functions f ( α ) = x ( α ) and g ( α ) = y ( z ( α ) ) are matched in ρ . Ie [ f , g ] ∈ ρ where x , y , z ∈ ψ We express the concept that for expressions e , f that e − f = [ p , q ] and there exists [ f , g ] ∈ ρ and expressions v 1 , . . . v n such that p = f ( v 1 , . . . v n ) and q = g ( v 1 , . . . v n ) by saying e ≡ f . We express that ∃ e 1 , e 2 , . . . , e n such that ∀ i < n : e i ≡ e i + 1 and e 1 = e and e n = f as e ∼ f . (previous posts use ≡ for both concepts) Lets create a new theory, called T1, this is a very simple theory, it has only 1 constant, 2 functions and 2 substitution rules, with only a single type. a ( b ( α ) ) ≡ α b ( a ( α ) ) ≡ α With the only constant being 0.  This theory can be considered to be a weak theory of integers with only a +1 and -1 function. It has a connected component of its graph for each integer. Propositions are in the same graph if and only if they have the same c o u n t ( a ) − c o u n t ( b ) . Theorems look like a ( a ( a ( b ( b ( 0 ) ) ) ) ) ∼ b ( a ( a ( 0 ) ) ) . Now consider the theory T2 formed by the symbols f , g , h f ( f ( f ( g ( g ( α ) ) ) ) ≡ α f ( α ) ≡ h ( g ( α ) ) f ( h ( α ) ) ≡ h ( f ( α ) ) g ( h ( α ) ) ≡ h ( g ( α ) ) It turns out that this theory also has one connected component for each integer, but this time, propositions are in the same component if 2 × c o u n t ( f ) − 3 × c o u n t ( g ) + 5 × c o u n t ( h ) is the same. When S = ( ψ S , ρ S , Ξ S , t y p e S , a r i t y S ) is a theory and similarly for T. We can define the disjoint union, S ⊔ T to be the theory ( ψ S ⊔ ψ T , ρ S ⊔ ρ T , Ξ S ⊔ Ξ t , t y p e S ⊔ t y p e T , a r i t y S ⊔ a r i t y T ) Consider a function f : Ξ S → Ξ T and a function Q : ψ S → basic functions in T ,  such that t y p e ( Q ( s i ) ) = f ( t y p e ( s i ) ) and where a r i t y ( s i ) = [ X 1 , . . . X n ] means a r i t y ( Q ( s i ) ) = [ f ( Q ( s 1 ) ) , . . . f ( Q ( s n ) ) ] . These arity conditions mean that for any expression e = s ( v 1 , . . . v n ) i n S , we can define  an expression in T V T is the set of expressions in T . Call Q ∗ : V S → V T a transjection if  it meets the condition that Q ∗ ( e ) = Q ( s ) ( Q ∗ ( v 1 ) , . . . Q ∗ ( v n ) ) . For each Q meeting the above conditions, there exists exactly one transjection. We can now define a relation. We say S ≲ T iff there exists Q ∗ : V S → V T a transjection such that e ∼ f in S iff Q ∗ ( e ) ∼ Q ∗ ( f ) in T . Call such transjections projections. Say S ≈ T iff S ≲ T and T ≲ S . Theorem S ≲ T and T ≲ U implies S ≲ U . Proof There exists a Q : V S → V T and R : V T → V U projections. The composition of basic maps is basic, by the recursive definition. The composition of transjections is a transjection. So R ∘ Q is a transjection. For all e , f ∈ V S , then e ∼ f ⟺ Q ( e ) ∼ Q ( f ) ⟺ R ( Q ( e ) ) ∼ R ( Q ( f ) ) Hence R ∘ Q is a projection. Lemma S ≲ S Let Q be the identity. The identity map is a projection. Theorem Suppose S and T are theories, with Q : V S → V T and R : V T → V S transjections. Suppose that for all e = s ( v 1 , . . . , v n ) ∈ V S we know that R ( Q ( e ) ) ∼ e . And the same when we swap S with T . Call Q and R psudoinverses. If we also know that for all [ f ( v 1 , . . . v n ) , g ( v 1 , . . . v n ) ] ∈ ρ S a pair of basic functions, that for all v 1 , . . . v n we know Q ( f ( v 1 , . . . ) ) ∼ Q ( g ( v 1 , . . . ) ) . Say that Q is axiom preserving.  Again we know the same when S is swapped with T , IE that R is axiom preserving. Note that all these claims are potentially provable with a finite list of a ∼ b ∼ c . . . when the expressions contain the arbitrary constants v 1 , . . . v n . All the stuff above implies that S ≈ T . Proof Consider e ≡ f ∈ V S . We know that e − f = [ a , b ] . st there exists [ f , g ] ∈ ρ S and some v 1 , . . . such that f ( v 1 , . . . ) = a and g ( v 1 , . . . ) = b (or visa versa.) This tells us that Q ( a ) ∼ Q ( b ) If ∀ i : Q ( v i ) ∼ Q ( w i ) then Q ( s ( v 1 , . . . v n ) ) ∼ Q ( s ( w 1 , . . . w n ) ) .  True because Q ( s ) is a basic function, and they preserve similarity. Repeat this to find that Q ( e ) ∼ Q ( f ) . If e ∼ f then e = e 1 , f = e n and e i ≡ e i + 1 , so Q ( e i ) ∼ Q ( e i + 1 ) so Q ( e ) ∼ Q ( f ) . On the other hand, if Q ( e ) ∼ Q ( f ) then R ( Q ( e ) ) ∼ R ( Q ( f ) ) because the same reasoning also applies to R . For any e ′ , f ′ ∈ V T we know e ′ ∼ f ′ ⟹ R ( e ′ ) ∼ R ( f ′ ) . We know Q ( e ) , Q ( f ) ∈ V T . But S and T are psudoinverses, so e ∼ R ( Q ( e ) ) ∼ R ( Q ( f ) ) ∼ f hence e ∼ f ⟺ Q ( e ) ∼ Q ( f ) Therefore S ≲ T . Symmetrically, T ≲ S so S ≈ T Remember our theories T 1 and T 2 from earlier? The ones about a,b and f,g,h? We can now express the concept that they are basically the same. T 1 ≈ T 2 . We can prove this by giving basic functions for each symbol, that generates transjections, and by showing that they are psudoinverses and axiom preserving, we know they are projections and T 1 ≈ T 2 . Q : T 1 → T 2 Q ( 0 ) = 0 , Q ( a ( α ) ) = f ( f ( g ( Q ( α ) ) ) ) , Q ( b ( α ) ) = f ( g ( Q ( α ) ) ) . R : T 2 → T 1 R ( f ( α ) ) = a ( a ( R ( α ) ) ) , R ( g ( α ) ) = b ( b ( b ( R ( α ) ) ) ) , R ( h ( α ) ) = a ( a ( a ( a ( a ( R ( α ) ) ) ) ) ) , R ( 0 ) = 0 . For example, pick the symbol a . To show that Q and R are psudoinverses, we need to show that R ( Q ( a ( α ) ) ) ∼ a ( α ) . We know R ( Q ( a ( α ) ) ) = R ( f ( f ( g ( Q ( α ) ) ) ) ) = a ( a ( a ( a ( b ( b ( b ( R ( Q ( α ) ) ) ) ) ) ) ) ) ∼ a ( a ( a ( a ( b ( b ( b ( α ) ) ) ) ) ) ) ∼ a ( α ) . To prove these transjections to be psudoinverses, do this with all symbols in ψ S ⊔ ψ T . Finally we prove that Q is axiom preserving. We must show that Q ( a ( b ( α ) ) ) ∼ Q ( α ) and that Q ( b ( a ( α ) ) ) ∼ Q ( α ) . Q ( a ( b ( α ) ) ) = f ( f ( g ( f ( g ( Q ( α ) ) ) ) ) ) ≡ f ( f ( g ( h ( g ( g ( Q ( α ) ) ) ) ) ) ) ≡ f ( f ( h ( g ( g ( g ( Q ( α ) ) ) ) ) ) ) ≡ f ( f ( f ( g ( g ( Q ( α ) ) ) ) ) ) ≡ Q ( α ) Likewise Q ( a ( b ( α ) ) ) ∼ Q ( α ) . R is also axiom preserving. So T 1 ≈ T 2 . Conclusion We have formally defined a notion of a theory, and provided a criteria for telling when two theories are trivial distortions of each other. This will allow us notions of logical provability that aren't dependent on an arbitrary choice of formalism. By looking at all equivalent theories, weighted by simplicity, we can hope for a less arbitrary system of logical counterfactuals based on something thematically similar to proof length, although kind of more continuous with graduations of partly true.