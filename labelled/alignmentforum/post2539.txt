This post is a response to abramdemski's post, Kelly *is* (just) about logarithmic utility . any argument in favor of the Kelly formula has to go through an implication that your utility is logarithmic in money, at some point. If it seems not to, it's either: mistaken cleverly hiding the implication some mind-blowing argument I haven't seen before. Challenge accepted. This is essentially a version of time-averageing which gets rid of the infinity-problem. Consider the Kelly-betting game: Each round, you can bet any fraction of your wealth on a fair coinflip, which will be tripled if you win. You play this game for an infinite number of rounds. Your utility is linear in money. The first thing to note is that this game does not have expected utility maximization recommend betting everything each round. This is true for any finite version of the game, but this version has various infinite payoffs, or no well-defined payoffs at all, since it doesn't end. We will get around this by, instead of computing expectations for strategies and comparing them based on expectation size, comparing them directly. First, consider the formal specification of expected utility maximisation: s m a x = a r g m a x s ∈ S ( E ( U ( g a m e ( s ) ) ) for S the set of strategies. Or written slightly unconventionally: s m a x = a r g m a x s ∈ S ( lim n → ∞ 1 / n n ∑ i = 0 ( U ( g a m e ( s ; r ( i ) ) ) ) ) with r as a source of randomness. This spells out the expected value as the average of a sample of size going to infinity. We can turn this into a comparison between strategies: s 1 ≥ s 2 ⟺ lim n → ∞ [ 1 / n n ∑ i = 0 ( U ( g a m e ( s 1 ; r ( i ) ) ) ) ] ≥ lim m → ∞ [ 1 / m m ∑ j = 0 ( U ( g a m e ( s 2 ; r ( j ) ) ) ) ] with the idea of then picking the strategy that is maximal under this order. We then try to pull the comparison inside the limit: s 1 ≥ s 2 ⟺ lim n → ∞ [ 1 / n n ∑ i = 0 ( U ( g a m e ( s 1 ; r ( i ) ) ) ) ≥ 1 / n n ∑ j = 0 ( U ( g a m e ( s 2 ; r ( j ) ) ) ) ] but this doesn't quite work, because we have a truth value inside the limit. Replace that with a propability (and dropping the normalizers, since they dont matter): s 1 ≥ s 2 ⟺ lim n → ∞ [ P [ n ∑ i = 0 ( U ( g a m e ( s 1 ; r ( i ) ) ) ) ≥ n ∑ j = 0 ( U ( g a m e ( s 2 ; r ( j ) ) ) ) ] ] > 0 and for the games where classic utility maximization was well-defined this should give the same results. Now we can properly define our infinite game: g a m e ( s ; r ) gets a third parameter indicating the number of rounds played: g a m e ( s , r , t ) stands for playing the kelly-game for t rounds instead of infinitely long. The full game is then the limit of this. Then I define the criterion for limiting games of this type as: s 1 ≥ s 2 ⟺ lim n → ∞ lim t → ∞ [ P [ n ∑ i = 0 ( U ( g a m e ( s 1 ; r ( i ) ; t ) ) ) ≥ n ∑ j = 0 ( U ( g a m e ( s 2 ; r ( j ) ; t ) ) ) ] ] > 0 which we can easily see reproduces Kelly-behaviour: For any n for any d as t goes to infinity the odds that any of the bettors in the sample has a percentage of heads so far that differs form 50% by more than d go to 0, so whichever strategy does better when it gets exactly 50% heads will have higher payoff at t = ∞ , and since this is true for any n it's also true as n goes to infinity. This is precisely the Kelly-strategy. Does it make sense to look at a game with infinitely many rounds? Perhaps not. You could also say that the game has a 1% chance of ending each round: Then it would end in finitely many rounds with propability one. I can't solve this analytically, but I think it would end up looking very close to Kelly behaviour. Notice that if the order of the n- and t-limits is switched, we get the all-in strategy. This is how I think the intuition that utility maximization implies all-in is generated, and this switch is why I put it into the "ergodic" category. Either version would give results consistent with expected utility maximization for games which are finite (encoded as ∃ t 1 ∀ t > t 1 ∀ s ∀ r [ g a m e ( s ; r ; t ) = g a m e ( s ; r ; t 1 ) ] ).