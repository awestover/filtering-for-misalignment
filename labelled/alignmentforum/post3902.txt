We define a new class of reductions which preserve optimal predictor schemes, generalizing the previous notion of pseudo-invertible reductions. These are reductions that preserve the estimation problem on average but allow for large variance. Definition 1 Fix an error space Δ of rank 2. Consider ( f , μ ) , ( g , ν ) distributional estimation problems, ^ ζ = ( ζ , r ζ , a ζ ) a { 0 , 1 } ∗ -valued ( p o l y , l o g ) -bischeme. ^ ζ is called a Δ -pseudo-invertible weak reduction of ( f , μ ) to ( g , ν ) when there is a polynomial p : N → N s.t. the following conditions hold: (i) E μ k [ ( E U r ζ ( k , j ) [ g ( ^ ζ k j ( x ) ) ] − f ( x ) ) 2 ] ∈ Δ (ii) P r μ k × U r ζ ( k , j ) [ ν p ( k ) ( ^ ζ k j ( x ) ) = 0 ] ∈ Δ (iii) There is M > 0 and ^ R = ( R , r R , a R ) a Q ∩ [ 0 , M ] -valued ( p o l y , l o g ) -bischeme s.t. E ν p ( k ) × U r R ( k , j ) [ ( ^ R k j ( y ) − P r μ k × U r ζ ( k , j ) [ ^ ζ k j ( x ) = y ] ν p ( k ) ( y ) ) 2 ] ∈ Δ (iv) There is a { 0 , 1 } ∗ -valued ( p o l y , l o g ) -scheme ^ ξ = ( ξ , r ξ , a ξ ) s.t. E μ k × U r ζ ( k , j ) [ ∑ x ′ ∈ { 0 , 1 } ∗ | P r U r ξ ( k , j ) [ ^ ξ k j ( ^ ζ k j ( x , z ) , w ) = x ′ ] − P r μ k × U r ζ ( k , j ) [ x ′′ = x ′ ∣ ^ ζ k j ( x ′′ , z ′ ) = ^ ζ k j ( x , z ) ] | ] ∈ Δ Such ^ ξ is called a Δ -pseudo-inverse of ^ ζ . ^ ζ = ( ζ , r ζ , a ζ ) a { 0 , 1 } ∗ -valued ( p o l y , l o g ) -scheme is called a Δ -pseudo-invertible weak reduction of ( f , μ ) to ( g , ν ) when it becomes such when adding trivial dependence on j . Definition 2 An error space Δ of rank 2 is called stable when for any non-constant polynomial p : N → N and δ ∈ Δ , the function δ ′ ( k , j ) : = δ ( p ( k ) , j ) is in Δ . Theorem Fix Δ a stable error space of rank 2. Suppose there is a polynomial h : N 2 → N s.t. h − 1 ∈ Δ . Consider ( f , μ ) , ( g , ν ) distributional estimation problems, ^ ζ a Δ -pseudo-invertible weak reduction of ( f , μ ) to ( g , ν ) and ^ P g a Δ ( p o l y , l o g ) -optimal predictor scheme for ( g , ν ) . Define ^ P f by ^ P k j f ( x , y 1 y 2 … y h ( k , j ) z 1 z 2 … z h ( k , j ) ) : = 1 h ( k , j ) h ( k , j ) ∑ i = 1 ^ P p ( k ) , j g ( ^ ζ k j ( x , y i ) , z i ) Here, we assume the lengths of the y i and z i are compatible with ^ ζ and ^ P g respectively. Then, ^ P f is a Δ ( p o l y , l o g ) -optimal predictor scheme for ( f , μ ) . Proposition 1 Consider ( f , μ ) , ( g , ν ) distributional estimation problems. Suppose ^ ζ = ( ζ , r ζ , a ζ ) is a weak Δ -pseudo-invertible reduction of ( f , μ ) to ( g , ν ) and ^ ξ = ( ξ , r ξ , a ξ ) is it's Δ -pseudo-inverse. Then there is δ ∈ Δ s.t. for any bounded function h : { 0 , 1 } ∗ 2 → R | E μ k × U r ζ ( k , j ) × U r ξ ( k , j ) [ h ( ^ ξ k j ( ^ ζ k j ( x , z ) , w ) , ^ ζ k j ( x , z ) ) ] − E μ k × U r ζ ( k , j ) [ h ( x , ^ ζ k j ( x , z ) ) ] | ≤ ( sup | h | ) δ ( k , j ) Proposition 1 proved exactly as Proposition 2 for unidistributional estimation problems . Proposition 2 Consider X a finite set, μ a probability measure on X , h : X → R and s , t ∈ R . Then E μ [ ( h ( x ) − s ) 2 − ( h ( x ) − t ) 2 ] = ( E μ [ h ( x ) ] − s ) 2 − ( E μ [ h ( x ) ] − t ) 2 Proof of Proposition 2 E μ [ ( h ( x ) − s ) 2 ] = E μ [ h ( x ) 2 ] − 2 E μ [ h ( x ) ] s + s 2 E μ [ ( h ( x ) − t ) 2 ] = E μ [ h ( x ) 2 ] − 2 E μ [ h ( x ) ] t + t 2 E μ [ ( h ( x ) − s ) 2 − ( h ( x ) − t ) 2 ] = 2 E μ [ h ( x ) ] ( t − s ) + s 2 − t 2 ( E μ [ h ( x ) ] − s ) 2 = E μ [ h ( x ) ] 2 − 2 E μ [ h ( x ) ] s + s 2 ( E μ [ h ( x ) ] − t ) 2 = E μ [ h ( x ) ] 2 − 2 E μ [ h ( x ) ] t + t 2 ( E μ [ h ( x ) ] − s ) 2 − ( E μ [ h ( x ) ] − t ) 2 = 2 E μ [ h ( x ) ] ( t − s ) + s 2 − t 2 Proof of Theorem Consider ^ Q f = ( Q f , s f , b f ) a ( p o l y , l o g ) -predictor scheme. Let ^ Q g = ( Q g , s g , b g ) be the ( p o l y , l o g ) -predictor scheme defined by ^ Q k j g ( x , y 1 y 2 y 3 y 4 ) : = ^ P k j g ( x , y 1 ) + ^ Q k j f ( ^ ξ k j ( x , y 2 ) , y 3 ) − ^ P k j f ( ^ ξ k j ( x , y 2 ) , y 4 ) We have E ν p ( k ) × U r R ( k , j ) × U r g ( p ( k ) , j ) [ ^ R k j ( y ) ( ^ P p ( k ) , j g ( y ) − g ( y ) ) 2 ] ≤ E ν p ( k ) × U r R ( k , j ) × U s g ( p ( k ) , j ) [ ^ R k j ( y ) ( ^ Q p ( k ) , j g ( y ) − g ( y ) ) 2 ] + δ 0 ( p ( k ) , j ) where δ 0 ∈ Δ . Applying the definitive property of ^ R to the left hand side we get E ν p ( k ) × U r R ( k , j ) × U r g ( p ( k ) , j ) [ ^ R k j ( y ) ( ^ P p ( k ) , j g ( y ) − g ( y ) ) 2 ] = E ν p ( k ) × U r g ( p ( k ) , j ) [ P r μ k × U r ζ ( k , j ) [ ^ ζ k j ( x ) = y ] ν p ( k ) ( y ) ( ^ P p ( k ) , j g ( y ) − g ( y ) ) 2 ] + γ R ( k , j ) where | γ R | ∈ Δ . Using property (ii) of pseudo-invertible reductions, we get E ν p ( k ) × U r R ( k , j ) × U r g ( p ( k ) , j ) [ ^ R k j ( y ) ( ^ P p ( k ) , j g ( y ) − g ( y ) ) 2 ] = E μ k × U r g ( p ( k ) , j ) × U r ζ ( k , j ) [ ( ^ P p ( k ) , j g ( ^ ζ k j ( x ) ) − g ( ^ ζ k j ( x ) ) ) 2 ] + γ R ( k , j ) Using the definitive property of ^ R and property (ii) of pseudo-invertible reductions on the right-hand side, we get E [ ^ R k j ( y ) ( ^ Q k j g ( y ) − g ( y ) ) 2 ] = E [ ( ^ P p ( k ) , j g ( ^ ζ k j ( x ) ) + ^ Q k j f ( ^ ξ k j ( ^ ζ k j ( x ) ) ) − ^ P k j f ( ^ ξ k j ( ^ ζ k j ( x ) ) ) − g ( ^ ζ k j ( x ) ) ) 2 ] + γ ′ R ( k , j ) where | γ ′ R | ∈ Δ . Applying Proposition 1 E [ ^ R k j ( y ) ( ^ Q k j g ( y ) − g ( y ) ) 2 ] = E [ ( ^ P p ( k ) , j g ( ^ ζ k j ( x ) ) + ^ Q k j f ( x ) − ^ P k j f ( x ) − g ( ^ ζ k j ( x ) ) ) 2 ] + γ ξ ( k , j ) + γ ′ R ( k , j ) where | γ ξ | ∈ Δ . Applying the stability of Δ to δ 0 and putting everything together E [ ( ^ P p ( k ) , j g ( ^ ζ k j ( x ) ) − g ( ^ ζ k j ( x ) ) ) 2 ] ≤ E [ ( ^ P p ( k ) , j g ( ^ ζ k j ( x ) ) + ^ Q k j f ( x ) − ^ P k j f ( x ) − g ( ^ ζ k j ( x ) ) ) 2 ] + δ 1 ( k , j ) for δ 1 ∈ Δ . Applying Proposition 2 E μ k [ E [ ^ P p ( k ) , j g ( ^ ζ k j ( x ) ) − g ( ^ ζ k j ( x ) ) ] 2 ] ≤ E μ k × U s f ( k , j ) + r f ( k , j ) [ ( E [ ^ P p ( k ) , j g ( ^ ζ k j ( x ) ) − g ( ^ ζ k j ( x ) ) ] + ^ Q k j f ( x ) − ^ P k j f ( x ) ) 2 ] + δ 1 ( k , j ) Applying property (i) of pseudo-invertible reductions E μ k [ ( E [ ^ P p ( k ) , j g ( ^ ζ k j ( x ) ) ] − f ( x ) ) 2 ] ≤ E μ k × U s f ( k , j ) + r f ( k , j ) [ ( E [ ^ P p ( k ) , j g ( ^ ζ k j ( x ) ) ] − f ( x ) + ^ Q k j f ( x ) − ^ P k j f ( x ) ) 2 ] + δ 2 ( k , j ) for δ 2 ∈ Δ . Using the definition of ^ P f we get E [ ( ^ P k j f ( x ) − f ( x ) ) 2 ] ≤ E [ ( ^ P k j f ( x ) − f ( x ) + ^ Q k j f ( x ) − ^ P k j f ( x ) ) 2 ] + δ 3 ( k , j ) for δ 3 ∈ Δ . Finally we get E [ ( ^ P k j f ( x ) − f ( x ) ) 2 ] ≤ E [ ( ^ Q k j f ( x ) − f ( x ) ) 2 ] + δ 3 ( k , j )