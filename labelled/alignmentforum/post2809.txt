EDIT : Added a section on Euler's conjecture. The Goldbach conjecture is likely The Goldbach conjecture is that "every even integer above two is the sum of two primes". For example, 4 = 2 + 2 , 6 = 3 + 3 , 8 = 5 + 3 , and so on. Though this is a mathematically precise statement, we can talk about the "probability" of it begin correct. How so? Well, by the prime number theorem , the probability of a random number less than N being prime, is 1 / log ( N ) . So if we sum up all the primes less than N , we get ( N / log ( N ) ) 2 different sums; these sums will be less than 2 N . So, is N itself is one of these sums? Well, the "probability" that it's not the total of any given sum is 1 − 1 2 N ; therefore the probability of it being the total of none of the sums is: ( 1 − 1 2 N ) ( N / log ( N ) ) 2 = ( ( 1 − 1 2 N ) 2 N ) N / ( 2 log ( N ) 2 ) ≈ ( 1 / e ) N / ( 2 log ( N ) 2 ) . So the probability of N being the total of such a sum is roughly: 1 − e − N / ( 2 log ( N ) 2 ) . Therefore, the probability of all numbers N being the total of such a sum is roughly: p 2 = ∞ ∏ N = 2 1 − e − N / ( 2 log ( N ) 2 ) . Now, the infinite product p 2 converges to a non-zero number if and only if the sum ∑ ∞ N = 1 e − N / ( 2 log ( N ) 2 ) converges to a finite number. That series can be seen to be convergent (for example, by noting that e − N / ( 2 log ( N ) 2 ) < 1 / N 2 for large enough N and using the comparison test ). If use computers to get an estimate of p 2 , we get a pretty low probability. However, most of that improbability mass is on the low numbers, and the Goldbach conjecture has been tested up to 4 × 10 18 . So, if we assume it's valid up to 1000 , we numerically get: p 1000 = ∞ ∏ N = 1000 1 − e − N / ( 2 log ( N ) 2 ) ≈ 0.9961. So the Goldbach conjecture is pretty likely, and, the more examples we discover where it holds, the more likely it is to hold all the way to infinity. "Probabilities" of logical facts The above reasoning seems dubious. The primes are not defined by random sampling among the natural numbers; quite to the contrary, they come from a mathematical rule of extreme precision. So what do these probabilities mean? Let X be an infinite set of numbers, selected from the natural numbers in a way that looks like the prime number theorem (eg the n -th number is approximately n log ( n ) ). Then what we've shown is that, if such an X obeys the " X -Goldbach conjecture" up to 1000 , then we'd expect it to go all the way to infinity. Thus the Goldbach conjecture can be restated as "in terms of sums of two elements, the prime numbers behave like a typical sequence selected in a prime-number-theorem way". So the Goldbach conjecture is not saying that there is something special about the primes; in fact, it's saying the opposite, that the primes are typical of similar sequences, that nothing in the specific ways that the primes are selected has an impact on the sum of two primes. So the Goldbach conjecture is essentially saying "there is no obstruction to the primes being typical in this way". One obstruction Did you notice that, so far, at no point did I require N to be an even number? But all the primes except for 2 are odd. So the distribution of sums of primes is very (very!) heavily skewed towards even numbers; most odd numbers will not appear at all. So, that is one clear obstruction to the possible values of the sum, coming from the way the primes are constructed. The Goldbach conjecture is therefore saying that there are no additional obstructions beyond this one condition on parity. In fact, the Goldbach conjecture has changed; 1 used to be seen as a prime number, and the original conjecture included 2 = 1 + 1 as another example Then 1 was removed from the list of prime numbers, and it turned out, as far as we can tell, that 2 was the only even number we lost from the list of sums. If we removed 2 from the list of primes, we'd only lose 4 = 2 + 2 as a sum. Similarly, if we strike out the first m primes, we expect - on probabilistic grounds - that "all numbers greater than a given n are the sums of two primes (first m primes not included)". If that were to fail, then there's a really interesting obstruction out there. Fermat's last theorem was likely (for n > 3 ) We can show, similarly, that Fermat's last theorem was very likely on probabilistic grounds. The theorem states that, for n > 2 , there do not exist natural numbers x , y , z > 0 such that x n + y n = z n . Fix z and n > 3 . Counting 1 and z , there are z natural numbers less than or equal to z . Therefore there are z 2 possible x n + y n , all less than 2 z n . So the probability that any two of these n -th powers sum to z n is z 2 / ( 2 z n ) = 1 / ( 2 z n − 2 ) . So the probability that there are no z 's such that z n = x n + y n , is p 2 , n = ∞ ∏ z = 2 1 − 1 / ( 2 z n − 2 ) . The sum ∑ ∞ z = 2 ( 1 / 2 ) ⋅ 1 / ( z n − 2 ) converges. Moreover, we can also sum over n : ∑ ∞ z = 2 , n = 4 ( 1 / 2 ) ⋅ 1 / ( z n − 2 ) = ∑ ∞ z = 2 ( 1 / 2 ) ⋅ z − 2 1 1 − 1 / z . This also converges. So the probability of Fermat's last theorem was non-zero, at least for n > 3 ; add on the fact that the theorem was proved for many n and checked for many x , y , and z , means that, even before it was proved, it was very probable it was correct. So Andrew Wiles's genius was in showing there were no unexpected obstructions for the "likely" outcome to be true. That's why the proof is so hard: he was trying to prove something very "likely", and show an absence of structure, rather than a presence, without knowing what that structure could be. Euler's conjecture was unlikely Euler's conjecture was that you needed to sum at least n powers of n to get another power of n ; Fermat's last theorem establishes this for n = 3 , and Euler theorised that this extended. Euler's theorem is in fact false; for n = 4 we have three fourth powers that sum to another fourth power as: 95800 4 + 217519 4 + 414560 4 = 422481 4 . There are counterexamples known for n = 5 as well, so the conjecture is false, and not just for one value of n . More interesting from our perspective, we expect it to be false on probabilistic grounds. Recall that the argument about Fermat's last theorem does not work for n = 3 ; it fails because the crucial sum is of the type 1 + 1 / 2 + 1 / 3 + 1 / 4 + … , which diverges. Similarly, if we estimate the probability of Euler's conjecture, we get terms like the following (for some constants C n ): p 2 , n = ∞ ∏ z = 2 1 − C n / ( z n − ( n − 1 ) ) = p 2 , n = ∞ ∏ z = 2 1 − C n / z . This goes to zero for the same reason as the n = 3 case. So, on probabilistic grounds, we expect Fermat's last theorem to be true for n ≥ 4 , and we expect Euler's conjecture to be false. The only unexpected result here is that Fermat's last theorem and Euler's conjecture are true for n = 3 . So something about the structure of the problem for n = 3 is moving the result away from the probabilistic outcome. The "Stuart conjecture" Based on what I wrote about Euler's conjecture, I'll hazard a conjecture myself, which I believe to be true on probabilistic grounds. Namely that if there are k integers, whose n -th powers sum non-trivially to another n -th power, then k is greater than or equal to n / 2 . Fermat's last theorem shows this is true for 1 , 2 , 3 , 4 , 5 , and 6 .