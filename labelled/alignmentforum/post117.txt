Introduction Recently, the Computational No-Coincidende Conjecture [1] was proposed, presented as an assumption that might be needed to develop methods to explain neural nets in the current approach from the Alignment Research Center . In this post, I will prove that some plausible extra assumption can be used to amplify the conjecture, showing it implies an arbitrarily stronger version of itself. In a slightly weakened version, the conjecture reads: (weak) Computational no-coincidence conjecture: For a reversible circuit C : { 0 , 1 } 3 n → { 0 , 1 } 3 n , let P ( C ) be the property that there is no input x to C that ends in n zeros, such that C ( x ) also ends in n zeros. There exists a polynomial-time verification algorithm V that receives as input: A reversible circuit C : { 0 , 1 } 3 n → { 0 , 1 } 3 n An advice string π such that: For all C such that P ( C ) is true, there exists π with length polynomial in the size of C , such that V ( C , π ) = 1 . For 99% of random reversible circuits C for which P(C) is false , no such π exists. The original conjecture omits "for which P ( C ) is false". As such π always exists when P ( C ) is true, the original conjecture implies this weak version. With an additional assumption, I will show that this (weak) conjecture implies a stronger version of itself, in which the "99%" can be replaced by " 1 − ϵ " for an arbitrarily small ϵ > 0 . This entails the original conjecture can also be strengthened. The strategy will be to define a new problem in NP using the conjecture. This problem is to decide whether a reversible circuit is in the set containing all circuits satisfying the property P plus a fraction of those falsifying it. If that fraction is smaller than 1%, we will have an stronger weak conjecture with a probability bound higher than "99%". Iterating this amplification step, that bound will be replaced by " 1 − ϵ ", arbitrarily close to one [2] . To achieve that, we will employ an extra assumption. Then we will apply the results to the original conjecture and discuss how reasonable the extra premise is. The Amplification Step Let C be the set of all reversible circuits and let P ⊊ C denote the set of circuits C such that P ( C ) is true. As the authors note, deciding P [3] is coNP-hard, and thus, coNP-complete [4] , implying ¯ ¯¯ ¯ P (the complement of P relative to C ) is NP-complete. We assume the (weak) conjecture is true, so there is a polynomial-time verifier V 0 such that: for all C ∈ P , there is a polynomial-sized π with V 0 ( C , π ) = 1 ;  and for 99% of random circuits C ∈ ¯ ¯¯ ¯ P , no such π exists. Let V 0 [5] denote also the set of circuits C (a property) such that there is a π yielding V 0 ( C , π ) = 1 . By definition, V 0 is in NP, implying ¯ ¯¯¯ ¯ V 0 is in coNP. Note that ¯ ¯¯¯ ¯ V 0 ⊆ ¯ ¯¯ ¯ P . Define the set V ′ 0 = V 0 ∩ ¯ ¯¯ ¯ P . That is, V ′ 0 contains the circuits C ∈ C such that P ( C ) does not hold and there is a π with V 0 ( C , π ) = 1 . Since both ¯ ¯¯ ¯ P and V 0 are in NP, so is V ′ 0 , and ¯ ¯¯¯¯ ¯ V ′ 0 is in coNP. Note that V ′ 0 ⊊ ¯ ¯¯ ¯ P , and the conjecture implies P r o b ( V 0 ( C ) | ¯ ¯¯ ¯ P ( C ) ) = P r o b ( V ′ 0 ( C ) | ¯ ¯¯ ¯ P ( C ) ) ≤ 10 − 2 , for a random C ∈ C [6] . As V ′ 0 is in NP, it can be reduced in polynomial time to ¯ ¯¯ ¯ P , which is NP-complete. Formally, there is a polynomial-time algorithm f 0 (a many-one reduction) such that C ∈ V ′ 0 iff f 0 ( C ) ∈ ¯ ¯¯ ¯ P . Given such a reduction f 0 , define the set V f 0 0 = { C ∈ C ∣ f 0 ( C ) ∈ V 0 } . For any C ∈ ¯ ¯¯¯¯ ¯ V ′ 0 , f 0 ( C ) ∈ P and, by the conjecture, there is a polynomial-sized π yielding V 0 ( f 0 ( C ) , π ) = 1 , and thus f 0 ( C ) ∈ V 0 . Therefore, C ∈ ¯ ¯¯¯¯ ¯ V ′ 0 implies C ∈ V f 0 0 .  Note that V f 0 0 is in NP by definition, as we can define a polynomial verification algorithm V f 0 0 ( C , π ) = V 0 ( f 0 ( C ) , π ) such that C ∈ V f 0 0 iff there is a (polynomial-sized) π yielding V f 0 0 ( C , π ) = 1 . Also note that ¯ ¯¯¯¯¯¯¯ ¯ V f 0 0 ⊆ V ′ 0 . Since V 0 and V f 0 0 are in NP, so is V 1 = V 0 ∩ V f 0 0 (the problem we are interested in). This implies there is a polynomial-time verifier V 1 ( ⋅ , ⋅ ) such that for any circuit C ∈ V 1 , there is a polynomial-sized π yielding V 1 ( C , π ) = 1 . In particular, for all C satisfying P , since P ⊆ V 1 , and all C ∈ V 1 ∩ ¯ ¯¯ ¯ P , there is such a π . Now define the set of circuits V ′ 1 = V 1 ∩ ¯ ¯¯ ¯ P = V ′ 0 ∩ V f 0 0 . As V 1 and ¯ ¯¯ ¯ P are in NP, so is V ′ 1 . The set V ′ 1 contains all circuits falsifying P that exhibit a special structure of those circuits satisfying P (there is a π with V 1 ( C , π ) = 1 ). As V ′ 1 ⊆ V ′ 0 , P r o b ( V 1 ( C ) | ¯ ¯¯ ¯ P ( C ) ) = P r o b ( V ′ 1 ( C ) | ¯ ¯¯ ¯ P ( C ) ) is not higher than P r o b ( V ′ 0 ( C ) | ¯ ¯¯ ¯ P ( C ) ) , and V 1 ( ⋅ , ⋅ ) is a polynomial-time verifier satisfying both conditions in the weak conjecture. For V 1 ( ⋅ , ⋅ ) to satisfy a stronger version of the conjecture, with P r o b ( V ′ 1 ( C ) | ¯ ¯¯ ¯ P ( C ) ) < P r o b ( V ′ 0 ( C ) | ¯ ¯¯ ¯ P ( C ) ) ≤ 10 − 2 , we need some extra assumption. The Extra Assumption Since V ′ 1 = V 1 ∩ ¯ ¯¯ ¯ P ⊆ V ′ 0 ⊆ ¯ ¯¯ ¯ P , it follows that, for a random C ∈ C , P r o b ( V ′ 1 ( C ) ∣ ¯ ¯¯ ¯ P ( C ) ) = P r o b ( V ′ 1 ( C ) ∣ V ′ 0 ( C ) ) P r o b ( V ′ 0 ( C ) ∣ ¯ ¯¯ ¯ P ( C ) ) . So we just need an assumption yielding P r o b ( C ∈ V ′ 1 | C ∈ V ′ 0 ) = P r o b ( f 0 ( C ) ∈ V ′ 0 ∣ C ∈ V ′ 0 ) < 1 in order for the polynomial verifier V 1 to satisfy a stronger version of the weak conjecture. Recall that C ∈ V ′ 0 iff f 0 ( C ) ∈ ¯ ¯¯ ¯ P , and note that P r o b ( C ∈ V 1 | C ∈ V ′ 0 ) is equal to P r o b ( f 0 ( C ) ∈ V 0 | C ∈ V ′ 0 ) = P r o b ( f 0 ( C ) ∈ V ′ 0 | C ∈ V ′ 0 ) . Thus we need an assumption entailing P r o b ( f 0 ( C ) ∈ V ′ 0 ∣ f 0 ( C ) ∈ ¯ ¯¯ ¯ P ) < 1 , or, equivalently, P r o b ( f 0 ( C ) ∈ ¯ ¯¯¯¯ ¯ V ′ 0 ∣ f 0 ( C ) ∈ ¯ ¯¯ ¯ P ) > 0 . This inequality says that, given a random reversible circuit C for which P ( f 0 ( C ) ) is false, f 0 ( C ) has non-zero probability of being in ¯ ¯¯¯ ¯ V 0 (not having a π such that V 0 ( f 0 ( C ) , π ) = 1 ). For a random C falsifying P , the conjecture implies P r o b ( C ∈ ¯ ¯¯¯¯ ¯ V ′ 0 ∣ C ∈ ¯ ¯¯ ¯ P ) ≥ 99 %,  thus we might wonder whether this probability bound is robust to applying a reduction to C . Nonetheless, by employing an arbitrary number of iterations of the amplification step, as we will show, we can achieve the desired strengthening of the conjecture with a much weaker premise [7] : Reduction-Regularity: [8] There is a δ ∈ ( 0 , 1 ) such that , given any NP problem L ⊊ ¯ ¯¯ ¯ P with P r o b ( C ∈ ¯ ¯¯ ¯ L ∣ C ∈ ¯ ¯¯ ¯ P ) ≥ 99 % for a random C ∈ C , there is a polynomial-time reduction f ( . ) from L to ¯ ¯¯ ¯ P yielding P r o b ( f ( C ) ∈ ¯ ¯¯ ¯ L ∣ f ( C ) ∈ ¯ ¯¯ ¯ P ) ≥ δ for a random C . While the (weak) conjecture implies P r o b ( V ′ 0 ( C ) | ¯ ¯¯ ¯ P ( C ) ) ≤ 10 − 2 , for a random C ∈ C , assuming also the premise above (with L = V ′ 0 ) implies there is a reduction f 0 such that P r o b ( V ′ 1 ( C ) | V ′ 0 ( C ) ) ≤ 1 − δ .  Consequently, we obtain P r o b ( V ′ 1 ( C ) | ¯ ¯¯ ¯ P ( C ) ) = P r o b ( V ′ 1 ( C ) | V ′ 0 ( C ) ) P r o b ( V ′ 0 ( C ) | ¯ ¯¯ ¯ P ( C ) ) ≤ 10 − 2 ( 1 − δ ) . This seems a small gain, as δ can be close to zero, but it is sufficient to iteratively amplify the weak conjecture. Amplifying the Weak Conjecture The whole process can be repeated to achieve a higher probability bound. The weak conjecture and Reduction-Regularity imply P r o b ( V 1 ( C ) | ¯ ¯¯ ¯ P ( C ) ) ≥ 0.99 + 10 − 2 δ , which would already give us a stronger version of the weak conjecture. But now Reduction-Regularity (with L = V ′ 1 ) implies there is a polynomial many-one reduction f 1 from V ′ 1 = V 1 ∩ ¯ ¯¯ ¯ P to ¯ ¯¯ ¯ P such that P r o b ( f 1 ( C ) ∉ V ′ 1 | f 1 ( C ) ∈ ¯ ¯¯ ¯ P ) ≥ δ . Defining V 2 = V 1 ∩ V f 1 1 , where V f 1 1 = { C ∈ C | f 1 ( C ) ∈ V 1 } , and V ′ 2 = V 2 ∩ ¯ ¯¯ ¯ P , this entails P r o b ( ¯ ¯¯¯ ¯ V 2 ( C ) | V ′ 1 ( C ) ) ≥ δ and P r o b ( V 2 ( C ) | V ′ 1 ( C ) ) = P r o b ( V ′ 2 ( C ) | V ′ 1 ( C ) ) ≤ 1 − δ . As P r o b ( V ′ 1 ( C ) | ¯ ¯¯ ¯ P ( C ) ) ≤ 10 − 2 ( 1 − δ ) and V ′ 2 ⊆ V ′ 1 ⊆ ¯ ¯¯ ¯ P , it follows that: P r o b ( V 2 ( C ) | ¯ ¯¯ ¯ P ( C ) ) = P r o b ( V ′ 2 ( C ) | V ′ 1 ( C ) ) P r o b ( V ′ 1 ( C ) | ¯ ¯¯ ¯ P ( C ) ) ≤ 10 − 2 ( 1 − δ ) 2 Note that P ⊆ V 2 , so V 2 would satisfy an even stronger conjecture. The amplification step can be iterated inductively. For any positive i ∈ N , given V ′ i is in NP, we can construct a reduction f i from V ′ i to ¯ ¯¯ ¯ P (via Reduction-Regularity) such that defining V i + 1 = V i ∩ V f i i and V ′ i + 1 = V i + 1 ∩ ¯ ¯¯ ¯ P yields P r o b ( ¯ ¯¯¯¯¯¯¯¯ ¯ V ′ i + 1 ( C ) | V ′ i ( C ) ) ≥ δ and P r o b ( V ′ i + 1 ( C ) | V ′ i ( C ) ) = P r o b ( V i + 1 ( C ) | V ′ i ( C ) ) ≤ 1 − δ . If the amplification is iterated m times, we have: P r o b ( V m ( C ) | ¯ ¯¯ ¯ P ( C ) ) = P r o b ( V 0 ( C ) | ¯ ¯¯ ¯ P ( C ) ) m ∏ i = 1 P r o b ( V i ( C ) | V ′ i − 1 ( C ) ) ≤ ( 1 − δ ) m 10 − 2 Given any ϵ ∈ ( 0 , 1 ) , we can choose an m ∈ N such that 10 − 2 ( 1 − δ ) m ≤ ϵ , or m ≥ log 1 − δ ( 10 2 ϵ ) .   Iterating the amplification step m times thus yields P r o b ( V m ( C ) | ¯ ¯¯ ¯ P ( C ) ) ≤ ϵ and, consequently, P r o b ( ¯ ¯¯¯¯¯ ¯ V m ( C ) | ¯ ¯¯ ¯ P ( C ) ) ≥ 1 − ϵ . Note that V m is exactly the set of reversible circuits C for which there is a π yielding V m ( C , π ) = 1 , for a polynomial verifier V m ( ⋅ , ⋅ ) , since V m is in NP. Furthermore, P ⊆ V m . Therefore the (weak) conjecture, together with Reduction-Regularity, implies: Amplified (weak) Computational no-coincidence conjecture: For a reversible circuit C : { 0 , 1 } 3 n → { 0 , 1 } 3 n , let P ( C ) be the property that there is no input x to C that ends in n zeros, such that C ( x ) also ends in n zeros. For any ϵ ∈ ( 0 , 1 ) , there exists a polynomial-time verification algorithm V that receives as input: A reversible circuit C : { 0 , 1 } 3 n → { 0 , 1 } 3 n An advice string π such that: For all C such that P ( C ) is true, there exists π with length polynomial in the size of C , such that V ( C , π ) = 1 . For 100 ( 1 − ϵ ) % of random reversible circuits C for which P(C) is false, no such π exists. Note that, relative to the size of the circuit C , the algorithm V (or V m ) still runs in polynomial time and π still is polynomial-sized. Nonetheless, the number m of amplification iterations needed for a given ϵ is proportional to log 1 / ϵ if we assume a fixed δ ∈ ( 0 , 1 ) . This implies the computational complexity of V and π might increase exponentially on 1 / ϵ , as indicated in the Appendix. Amplifying the Original Conjecture The amplified weak conjecture can finally be used to amplify the original one. Let α ∈ ( 0 , 1 ) be such that P r o b ( C ∈ P ) = α and P r o b ( C ∈ ¯ ¯¯ ¯ P ) = 1 − α . Since P r o b ( ¯ ¯¯ ¯ V ( C ) | P ( C ) ) = 0 for any V satisfying the amplified weak conjecture, the latter implies that, for any ϵ ∈ ( 0 , 1 ) , there is a V such that P r o b ( ¯ ¯¯ ¯ V ( C ) ) = P r o b ( ¯ ¯¯ ¯ P ( C ) ) P r o b ( ( ¯ ¯¯ ¯ V ( C ) | ¯ ¯¯ ¯ P ( C ) ) ≥ ( 1 − α ) ( 1 − ϵ ) . Note that P r o b ( ¯ ¯¯ ¯ V ( C ) ) ≤ 1 − α , for all C ∈ P is also in V , as required by the amplified conjecture. Hence, we can make the probability bound arbitrarily close to that limit, and, assuming Reduction-Regularity, the (weak) conjecture implies: Amplified Computational no-coincidence conjecture: For a reversible circuit C : { 0 , 1 } 3 n → { 0 , 1 } 3 n , let P ( C ) be the property that there is no input x to C that ends in n zeros, such that C ( x ) also ends in n zeros. Let α ∈ ( 0 , 1 ) be such that exactly 100 α % of  random reversible circuits satisfy P. For any ϵ ∈ ( 0 , 1 ) , there exists a polynomial-time verification algorithm V that receives as input: A reversible circuit C : { 0 , 1 } 3 n → { 0 , 1 } 3 n An advice string π such that: For all C such that P ( C ) is true, there exists π with length polynomial in the size of C , such that V ( C , π ) = 1 . For 100 ( 1 − ϵ ) ( 1 − α ) % of random reversible circuits C , no such π exists. The Reasonability of Reduction-Regularity Before speculating about the implications of these results, we have to check how reasonable Reduction-Regularity is. At first, it might appear that it is just a harmless assumption. Upon closer look, we can see, for instance, that it implies a δ -fraction of the circuits in V ′ i to be reduced (via f i ) to circuits in ¯ ¯¯ ¯ P ∖ V ′ i . All circuits in V ′ i ⊂ V i show the special structure ( V i ( C , π ) = 1 ) without satisfying the property P . Therefore, it is plausible to conceive that C ∈ V ′ i might imply probability 100% for f i ( C ) ∈ V ′ i ⊂ V i , even though at least 99% of the circuits in ¯ ¯¯ ¯ P are not in V i ⊆ V 0 . Against that, we can argue that f i can be constructed as a composition of reductions, for instance reducing V ′ i to SAT and then reducing SAT to ¯ ¯¯ ¯ P , probably washing away any possible structure that entail f i ( C ) ∈ V ′ i (C). In the end, the plausibility of Reduction-Regularity might depend on the specific probability distribution over circuits; personally, I believe this premise is quite reasonable, and maybe it can be supported by some empirical experiments. Reduction-Regularity can actually be weakened, as we just need an infinite number of i 's such that P r o b ( V i ( C ) | V ′ i − 1 ) ≤ 1 − δ . Let I ⊆ N be the (infinite) set of such values of i , with I = { i 1 , i 2 , i 3 … } such that i 1 < i 2 < i 3 … . Then the m amplification iterations with the original Reduction-Regularity can be emulated with i m iterations using this weakened version. Though the bounds derived in the Appendix do not hold anymore, intuitively the weakened version should be even more plausible. Conclusion Assuming Reduction-Regularity, we might speculate whether the original conjecture is likely by analysing its amplified version. Intuitively, the strengthened version should decrease our credence on the conjecture, but it is not clear to what amount. It is tempting to consider what happens when m tends to infinity, as ϵ tends to zero and V ′ i tends to the empty set. This would imply P ∪ V ′ i = P is in NP, but we know it is coNP-hard, so we would have NP=coNP. However, the running time of the verifier might increase exponentially on 1 / ϵ , as indicated in the Appendix, or the complexity of f i might increase with i , not being polynomial in the limit. Personally, I am inclined to think the conjecture is false. If the conjecture is indeed false, then it follows that NP ≠ coNP [9] and, consequently, P ≠ NP. Hence, it should be rather hard to prove the conjecture is false. Appendix To derive an upper bound for the complexities of V and π in the amplified conjecture after m amplification iterations, we construct an algorithm for V 1 ( ⋅ , ⋅ ) using V 0 ( ⋅ , ⋅ ) , f 0 and V f 0 0 ( ⋅ , ⋅ ) . Recall that V 1 ( ⋅ , ⋅ ) is a verifier for V 0 ∩ V f 0 0 , V 0 ( ⋅ , ⋅ ) is a verifier for V 0 and V f 0 0 ( ⋅ , ⋅ ) is a verifier for V f 0 0 . To verify that C ∈ V 0 ∩ V f 0 0 , we can verify that C ∈ V 0 and C ∈ V f 0 0 . C ∈ V 0 iff there is a π 0 such that V 0 ( C , π 0 ) = 1 ; C ∈ V f 0 0 iff there is a π f 0 such that V f 0 0 ( C , π f 0 ) = V 0 ( f 0 ( C ) , π f 0 ) = 1 . Hence, V 1 ( ⋅ , ⋅ ) can be defined via the multiplication V 1 ( C , π 0 π f 0 ) = V 0 ( C , π 0 ) V 0 ( f 0 ( C ) , π f 0 ) , [10] such that C ∈ V 1 iff there are π 0 and π f 0 such that V 1 ( C , π 0 π f 0 ) = 1 . The complexity of V 1 ( ⋅ , ⋅ ) is thus dominated by the complexity of V f 0 0 ( ⋅ , ⋅ ) . Assuming | π 0 | ∈ O ( | C | α ) and the time to run V 0 ( C , π ) is O ( ( | C | + | π | ) β ) , it follows that V 0 is in O ( ( | C | α β ) .  If the time to run f 0 ( C ) is O ( | C | γ ) , then the time to run V 1 ( C , π ) = V 0 ( f 0 ( C ) , π ) is O ( ( | C | α β γ ) and the size of its certificate is O ( | C | α γ ) . That is, after one iteration of the amplifying step, the size of the certificate π and the and the run time of the verifier have their upper bound raised to the power of γ . After m iterations, they will be raised to the power of γ m (assuming all f i have the same complexity [11] ), hence increasing doubly exponentially on m , unless γ = 1 (all reductions run in linear time). Since m = O ( log 1 / ϵ ) for a fixed δ , both complexity bounds would increase exponentially on 1 / ϵ . ^ Also posted at LessWrong . ^ In the original conjecture, this probability cannot arbitrarily approach 1, as there is a positive probability for P ( C ) being true, as we will discuss. ^ We use the same symbol, say S , to denote a property of circuits, the set of circuits satifying that property and the problem of deciding, given a circuit C ∈ C , whether C ∈ S (or, equivalently, S ( C ) ). ^ To verify that a C is in ¯ ¯¯ ¯ P , one can guess an input that ends with n zeros and obtain the output ending with zeros in polynomial time. Thus ¯ ¯¯ ¯ P is in NP and P is in coNP. ^ Abusing the notation, we use the same symbol for a set in NP and the corresponding polynomial-time verifier. ^ We think the probability distribution should not matter, as the conjecture's authors write, but they show a possible distribution to be concrete. ^ This premise can be weakened as we discuss later. ^ This is admittedly not a good name, and suggestions are welcome. ^ If NP=coNP, then deciding the property P is in NP, and there is a verifier satisfying the conjecture. ^ For strings a and b , a b denotes their concatanation. ^ This might be a rather strong assumption, as the complexity of f i might increase with i .