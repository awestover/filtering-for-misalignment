TL;DR In this work, I explain how a mind can function in a universe devoid of cause and effect. I show that such a design can accommodate arbitrary restrictions that the laws of physics might happen to place on its outputs. I originally decided to write this post when I decided that I wanted to refer to this idea within something else that I intend to write, and then realized that I couldn't think of anywhere that the whole idea was clearly expressed. Imagine a acausal universe, as described in https://www.lesswrong.com/posts/o5F2p3krzT4JgzqQc/causal-universes (The rest of this post probably won't make sense if you haven't read and understood this first) What kind of mind design would work in such a universe. An acausal mind doesn't have separate inputs and outputs, it just has acausal connections, which for the purposes of this post, I call aputs. An aput is a correlation between some part of the external world and the AI algorithm that is enforced by the laws of physics. Lets assume that all the aputs are binary, true or false. Let B = { 0 , 1 } The AI is then a black box that is consistent with some but not necessarily all possible aputs. In terms of the exponentially big computer simulating the universe, the AI has a set of aputs a 1 . . . a n and the AI has an action set S . S ⊂ B n . The computer simulating the universe searches through all possible bitstrings. If the subset of bits that consist of the AI's aputs is not in S , then the bitstring is discarded. Of course, the AI might not be a black box to the physics of the universe. The AI might contain some internal variables, with multiple consistency checks relating them to the surroundings. The AI might not be guaranteed existence at all. If the state of the world where the AI is never turned on is self consistent, there isn't anything the AI can do about it. Of course, sometimes the laws of physics put constraints on S . These physical constraints can be modeled by forcing the AI to pick S ∈ C for some set C determined by the laws of physics. Some physically relevant constraints on C include causality. C = { S ⊂ B n : ∀ ( a 1 , . . . , a n ) ∈ S ∀ x ∈ B m ∃ 1 y ∈ B n − m s t ( a 1 , . . . a m ) = x ⟹ ( a m + 1 , . . . , a n ) = y } for fixed m < n . ( ∃ 1 means there exists a unique value) If we divide the aputs into blocks ( i 1 , o 1 , i 2 , o 2 , . . . i m , o m ) for easier notation, then we can describe the condition that not all outputs depend on all inputs. You can put other more complicated conditions to represent other limits to information flow. Another condition you might want is C = { S ⊂ B n : ∃ f : B n 2 → B n 2 a bijection : S = { ( y , f ( y ) ) : y ∈ B n 2 } } This condition says that the AI has to implement a bijective function. This might be a real limitation of an AI built out of reversible computing with no information sink. Quantum computers can be represented by making the a i be real numbers describing the input and output quantum state, with C being the set produced by unitary matrices. An agent that had access to an outcome pump type device that could force reality to not give it certain inputs by creating a conditional contradiction would also be described easily. For each input, there is at most one output. What does AIXI look like in this formalism. You have some function U : P ( B n ) → R You have a set H of acausal universe models, a single universe model is a function P ( B n ) . S o H ⊂ P ( P ( B n ) ) . H can be considered a multiset if you like. You have a weight function w : P ( B n ) → R . The weight function could be w ( S ) = 2 ( − w ′ ( S ) ) where w ′ ( S ) = m i n t ∈ T (states t ) where T =set of Turing machines from machines, considered as functions from n bits to 1 bit that acts as an indicator function for S . Your set C is determined by what physics you have access to when building your AI. If the universe contains closed timelike curves, but your AI doesn't, then C has the causal structure. Action = argmax S ∈ C ( ∑ h ∈ H w ( h ) U ( h ∩ S ) ) By separating the physical facts about where information can and can't go from our agent design, we are left with a simpler design that can be applied to a wide range of systems. Note that the new design is searching an exponentially larger action space than AIXI.