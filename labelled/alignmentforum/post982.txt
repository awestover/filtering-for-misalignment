This research was produced during SERI MATS. Thanks to Vanessa Kosoy for providing ideas and reading drafts. Introduction In this article, we investigate "infra-Bayesian logic" (IBL for short), which is an idea introduced by Vanessa Kosoy. The original idea is outlined in Vanessa Kosoy's Shortform . Here, we expand with some details and examples. We also try to fix the mentioned issues (e.g. lack of continuity for certain maps) by investigating several candidate categories for semantics. However, we fail to find something that works. As a theory of beliefs and reasoning, infra-Bayesianism gives rise to semantics for a certain logic, which we might call "infra-Bayesian logic" (IBL for short). Formalizing the syntax for this logic has the advantage of providing a notion of description complexity for infra-POMDPs (partially observable Markov decision processes) expressed via this syntax, and hence could serve as a foundation for an infra-Bayesian analogue of AIXI. Infra-Bayesian logic is not the only way to define an infra-Bayesian analog of AIXI. Such an alternative could be to use oracle machines (with an extra input tape for a source of randomness): For a probabilistic oracle machine, the corresponding IB hypothesis is the closed convex hull of all stochastic environments that result from using the oracle machine with a particular oracle, and then one could use the description complexity of the oracle machine (which can be defined by choosing a universal oracle machine) as a basis for an infra-Bayesian AIXI. The analogue of oracle machines for (non-infra-Bayesian) AIXI would be (probabilistic) Turing machines. However, infra-Bayesian logic might be an interesting alternative to describing infra-Bayesian hypotheses, and this approach would be specific to infra-Bayesianism (there is, as far as we know, no good analogue of infra-Bayesian logic in (ordinary) Bayesianism). Note that we are currently unaware of a working semantics for the higher order logic. We discuss some candidates considered in Candidates for the Semantics , and the ways in which they fail. It's unclear whether these issues with the semantics are mostly technical in nature, or whether they point to some deeper phenomena. We can, however, restrict to a first order IBL on finite sets, which, albeit less powerful, is still expressive enough for many applications (in particular covers all the examples in Examples ). See also the paragraph on IBL in the overview of the learning theoretic Agenda . Outline and Reading Guide You can skim/skip the Notation section and use it as a reference instead. The main description of IBL is given in Infra-Bayesian Logic . To get an initial and informal idea what IBL looks like, read Less Formal Description of Infra-Bayesian Logic . For a technical description and a complete list of properties, read Formal Description of Infra-Bayesian Logic . Note that the latter description requires some familiarity with category theory. In Constructions in IBL we list how we can combine basic elements of IBL to express more complicated things. In Infra-POMDPs we talk about infra-POMDPs as an application of IBL. Some knowledge of infra-Bayesianism is beneficial here, but not required. We highlight the section on Examples , where we describe the IBL terms for concrete Infra-POMDPs. In Candidates for the Semantics we discuss the various (failed) candidates we tried for the higher-order logic version of IBL. A typical reader is not expected to read this section. The Appendix is for mostly technical proofs and counterexamples. We recommend to only look these up when you are interested in the technical details. For example, if you wish to understand why conjunction is not continuous in IBL, you can find the details there. Notation Let us describe notation needed for using concepts from infra-Bayesianism. This notation section is partially copied from the Infra-Bayesian Physicalism article , but extended from finite sets to compact Polish spaces, wich requires a bit more measure theory. Also, we use the symbol □ X for homogeneus ultracontributions (instead of □ c X as in the IBP article). The notation from the IBP post is a bit different from some of the other posts on infra-Bayesianism in that it uses ultradistributions/ultracontributions rather than infradistributions. We denote R + : = [ 0 , ∞ ) . We will work a lot with compact Polish spaces. Compact Polish spaces are spaces that are topologically equivalent to some compact metric space (the metric is not fixed, however, only the topology). An important special case of compact Polish spaces are finite (discrete) sets. Definition 1 . Given a compact Polish space X , a contribution on X is a (Borel) measure θ on X with θ ( X ) ≤ 1 . Given a measurable function f : X → R and θ ∈ Δ c X , we denote θ ( f ) : = ∫ X f ( x ) d θ ( x ) . The space of contributions is denoted Δ c X , equipped with the weak- ∗ topology (i.e. the weakest topology such that the functions Δ c X ∋ θ ↦ θ ( f ) ∈ R are continuous for all continuous functions f : X → R ). Naturally, any (probability) distribution is in particular a contribution, so Δ X ⊆ Δ c X . There is a natural partial order on contributions: θ 1 ≤ θ 2 when θ 1 ( A ) ≤ θ 2 ( A ) for all measurable A ⊂ X . Definition 2 . A homogeneous ultracontribution (HUC) on X is non-empty closed convex Θ ⊆ Δ c X which is downward closed w.r.t. the partial order on Δ c X . The space of HUCs on X is denoted □ X . If a HUC Θ ∈ □ X has the property Θ s.t. Θ ∩ Δ X ≠ ∅ , we call it a homogeneuous ultradistribution. Sometimes we need a topology on the space of HUCs □ X . In this case we will use the topology induced by the Hausdorff metric, (where we use a metric on Δ c X that fits with the weak- ∗ topology. The topology induced by the Hausdorff metric is also equivalent to the so-called Vietoris topology, which is a topology that only depends on the underlying toplogy on Δ c ( X ) , see here . See also Propositions 42 and 50 in Less Basic Inframeasure Theorey for the same result for infra-distributioins). One can show that □ X is a compact Polish space with this topology when X is a compact Polish space, see Lemma 10. Let us introduce more notation. For a set A ⊂ Δ c ( X ) , cl A denotes its closure. Given another compact Polish space Y and a measurable function s : X → Y , s ∗ : □ X → □ Y is the pushforward by s : s ∗ Θ : = cl { s ∗ θ ∣ θ ∈ Θ } , where ( s ∗ θ ) ( A ) : = θ ( s − 1 ( A ) ) for all measurable A ⊂ Y . We can omit the cl in the definition if s is continuous. A map X → □ Y is sometimes referred to as an infrakernel . Given an infrakernel Ξ : X → □ Y , Ξ ∗ : □ X → □ Y is the pushforward by Ξ : Ξ ∗ Θ : = cl { κ ∗ θ ∣ θ ∈ Θ , κ : X → Δ c Y , κ measurable , ∀ x ∈ X : κ ( x ) ∈ Ξ ( x ) } , where (for measurable A ⊂ Y ) ( κ ∗ θ ) ( A ) : = ∫ X κ ( x ) ( A ) d θ ( x ) . For a measurable function s : X → Y We also define the pullback operator s ∗ : □ Y → □ X via s ∗ Θ : = cl { θ ∈ Δ c X ∣ s ∗ θ ∈ Θ } . We can omit cl here if s is continuous. pr X : X × Y → X is the projection mapping, i X : X → X ∐ Y is the inclusion map. Given Θ ∈ □ X and an infrakernel Ξ : X → □ Y , Θ ⋉ Ξ ∈ □ ( X × Y ) is the semidirect product: Θ ⋉ Ξ : = cl { κ ⋉ θ ∣ θ ∈ Θ , κ : X → Δ c Y , κ measurable , ∀ x ∈ X : κ ( x ) ∈ Ξ ( x ) } , where the measure κ ⋉ θ is defined by ( κ ⋉ θ ) ( A × B ) : = ∫ A κ ( x ) ( B ) d θ ( x ) for all measurable A ⊂ X , B ⊂ Y , which can be extended to arbitrary measurable sets C ⊂ X × Y in the usual measure-theoretic way. We will also use the notation Ξ ⋊ Θ ∈ □ ( Y × X ) for the same HUC with X and Y flipped. And, for Λ ∈ □ Y , Θ ⋉ Λ ∈ □ ( X × Y ) is the semidirect product of Θ with the constant ultrakernel whose value is Λ . For a closed set A ⊂ X , we define ⊤ A : = { μ ∈ Δ c X ∣ μ ( X ∖ A ) = 0 } ∈ □ X (we'll call these sharp ultradistributions). We also define ⊥ ∈ □ X via ⊥ = { 0 } . Infra-Bayesian Logic The formal description in this section assumes some familiarity with type theory and categorical logic. For an informal overview of the syntax, we point the reader to Less Formal Description of Infra-Bayesian Logic . The infra-Bayesian notion of beliefs gives rise to a fairly weak form of logic, in the sense that the spaces of predicates in infra-Bayesian logic don't form Heyting algebras, and are generally non-distributive and even non-modular as lattices. Also, due to the lack of function types, we cannot use the full syntax of type theory. We will therefore work with a simplified syntax, still maintaining versions of many of the usual constructions appearing in higher order logic. This language can be used to describe infra-POMDPs (see Infra-POMDPs ), which in turn is a useful beginning to something like an infra-AIXI (see Application: an Infra-Bayesian AIXI Analogue ). Less Formal Description of Infra-Bayesian Logic Infra-Bayesian logic is a logical language. The language has types. Types can come from a set of initial types T ι , or can be combined from other types using sums and products. Also, 0 and 1 are special types (where 0 contains no element, and 1 contains exactly one element, so to speak). There is also a more complicated construction of additional types: If α is a type, then we also consider predicates on α a type, which we denote by [ α ] . Infra-Bayesian logic also has maps between types. The set of maps between types α and β is denoted by F α → β . We will not list every kind of map that we require for infra-Bayesian logic in this informal description. But some examples are ∧ α ∈ F [ α ] × [ α ] → [ α ] and ∨ α ∈ F [ α ] × [ α ] → [ α ] , which correspond to a meaning of "and" and "or". A map of type F 1 → α is basically the same as something of type α , but it allows us to compose this with other maps. Examples are ⊤ ∈ F 1 → [ 1 ] and ⊥ ∈ F 1 → [ 1 ] which correspond to "true" and "false". There are also maps for equality and predicate evaluation. All kinds of different maps can be combined and composed to yield expressions in infra-Bayesian logic. How does this connect to infra-Bayesianism? A collection of sentences in infra-Bayesian logic can have a model M . There are lots of rules for a model to ensure that the symbols of infra-bayesian logic correspond to their intended meaning. A model maps types into topological spaces. In order to make sure the above-mentioned types behave reasonably under the model, we require that M ( 0 ) is the empty topological space, M ( 1 ) is the 1 -point topological space, products and sums work as expected ( M ( α × β ) = M ( α ) × M ( β ) and M ( α + β ) = M ( α ) ⊔ M ( β ) ). A special case is the topological space for [ α ] (the type of predicates on α ): We require that M ( [ α ] ) is the topological space of homogeneous ultra-contributions over M ( α ) , i.e. □ M ( α ) . We will also explore alternatives to HUCs over topological spaces, but it should be some general notion of infra-distribution. The model of a map f ∈ F α → β is a map between the topological spaces M ( α ) → M ( β ) . We will have conditions that the model of a map is consistent with the meaning. For example, we require that the model of " ∧ α " maps two HUCs to their intersection. We will later investigate the precise conditions on toplogical spaces and maps that we would like to have for infra-Bayesian logic. Formal Description of Infra-Bayesian Logic Syntax Given a set T ι of primitive types, we can require that the types form a category C ( T ) , which should be the "freest" category such that: T ι ⊂ O b ( C ( T ) ) C ( T ) has finite products and coproducts C ( T ) supports infra-Bayesian logic (Definition 3). We won't construct the category C ( T ) here (uniqueness is clear). We'll use the shorthand F α → β = C ( T ) ( α , β ) for the set of morphisms, and write V α = F 1 → α (where 1 is the terminal object). Definition 3 . We say that a category C with finite products and coproducts supports infra-Bayesian logic, if it satisfies the following requirements: There is a functor [ _ ] : C → C o p (recall that C o p is the opposite category of C ). For α ∈ O b ( C ( T ) ) , [ α ] is the object intended to correspond to predicates on α . For f ∈ C ( α , β ) , we write f ∗ : [ β ] → [ α ] instead of [ f ] to denote pullback of predicates. There are morphisms ∨ α , ∧ α ∈ F [ α ] × [ α ] → [ α ] . We require that these operations turn V [ α ] into a bounded lattice, and we require the functor [ _ ] to induce a functor into the category of lattices. In particular, we have ⊤ , ⊥ ∈ V [ 1 ] . We require that pr ∗ β : [ β ] → [ α × β ] have natural left and right adjoints with respect to the poset structure (of the lattice) above. We also require these adjoints to come from morphisms in C , denoted by ∃ α β , ∀ α β ∈ F [ α × β ] → [ β ] respectively. We require the existence of an equality predicate = α ∈ V [ α × α ] , which is the minimal predicate such that ( diag ∗ α ∘ = α ) = ⊤ α (cf. A constant function with output top ). We require the existence of ev α ∈ V [ [ α ] × α ] (predicate evaluation). Given f : β → [ α ] , we can pull back ev α via f × 1 α to get ^ f ∈ V [ β × α ] . Note however that we cannot require universality here (i.e. that every predicate in V [ β × α ] arise this way), due to the failure of the disintegration theorem in infra-Bayesianism. It's not entirely clear currently what the appropriate condition to require from ev α should be on the syntax side, even though the intended semantics can be described (cf. Item 5 in the semantics). For q ∈ Q ∩ [ 0 , 1 ] we use δ q ∈ V [ 1 + 1 ] as a syntactic constant symbol corresponding to a coin toss with probability q . Note that in Item 6 we could require the following more general set of symbols, however, the relevant ones can likely be approximated via the existing syntax. For n ∈ N , let D n ⊂ □ n (treating n as an n -point discrete space) be the subset of "describable" ultracontributions under some such notion. We would then introduce constant symbols ┌ μ ┐ ∈ V [ n ] for each μ ∈ D n . Remark 4 . In order to construct the syntax for the first order theory, we can instead consider two categories C (base types) and D (predicate types), with the functor [ _ ] : C → D o p . In this context the predicate functor [ _ ] cannot be iterated, hence we are left with a first order theory. The requirements in Definition 3 remain the same, except for Item 5 being removed. The construction of a pushforward via a kernel in Pushforward via a kernel no longer makes sense in that generality, but we explain how to recover it for finite sets in the first order theory in Pushforward via kernel for finite sets , which is then used when unrolling the time evolution of an infra-POMDP in Process . Semantics We require a model to be a functor M : C ( T ) → P , which preserves finite products and coproducts. Moreover, we require P to support infra-Bayesian logic (cf. Definition 3), and the model functor M to respect the logical structure. In practice, we will want P to be some subcategory of T o p . The motivating candidate is to take P to be the category of compact Polish spaces with continuous maps, and the predicate functor on P to be □ . This choice however doesn't work for higher order logic. We nevertheless spell out what the logical semantics translate to, using □ as a generic symbol denoting some appropriate notion of "ultracontributions". M ( [ α ] ) = □ M ( α ) (cf. Lemma 10), and M ( f ∗ ) = M ( f ) ∗ is the pullback (see Continuity Counterexamples about issues with continuity in the case of HUCs). We require M to induce a lattice homomorphism V [ α ] → □ M ( α ) , where M ( ∨ α ) : □ M ( α ) × □ M ( α ) → □ M ( α ) is given by convex hull of the union M ( ∧ α ) : □ M ( α ) × □ M ( α ) → □ M ( α ) is given by intersection (see Continuity Counterexamples about issues with continuity in the case of HUCs) Predicates. Let X = M ( α ) , Y = M ( β ) , and pr Y : X × Y → Y be projection onto the second factor. The following follow from the adjunction M ( ∃ α β ) = pr Y ∗ is the pushforward For μ ∈ □ ( X × Y ) , we have M ( ∀ α β ) ( μ ) = { p ∈ □ Y | ∀ q ∈ Δ c ( X × Y ) : ( pr Y ∗ ( q ) = p ⟹ q ∈ μ ) } (see Continuity Counterexamples about issues with continuity in the case of HUCs) M ( = α ) = ⊤ diag M ( α ) (as a sharp ultradistribution) If X = M ( α ) , then M ( ev α ) = ⊤ □ X ⋉ 1 □ X , where ⊤ □ X ∈ □ □ X , and 1 □ X : □ X → □ X is considered as an infrakernel. M ( δ q ) ∈ □ ( pt + pt ) is the crisp ultradistribution corresponding to a coin toss with probability q ∈ Q ∩ [ 0 , 1 ] (here pt is the one point space). Note in the more general setting of describable ultracontributions, we would require M ( ┌ μ ┐ ) = μ . Definition 5 . A subset of V [ 1 ] (i.e. a set of sentences) is called a theory. We say that M models the theory T if M ( ϕ ) = ⊤ pt for all ϕ ∈ T . Remark 6 . Finding an appropriate category P turns out to be harder than first expected. We discuss various candidates considered in Candidates for the Semantics . In general, we note that for infra-POMDPs with finite state spaces, the transition (infra-)kernels are always continuous, and some of the issues with continuity mentioned in Candidates for the Semantics are less of a problem. Constructions in IBL In the following we construct various useful components of IBL using the syntax outlined above. These constructions will also be used to build examples of infra-POMDPs in Infra-POMDPs . Pushforward Given f : X → Y , we can construct the pushforward f ∗ : [ X ] → [ Y ] as follows. First, consider the following two maps into [ X × Y ] : 1 = Y − − → [ Y × Y ] ( f × 1 Y ) ∗ − −−−− → [ X × Y ] (this represents the graph of f ) [ X ] pr ∗ X − − → [ X × Y ] . Composing the product of these two with ∧ X × Y : [ X × Y ] × [ X × Y ] → [ X × Y ] , we get [ X ] = 1 × [ X ] → [ X × Y ] , and finally post-composing with [ X × Y ] ∃ X Y − − → [ Y ] , we get f ∗ : [ X ] → [ Y ] . Pushforward via a kernel Given f : X → [ Y ] , we can construct the pushforward f ∗ : [ X ] → [ Y ] as well. This is done similarly to Pushforward , except the element in [ X × Y ] is replaced with 1 ev Y − − → [ [ Y ] × Y ] ( f × 1 Y ) ∗ − −−−− → [ X × Y ] , where ev Y is predicate evaluation. Pushforward via kernel for finite sets If X is a finite set, then we can think of a map f : X → [ Y ] as a collection of points f x : 1 D → [ Y ] , which is meaningful in the first order syntax too, as long as the predicate category has a final object 1 D ∈ D . In this case we can construct the pushforward along the kernel f in the first order theory as follows. For each x ∈ X we have the composite G f x : 1 f x − → [ Y ] ( ι x × 1 Y ) ∗ − −−−− → [ X × Y ] , where ι x is the inclusion of x ∈ X , and ( ι x × 1 Y ) ∗ is the regular pushforward from Pushforward . Now, taking the product of these over x ∈ X , and taking (iterated) disjunction, we have 1 ∏ x ∈ X G f x − −−−−− → ∏ x ∈ X [ X × Y ] ∨ → [ X × Y ] , which is the "graph of f ", using which we construct the pushforward f ∗ : [ X ] → [ Y ] analogously to Pushforward and Pushforward via a kernel . Equality of functions Given f , g : α → β , we want to construct a sentence s f = g ∈ V [ 1 ] . This can be done as follows. First, take the composite with the diagonal on α φ : α diag α − −− → α × α f × g − − → β × β , then we have s f = g : 1 = β − → [ β × β ] φ ∗ − → [ α ] ∀ α 1 − − → [ 1 ] , so s f = g ∈ V [ 1 ] is the desired sentence. Mixing with probability 1/2 Assume that we have two terms s 1 ∈ F 1 → σ 1 , s 2 ∈ F 1 → σ 2 . Then we have s 1 + s 2 ∈ F 1 + 1 → σ 1 + σ 2 . Applying a pushforward yields ( s 1 + s 2 ) ∗ ∈ F [ 1 + 1 ] → [ σ 1 + σ 2 ] . Then we can compose with δ 1 / 2 ∈ F 1 → [ 1 + 1 ] , which assigns a fair coin distribution on 1 + 1 . f : 1 δ 1 / 2 − − → [ 1 + 1 ] ( s 1 + s 2 ) ∗ − −−−− → [ σ 1 + σ 2 ] . A constant function with output bottom We can construct a constant function term f ∈ F α → [ β ] whose model M ( f ) is a constant function that maps everything to ⊥ M ( β ) as follows. Let t α ∈ F α → 1 be the terminal map. Then we can define the term f via f : α t α − → 1 ⊥ → [ 1 ] t ∗ β − → [ β ] . This does the right thing: By factoring through M ( 1 ) = pt the function M ( f ) has to be constant, and by using ⊥ , the output has to be ⊥ M ( β ) . A constant function with output top This works the same way, just using the symbol ⊤ ∈ F 1 → [ 1 ] instead of ⊥ ∈ F 1 → [ 1 ] : f : α t α − → 1 ⊤ → [ 1 ] t ∗ β − → [ β ] . Components of infrakernels for sum types For a function f ∈ F α + β → [ γ + δ ] , how do we get access to its components, so that we get a term f α , γ ∈ F α → [ γ ] ? We do this by composing with i α β and i ∗ γ δ , i.e. f α , γ : α i α − → α + β f → [ γ + δ ] i ∗ γ − → [ γ ] . For the other components this would work essentially in the same way, which would give us functions f α , δ ∈ F α → [ δ ] , f β , γ ∈ F β → [ γ ] , f β , δ ∈ F β → [ δ ] . Infra-POMDPs Setup We can describe infra-POMDPs in the language of infra-Bayesian logic in the following way. Infra-POMDPs consist of the following. Finite sets of actions A and observations O For each observation o ∈ O , a type σ o of states producing the given observation. Let σ ∗ = ∑ o ∈ O σ o be the type of all states. An initial state s 0 ∈ V [ σ ∗ ] For each a ∈ A , a transition kernel K a ∈ F σ ∗ → [ σ ∗ ] . Process Given a state at time t , s t ∈ V [ σ ∗ ] , and an action a ∈ A , we can apply the kernel pushforward ( K a ) ∗ : [ σ ∗ ] → [ σ ∗ ] , to end up in a new state s t + 1 ∈ V [ σ ∗ ] . Once receiving an observation o t ∈ O , we can do an update on the observed state. In general, this update depends on the loss function, but we can obtain a "naive" update via pull back and push forward through i o t : σ o t → ∑ o ∈ O σ o = σ ∗ to get the observed state ^ s t + 1 = ( i o t ) ∗ ( i o t ) ∗ ( s t + 1 ) ∈ V [ σ ∗ ] . Laws In infra-Bayesianism, laws (also known as belief functions in earlier posts on infra-Bayesianism) are functions Θ : Π → □ ( ( A × O ) ω ) , where Π is the space of possible (deterministic) policies of the IB agent (a technical note: the space ( A × O ) ω is a Polish space, when equipped with the topology generated by cylinder sets). Such a law describes infra-Bayesian beliefs how a policy will lead to certain histories. Under some conditions, one can convert an infra-POMDP into a corresponding law. We will not explain exactly how, and instead refer to Theorem 4 in "The many faces of infra-beliefs" . Examples Let us give an example of an infra-POMDP. The first example is basically just and ordinary MDP, rewritten to fit into the above notation for infra-POMDPs. Example 7 . We set O = { 0 , 1 } , A = { 0 , 1 } . This example has (functionally) no relevant hidden states, i.e. states are equivalent to observations. Taking action 0 ∈ A will lead to the same observation as the previous observation. Taking action 1 ∈ A will lead to the other observation as the previous observation. As for the initial conditions, we start out with probability 1 2 for each observation/corresponding state. Let us explain how Example 7 can be described using an IBL theory T ⊂ V 1 . We have types σ 0 and σ 1 for the states corresponding to the two possible observations. First, we introduce non-logical symbols s 1 ∈ V σ 0 , s 2 ∈ V σ 1 . Then, using the construction in Mixing with probability 1/2 , we can define a term in V [ σ ∗ ] that assigns probability 1 / 2 to each of σ 0 , σ 1 , as desired. Using function equality from Equality of functions , we can equate the initial state s 0 ∈ V [ σ ∗ ] with this mixture. We add the equality sentence to our theory T . This ensures that every model of the theory T satisfies M ( s 0 ) = 1 2 ⊤ M ( σ 0 ) + 1 2 ⊤ M ( σ 1 ) . Next, we will add sentences that describe the transition kernels. Note that we have two transition kernels K 0 , K 1 ∈ F σ ∗ → [ σ ∗ ] , one for each possible action. Then, for each transition kernel, we can decomposition it, like in Components of infrakernels for sum types . This gives us 8 possibilities. For example, ( K 0 ) σ 0 , σ 1 describes our beliefs that we will be in state σ 1 after we take action 0 ∈ A and are in state σ 0 . For all the 8 possible combinations, the resulting function should be a constant function, with values ⊥ or ⊤ σ 0 , 1 . Again, we can use the equality of functions as described in Equality of functions to ensure that these components of the transition kernels have the correct values, in accordance with the transition kernel as described in the example. We will add these sentences to the theory T , so that T now has 9 elements. Example 8 . The following is a "fully infra" POMDP. O = { o } , single observation σ o = { A , B } , two states A = { a } , single action. The credal set corresponding to K ( A ) is the interval [ 1 3 A + 2 3 B , B ] K ( B ) is the interval [ A , 2 3 A + 1 3 B ] . We can take downward closure to end up with a homogeneous ultradistribution. So a single step in the Markov process swaps A and B , but with some Knightean uncertainty of landing up to 1 / 3 away from the target. As we iterate through multiple timesteps, we gain no information through observation (since | O | = 1 ), so the intervals of Knightean uncertainty widen (the portion outside the Knightean interval shrinks as ( 2 3 ) t ). We can construct the above infra-POMDP via IBL as follows. Let δ 1 / 3 , δ 2 / 3 ∈ V [ 2 ] be coin tosses with probability of heads equal to 1 / 3 and 2 / 3 respectively. We could in principle approximate these with iterated fair coin tosses, but we assume them as given for convenience. Let i A , i B : 1 → 1 + 1 = σ ∗ be the two states. Then we have ⊤ A : 1 ⊤ → [ 1 ] i A ∗ − − → [ σ ∗ ] , and similarly for ⊤ B . We can construct the intervals of length 1 / 3 from A and B : I A = ⊤ A ∨ δ 2 / 3 ∈ V [ σ ∗ ] I B = ⊤ B ∨ δ 1 / 3 ∈ V [ σ ∗ ] . Finally, we construct the transition kernel K a = I B + I A : σ ∗ → [ σ ∗ ] . Application: an Infra-Bayesian AIXI Analogue A potential application for infra-Bayesian logic is to describe the hypotheses of an AIXI-like infra-Bayesian agent, by using IBL to describe infra-POMDPs. Let us expand a bit on this idea. Let's assume an infra-Bayesian agent knows that the environment is an infra-POMDP and also happens to know the finitely many actions A the agent can take each time step, and the finitely many possible observations O the agent could be receiving. However, it does not not know how many states there are. (We will leave rewards out of the picture here. We could include rewards by encoding it in the observations, e.g., by adding a reward r o for each observation. But for now let's focus only on the agent's model of the environment.) An infra-Bayesian agent would have a set of hypotheses of how the environment could be. In our setting, each hypothesis has the form of an infra-POMDP. Like an AIXI agent, we would like to have a variant of Occam's razor: simpler hypotheses should receive a higher weight. There is a potential approach to use a finite theory in IBL to describe a hypothesis for our infra-POMDP, and then the weight of this hypothesis in the prior is based on the length of the description of the IBL theory, e.g. proportional to 2 − 2 l when l is the description length. Note that some IBL theories might have no valid model, so these theories should be discarded from the hypotheses; and there might be other reason why an IBL theory might be excluded from the space of hypotheses, see below. Each theory in infra-Bayesian logic can have (possibly none or multiple) models. If we use types σ o , σ ∗ and symbols s 0 ∈ V [ σ ∗ ] , K a ∈ F σ ∗ → [ σ ∗ ] as in Setup , then each model M describes an infra-POMDP: The initial state can be described by M ( s 0 ) , and for each a ∈ A , M ( K a ) is the transition kernel. The question arises what do we do if there are multiple models for the same IBL term. Let us describe two approaches, which both rely on converting the infra-POMDP into a corresponding law, see Laws . A first approach could be to only allow theories in IBL that produce models which are unique up to equivalence, where we say that two models are equivalent if they produce infra-POMDPs that produce the same laws. A second approach could be to consider all possible models in a first step, then convert these models into corresponding laws, and then take the disjunction (i.e. closed convex hull of all outputs of the laws) to turn it into the final law. Candidates for the Semantics Compact Polish Spaces with Continuous Maps A first candidate for the category P would be compact Polish spaces with continuous maps, and ' □ ' being the space of HUCs as defined in Notation . However, we run into issues with continuity in this category. Namely, the maps M ( ∧ ) , M ( ∀ α β ) , M ( f ) ∗ are not always continuous, see Continuity Counterexamples . Allowing Discontinuity Another approach could be to bite the bullet on discontinuity and broaden the set of allowed morphisms in the semantics category. The problem with these approaches generally is that pullbacks really only behave nicely with respect to continuous maps, we typically lose functoriality when allowing discontinuity. That is, the desired property ( g ∘ f ) ∗ = f ∗ ∘ g ∗ can fail to hold for maps f : X → Y , g : Y → Z . This is mostly because for discontinuous functions we have to take the closure in the definition of the pullback (see Notation ). Upper Semicontinuity This approach is inspired by the fact that while intersection is not continuous on □ X , it is upper semicontinuous (wrt to the set inclusion order) on □ X . For this approach, we would use the category of compact polish spaces with a closed partial order, and for the maps we require that they are monotone increasing and upper semicontinuous. Here, a function f : X → Y is upper semicontinuous when x n → x ∧ f ( x n ) → y ⟹ y ≤ Y f ( x ) holds for all sequences { x n } ⊂ X and points x ∈ X , y ∈ Y . As for the partial order on □ X , one could consider the partial order based on set inclusions, or additionally combine this with the stochastic order mentioned in Definition 2.1 in IBP by requiring that elements in □ X are also downwards closed with respect to the stochastic order. In both cases, the approach with upper semicontinuous maps, runs into the functoriality issues mentioned above, see Semi-continuous Pullback is not Compositional . Measurable Maps We could try to broaden the set of morphisms even further, but naturally the issues with functoriality remain. A Different Notion of HUCs A possible remedy for the continuity issues could be to use an alternative definition of HUCs, in which the problematic maps become continuous. Roughly speaking, the high level idea here is to require elements of the modified HUCs to "widen" closer to ⊥ , thus avoiding the discontinuities. Unfortunately, we were not able to find a working semantics of this type, despite trying different approaches, as described below. We can require HUCs to be closed under the finer partial order ⪯ in Definition 9, and modify Definition 2 accordingly. Let □ L ( X ) denote the space of these alternative HUCs. One downside of this approach is that now the space □ L X depends on the metric on X , while previously it only depended on the underlying topology. Definition 9 (downward closure related to 1-Lipschitz functions). Let X be a compact metric space. For θ 1 , θ 2 ∈ Δ c ( X ) we define the relation θ 1 ⪯ θ 2 : ⟺ ∀ f : X → R + , f 1 -Lipschitz : θ 1 ( 1 + f ) ≤ θ 2 ( 1 + f ) . The space □ L ( X ) is defined as the set of closed convex subsets of Δ c ( X ) that are downward closed under the partial order ⪯ . To see that it achieves some of the desired behavior, we show that M ( ∧ ) is continuous in Lemma 14. This approach also requires that we work with compact metric spaces, instead of merely with compact polish spaces. We give some technical details in Standard setting for the alternative HUC case . Later we will look at alternatives, mostly to justify the choices made in Standard setting for the alternative HUC case . Standard setting for the alternative HUC case The Category of metric spaces is typically equipped with maps that are 1 -Lipschitz continuous, and the metric on a product X × Y of metric spaces X , Y is given by d X × Y ( ( x 1 , y 1 ) , ( x 2 , y 2 ) ) = max ( d X ( x 1 , x 2 ) , d Y ( y 1 , y 2 ) ) . We do make some further modifications. First, we only consider compact metric spaces whose metric d only has values in [ 0 , 1 ] . This allows us to consider sums/coproducts of metric spaces (usually the category of metric spaces does not have coproducts). For the metric on a sum (disjoint union) of two metric spaces, we set the distance of two points from different components to 1 . Let us define the metric we will use on □ L . As a metric on Δ c ( X ) we will use the Kantorovich-Rubenstein metric d ( p , q ) : = sup { | p ( g ) − q ( g ) | : g : X → [ − 1 , 1 ] 1 -Lipschitz } , which is a metric that is compatible with the weak- ∗ topology on Δ c ( X ) . Then we use the Hausdorff metric d H on □ L . It can be seen that this Hausdorff metric has values in [ 0 , 1 ] again. A problem with □ L ( X ) is that it is not always preserved under the pullback, i.e. f ∗ ( Θ ) ∉ □ L ( X ) can happen for some f : X → Y , Θ ∈ □ L ( Y ) . Thus, we will redefine the pullback in this context. For a function between metric spaces f : X → Y we define the modified pullback f ∗ L : □ L Y → □ L X via f ∗ L ( Θ ) : = { μ ∈ Δ c ( Y ) | ∃ ν ∈ f ∗ ( Θ ) : μ ⪯ ν } . We will use this alternative pullback for the case of □ L . Under this setting, we run into the issue that M ( ∧ ) is not 1 -Lipschitz continuous, see Example 16. This is despite the fact that M ( ∧ ) is continuous (and probably even Lipschitz continuous). Allow higher Lipschitz constants for maps One might wonder what happens, when we pick a higher Lipschitz constant c > 1 for maps in our category (instead of c = 1 ). If we have two functions with a Lipschitz constant c > 1 , then we can only guarantee a Lipschitz constant of c 2 for the composition (e.g. with the function [ 0 , 1 ] ∋ x ↦ min ( 1 , c x ) ∈ [ 0 , 1 ] ). If we repeat this argument, we cannot guarantee a finite Lipschitz constant, because c n → ∞ as n → ∞ . So, what happens if we have allow maps with Lipschitz constant 2 ? It turns out that then we run into issues with functoriality, as in Allowing Discontinuity . A concrete counterexample is described in Example 15. Another metric on products Instead of the choice for d X × Y in Standard setting for the alternative HUC case , we could consider using the metric d X × Y ( ( x 1 , y 1 ) , ( x 2 , y 2 ) ) = d X ( x 1 , x 2 ) + d Y ( y 1 , y 2 ) . A first problem with this choice is that this is incompatible with any finite bound on d , as is the case in Standard setting for the alternative HUC case . This issue can be avoided by considering extended metric spaces, which are metric spaces whose metric can take values in [ 0 , ∞ ] (in that case the distance between disjoint components in a sum is set to ∞ ). A more difficult problem with this approach would be that the diagonal map diag : X → X × X is not 1 -Lipschitz continuous for other natural choices of metric on products. We do need the diagonal map, see, e.g., Equality of functions . Modifying the definition of alternative HUCs We mention that as an extension, the definition for ⪯ in Definition 9 could be modified to include a constant c > 0 and use θ 1 ( c + f ) ≤ θ 2 ( c + f ) . For smaller c > 0 , this would make these alternative HUCs sharper. The version with c = 1 has some drawbacks as a lot of probability mass gets assigned to points nearby: For X = [ 0 , 1 ] , we have 1 2 δ 0 ⪯ δ 1 , so an alternative HUC which contains δ 1 also has to contain 1 2 δ 0 . In the context of infra-Bayesianism, this means we can use these kind of HUCs only in combination together with a smaller class of loss functions (in this case, loss functions that are of type 1 + f for a nonnegative Lipschitz continuous f ). One might wonder whether increasing c might help us decrease the Lipschitz constant for M ( ∧ ) or even choose a c > 1 such that M ( ∧ ) is 1 -Lipschitz. While the Lipschitz constant does get improved, calculating through Example 16 would show that the Lipschitz constant M ( ∧ ) cannot reach 1 even if we use these modified versions of □ L . Appendix Lemma 10 . If X is a compact Polish space then so is □ X . Proof. It is known that the space of nonempty compact subsets of X is compact in the Hausdorff metric. One can also show that □ X is a closed subset of the space of nonempty compact subsets of X . For the related concepts (but not HUCs) in IB theory, this result can also be found in Proposition 47 in "Less Basic Inframeasure Theory" ◻ Issues with Continuity Using the topology induced by the Hausdorff metric on □ X (see below Definition 2), we find that in the 'logical' semantics (inverse) limit type constructions (in the category theoretical sense) are generally not continuous (see Continuity Counterexamples for details). This includes the semantics for ∧ α , ∀ α β , and the pullback f ∗ . If X itself is finite, then □ X is nice enough that we don't run into these issues. This observation is sufficient for example in the construction of the infra-POMDPs in Examples when the state spaces are finite. However, we quickly run into issues if we're not careful with iterating the □ construction, since □ X is not finite even if X is. Below is some discussion on a possible approach to trying to fix these issues (we haven't found an entirely satisfactory fix though). Continuity Counterexamples Lemma 11 . The function M ( ∧ ) : □ M ( α ) × □ M ( α ) → □ M ( α ) , given by M ( ∧ ) ( μ , ν ) = μ ∩ ν is not always continuous. Proof. Consider the case where M ( α ) is the space [ 0 , 1 ] with standard topology. This is a Polish space. We consider sequences with x i = 1 / 2 − 1 / i and y i = 1 / 2 + 1 / i . We define x 0 = y 0 = 1 / 2 . Then ⊤ { x i } and ⊤ { y i } are in □ M ( α ) . (For a point z ∈ [ 0 , 1 ] , I understand this notation to be ⊤ { z } : = { a δ z ∣ a ∈ [ 0 , 1 ] } , where δ z ∈ Δ ( [ 0 , 1 ] ) is the measure that puts all weight on the single point z ). One can calculate that M ( ∧ ) ( ⊤ { x i } , ⊤ { y i } ) = ⊥ . Because of the Hausdorff metric in □ M ( α ) we have ⊤ { x i } → ⊤ { x 0 } and ⊤ { y i } → ⊤ { x 0 } . To put it together, we have lim M ( ∧ ) ( ⊤ { x i } , ⊤ { y i } ) = ⊥ ≠ ⊤ { x 0 } = M ( ∧ ) ( ⊤ { x 0 } , ⊤ { y 0 } ) = M ( ∧ ) ( lim ⊤ { x i } , lim ⊤ { y i } ) . Thus, M ( ∧ ) is not continuous. ◻ Lemma 12 . The function M ( ∀ α β ) is not always continuous. Proof. Consider the case that M ( α ) = M ( β ) = [ 0 , 1 ] . We use the notation f : = M ( ∀ α β ) . We choose the sequence μ n = ⊤ [ ( 0 , 0 ) , ( 1 , 1 / n ) ] , where [ , ] denotes the line between points. Then one can show that f ( μ n ) = ⊥ . However, we also have μ n → μ 0 : = ⊤ [ ( 0 , 0 ) , ( 1 , 0 ) ] . One can show that f ( μ 0 ) = ⊤ { 0 } ∈ □ M ( β ) holds. Thus, we have f ( μ n ) → ⊥ ≠ f ( μ 0 ) , i.e. f is not continuous. ◻ Lemma 13 . There is a continuous function f : X → Y such that f ∗ : □ Y → □ X is not continuous. Proof. Pick f : [ − 1 , 1 ] → [ 0 , 1 ] , f ( x ) = max ( 0 , x ) . Then f ∗ ( ⊤ { 1 / n } ) = ⊤ { 1 / n } , but for the limit we have f ∗ ( ⊤ { 0 } ) = ⊤ [ − 1 , 0 ] , and not ⊤ { 1 / n } → ⊤ [ − 1 , 0 ] . ◻ Semi-continuous Pullback is not Compositional Let f , g : [ 0 , 1 ] → [ 0 , 1 ] be given by g ( x ) = { 0 if x < 1 / 2 1 if x ≥ 1 / 2 , And f ( x ) = ⎧ ⎨ ⎩ 0 if x < 1 / 3 1 / 2 if 1 / 3 ≤ x < 2 / 3 1 if x ≥ 2 / 3. Both f and g are monotone increasing, upper semi-continuous. Let C = [ 0 , 1 / 2 ] ⊂ [ 0 , 1 ] . Then B = g − 1 ( C ) = [ 0 , 1 / 2 ) , the closure ¯ ¯¯ ¯ B = [ 0 , 1 / 2 ] . Hence f − 1 ( B ) = [ 0 , 1 / 3 ) , while f − 1 ( ¯ ¯¯ ¯ B ) = [ 0 , 2 / 3 ) , so ¯ ¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯ ¯ f − 1 ( ¯ ¯¯ ¯ B ) ≠ ¯ ¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯ ¯ f − 1 ( B ) . We can construct a corresponding counterexample where ( g ∘ f ) ∗ ≠ g ∗ ∘ f ∗ by considering Θ ∈ □ [ 0 , 1 ] , defined as follows. Let Θ = ⊤ C be the sharp HUC on C . Then g − 1 ∗ ( Θ ) = { ρ ∈ Δ c [ 0 , 1 ] : supp ( ρ ) ⊂ [ 0 , 1 / 2 ) } so g ∗ ( Θ ) = ¯ ¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯ ¯ g − 1 ∗ ( Θ ) = { ρ ∈ Δ c [ 0 , 1 ] : supp ( ρ ) ⊂ [ 0 , 1 / 2 ] } . Then ( g ∘ f ) ∗ ( Θ ) = { ρ ∈ Δ c [ 0 , 1 ] : supp ( ρ ) ⊂ [ 0 , 1 / 3 ] } , but ( f ∗ ∘ g ∗ ) ( Θ ) = f ∗ ( g ∗ ( Θ ) ) = { ρ ∈ Δ c [ 0 , 1 ] : supp ( ρ ) ⊂ [ 0 , 2 / 3 ] } , which is different. Stricter Homogeneity We collect some technical results for A Different Notion of HUCs With Definition 9 we can prove continuity for M ( ∧ ) , which does not hold for ordinary HUCs. Lemma 14 . The function M ( ∧ ) : □ L M ( α ) × □ L M ( α ) → □ L M ( α ) , given by M ( ∧ ) ( μ , ν ) = μ ∩ ν is continuous. Proof. We set X : = M ( α ) . As a metric on Δ c ( X ) we will use the Kantorovich-Rubenstein metric d ( p , q ) : = sup { | p ( g ) − q ( g ) | : g : X → [ − 1 , 1 ] 1 -Lipschitz } . (1) Let μ k , ν k be sequences in □ L ( X ) with μ k → μ 0 , ν k → ν 0 . We want to show that μ k ∩ ν k → μ 0 ∩ ν 0 . We have d H ( μ k ∩ ν k , μ 0 ∩ ν 0 ) ≤ sup p ∈ μ k ∩ ν k d ( p , μ 0 ∩ ν 0 ) + sup p ∈ μ 0 ∩ ν 0 d ( p , μ k ∩ ν k ) . (2) For the first term, let p k ∈ μ k ∩ ν k be such that d ( p k , μ 0 ∩ ν 0 ) is maximized. By compactness, there exists a convergent subsequence of p k . Wlog let p k → p 0 . We have p k ∈ μ k for all k , and taking limits implies p 0 ∈ μ 0 . The same argument also implies p 0 ∈ ν 0 . Thus, we have sup p ∈ μ k ∩ ν k d ( p , μ 0 ∩ ν 0 ) = d ( p k , μ 0 ∩ ν 0 ) → d ( p 0 , μ 0 ∩ ν 0 ) = 0. For the second term, let p 0 ∈ μ 0 ∩ ν 0 be given. Due to μ k → μ 0 , there exists a sequence p k with p k ∈ μ k and p k → p 0 . Similarly, there exists a sequence q k with q k ∈ ν k and q k → q 0 . The idea is now to construct a measure (i.e. a point in Δ c ( X ) ) r k that is close to p k and q k but in μ k ∩ ν k . Wlog we assume p 0 ( 1 ) > 0 and p k ( 1 ) > 0 , q k ( 1 ) > 0 for all k . We define δ k > 0 via δ k : = d ( p k , q k ) ( 2 + diam X ) ( p k + q k ) ( 1 ) , where diam X : = sup x , y ∈ X d ( x , y ) is the diameter of X . Clearly, we have δ k → 0 . We also define r k : = 1 − δ k 2 ( q k + p k ) . We want to show r k ⪯ q k and r k ⪯ p k . By symmetry we only need to show r k ⪯ p k . For that purpose, let f : X → R + be an arbitrary 1 -Lipschitz continuous function. We define g : = 1 + f . We have to show r k ( g ) ≤ p k ( g ) . We can decompose g = g min + g 0 , where g min : = min x ∈ X g ( x ) is a constant, and g 0 is a nonnegative function that satisfies g 0 ( x 0 ) = 0 for some x 0 ∈ X . Since g 0 is 1 -Lipschitz continuous, this implies that g 0 ( x ) ≤ diam X for all x ∈ X . Thus, ( 1 + diam X ) − 1 g 0 is a function that is 1 -Lipschitz continuous and bounded by 1 , i.e. admissible in the definition Eqn. (1). We can use this to obtain ( q k − p k ) ( g 0 ) = ( 1 + diam X ) ( q k − p k ) ( ( 1 + diam X ) − 1 g 0 ) ≤ ( 1 + diam X ) d ( q k , p k ) ≤ d ( p k , q k ) ( 1 + diam X ) ( p k + q k ) ( 1 ) ( p k + q k ) ( g ) . On the other hand, we have ( q k − p k ) ( g min ) = g min ( q k − p k ) ( 1 ) ≤ g min d ( p k , q k ) ≤ d ( p k , q k ) ( p k + q k ) ( 1 ) ( p k + q k ) ( g min ) ≤ d ( p k , q k ) ( p k + q k ) ( 1 ) ( p k + q k ) ( g ) Adding these yields ( q k − p k ) ( g ) = ( q k − p k ) ( g min + g 0 ) ≤ d ( p k , q k ) ( 1 + diam X + 1 ) ( p k + q k ) ( 1 ) ( p k + q k ) ( g ) = δ k ( p k + q k ) ( g ) . If we rearrange this inequality, we get ( 1 − δ k ) ( p k + q k ) ( g ) ≤ 2 p k ( g ) . Dividing by 2 yields r k ( g ) ≤ q k ( g ) , Since g = f + 1 and f ≥ 0 was an arbitrary 1 -Lipschitz function this proves r k ⪯ p k . Since p k ∈ μ k and μ k is downwards closed wrt ⪯ , this implies r k ∈ μ k . Similarly, we can obtain r k ⪯ q k and r k ∈ ν k . From the definition of r k we also obtain r k → p 0 (due to p k → p 0 and q k → q 0 ). Thus we have d ( p 0 , μ k ∩ ν k ) ≤ d ( p 0 , r k ) + d ( r k , μ k ∩ ν k ) = d ( p 0 , r k ) + 0 → 0 as k → ∞ . Since p 0 ∈ μ 0 ∩ ν 0 was arbitrary, this implies that the right-hand side in Eqn. (2) converges to 0 . This implies μ k ∩ ν k → μ 0 ∩ ν 0 in the Hausdorff metric, which completes the proof. ◻ In the next we will use the notation f ∗ L for the modified pullback, see Standard setting for the alternative HUC case . Example 15 . Consider X = [ 0 , 1 ] as a compact metric space with the usual metric. Further, let f , g : X → X be given by f ( x ) = min ( 2 x , 1 ) , g ( x ) = x / 2 for all x ∈ [ 0 , 1 ] . Then g ∗ L ∘ f ∗ L ≠ ( f ∘ g ) ∗ L , i.e. functoriality does not hold. Proof. Clearly, we have ( f ∘ g ) ( x ) = x for all x ∈ [ 0 , 1 ] . We define Θ 0 : = { μ ∈ Δ c ( [ 0 , 1 ] ) : μ ⪯ δ 0 } . We claim that ( g ∗ L ∘ f ∗ L ) ( Θ 0 ) ≠ ( f ∘ g ) ∗ L ( Θ 0 ) holds. Due to ( f ∘ g ) ( x ) = x for all x ∈ [ 0 , 1 ] this simplifies to ( g ∗ L ∘ f ∗ L ) ( Θ 0 ) ≠ Θ 0 . (3) We start by observing δ 0 ∈ Θ 0 and δ 0 ∈ f ∗ L ( Θ 0 ) . We also claim 3 4 δ 1 / 3 ⪯ δ 0 . Indeed, for 1 -Lipschitz continuous h : [ 0 , 1 ] → R + we have 3 4 δ 1 / 3 ( 1 + h ) = 3 4 ( 1 + h ( 1 3 ) ) ≤ 3 4 ( 1 + h ( 0 ) + 1 3 ) = 3 4 ( 4 3 + h ( 0 ) ) ≤ 1 + h ( 0 ) = δ 0 ( 1 + h ) . Due to δ 0 ∈ f ∗ L ( Θ 0 ) ∈ □ L [ 0 , 1 ] this implies 3 4 δ 1 / 3 ∈ f ∗ L ( Θ 0 ) . Due to g ( 2 / 3 ) = 1 / 3 we have g ∗ ( 3 4 δ 2 / 3 ) = 3 4 δ 1 / 3 . This implies 3 4 δ 2 / 3 ∈ g ∗ ( f ∗ L ( Θ 0 ) ) ⊂ ( g ∗ L ∘ f ∗ L ) ( Θ 0 ) . However, we can also show that 3 4 δ 2 / 3 ∉ Θ 0 . Indeed, lets consider the 1 -Lipschitz continuous function h ( x ) = x . Then 3 4 δ 2 / 3 ( 1 + h ) = 3 4 ( 1 + 2 / 3 ) = 5 / 4 ≰ 1 = δ 0 ( 1 + h ) . Thus 3 4 δ 2 / 3 ∉ Θ 0 . This completes the proof of Eqn. (3) and hence completes the proof of the lemma. ◻ Example 16 . Let X = { 0 , 1 } be the compact metric space where the metric satisfies d ( 0 , 1 ) = 1 . We use the standard setting from Standard setting for the alternative HUC case otherwise. Then the function M ( ∧ ) : □ L M ( α ) × □ L M ( α ) → □ L M ( α ) , given by M ( ∧ ) ( Θ 1 , Θ 2 ) = Θ 1 ∩ Θ 2 is not 1 -Lipschitz continuous. Proof. Consider the measures μ 0 = 1 2 δ 0 , μ 1 = 1 2 δ 1 , μ 2 = 1 2 δ 0 + 1 2 δ 1 . Let Θ i be the smallest set in □ L that contains μ i , for i = 0 , 1 , 2 . Then it can be calculated that Θ 0 = { α 0 δ 0 + α 1 δ 1 ∣ α 0 + 2 α 1 ≤ 1 2 , α 0 , α 1 ≥ 0 } , Θ 1 = { α 0 δ 0 + α 1 δ 1 ∣ 2 α 0 + α 1 ≤ 1 2 , α 0 , α 1 ≥ 0 } , Θ 2 = { α 0 δ 0 + α 1 δ 1 ∣ 2 α 0 + α 1 ≤ 3 2 , α 0 + 2 α 1 ≤ 3 2 , α 0 , α 1 ≥ 0 } . We want to calculate d H ( Θ 2 , Θ 0 ) . Due to Θ 0 ⊂ Θ 2 , we have d H ( Θ 2 , Θ 0 ) = sup μ ∈ Θ 2 d ( μ , Θ 0 ) . Since the supremum of a convex function is attained on extremal points, we only need to consider d ( μ , Θ 0 ) for the case that μ is an extremal point of Θ 2 . The extremal points of Θ 2 are μ 2 = 1 2 δ 0 + 1 2 δ 1 , 3 4 δ 0 , 3 4 δ 1 , 0 . Let us calculate the distances (or bounds on distances) of these points to Θ 0 . We start with μ 2 . We observe 1 2 δ 0 ∈ Θ 0 . This implies d ( μ 2 , Θ 0 ) ≤ d ( μ 2 , 1 2 δ 0 ) = sup { | μ 2 ( g ) − 1 2 δ 0 ( g ) | : g : X → [ − 1 , 1 ] 1 -Lipschitz } = sup { | 1 2 δ 1 ( g ) | : g : X → [ − 1 , 1 ] 1 -Lipschitz } = 1 2 . On the other hand, we have μ 2 ( 1 ) = 1 and μ ( 1 ) ≤ 1 2 for all μ ∈ Θ 0 . Since 1 is admissible in Eqn. (1), this implies d ( μ 2 , μ ) ≥ 1 2 for all μ ∈ Θ 0 , and therefore d ( μ 2 , Θ 0 ) ≥ 1 2 . Thus, d ( μ 2 , Θ 0 ) = 1 2 . Next, we calculate a bound on d ( 3 4 δ 0 , Θ 0 ) . As we have 1 2 δ 0 ∈ Θ 0 , we obtain d ( 3 4 δ 0 , Θ 0 ) ≤ d ( 3 4 δ 0 , 1 2 δ 0 ) = sup { | 3 4 δ 0 ( g ) − 1 2 δ 0 ( g ) | : g : X → [ − 1 , 1 ] 1 -Lipschitz } = sup { | 1 4 δ 0 ( g ) | : g : X → [ − 1 , 1 ] 1 -Lipschitz } = 1 4 . Similarly, for a bound on d ( 3 4 δ 1 , Θ 0 ) , we observe 1 4 δ 1 ∈ Θ 0 and calculate d ( 3 4 δ 1 , Θ 0 ) ≤ d ( 3 4 δ 1 , 1 4 δ 1 ) = sup { | 3 4 δ 1 ( g ) − 1 4 δ 1 ( g ) | : g : X → [ − 1 , 1 ] 1 -Lipschitz } = sup { | 1 2 δ 1 ( g ) | : g : X → [ − 1 , 1 ] 1 -Lipschitz } = 1 2 . Finally, d ( 0 , Θ 0 ) = 0 holds due to 0 ∈ Θ 0 . In summary, we have shown for all extremal points of Θ 2 that the distances to Θ 0 do not exceed 1 2 (and obtain the value 1 2 in at least one case). This implies d H ( Θ 2 , Θ 0 ) = 1 2 . By symmetry we also have d ( Θ 2 , Θ 1 ) = 1 2 . Now, let us consider the intersection Θ 0 ∩ Θ 1 . Using the above descriptions for Θ 0 and Θ 1 we can obtain the subset relation Θ 0 ∩ Θ 1 ⊂ { α 0 δ 0 + α 1 δ 1 ∣ α 0 + α 1 ≤ 1 3 , α 0 , α 1 ≥ 0 } = { μ ∈ Δ c ( X ) ∣ μ ( 1 ) ≤ 1 3 } . This implies μ ( 1 ) ≤ 1 3 for all μ ∈ Θ 0 ∩ Θ 1 . Recall that we have μ 2 ∈ Θ 2 and μ 2 ( 1 ) = 1 . By using g = 1 in Eqn. (1), it follows that d ( μ 2 , μ ) ≥ 1 − 1 3 = 2 3 for all μ ∈ Θ 0 ∩ Θ 1 . Thus, d ( Θ 2 , Θ 0 ∩ Θ 1 ) ≥ d ( μ 2 , Θ 0 ∩ Θ 1 ) = inf { d ( μ 2 , μ ) : μ ∈ Θ 0 ∩ Θ 1 } ≥ 2 3 . Combining all these results shows d H ( Θ 2 ∩ Θ 2 , Θ 0 ∩ Θ 1 ) ≥ 2 3 > 1 2 = max ( d H ( Θ 2 , Θ 0 ) , d ( Θ 2 , Θ 1 ) ) = d ( ( Θ 2 , Θ 2 ) , ( Θ 0 , Θ 1 ) ) , which shows that the Lipschitz constant has to be at least 3 2 > 1 . ◻ Measurability and Continuity Proofs Let us collect proofs that some maps between compact Polish spaces that are mentioned in Semantics are indeed measurable, as required. This concerns M ( ∃ α β ) , M ( ∀ α β ) , M ( ∨ α ) , M ( ∧ α ) . Lemma 17 . The function M ( ∨ ) : □ M ( α ) × □ M ( α ) is continuous and measurable. Proof. Let X : = M ( α ) and f : = M ( ∨ ) . Recall that f ( μ , ν ) : = conv ( μ ∪ ν ) . Let μ n , ν n ∈ □ X be sequences with μ n → μ 0 and ν n → ν 0 . We need to show f ( μ n , ν n ) → f ( μ 0 , ν 0 ) for continuity. We do this by showing two things: First, every limmit z 0 of a convergent sequence z n with z n ∈ f ( μ n , ν n ) satisfies z 0 ∈ f ( μ 0 , ν 0 ) . Second, for every point z 0 ∈ f ( μ 0 , ν 0 ) there exists a sequence z n with z n ∈ f ( μ n , ν n ) . So, first, let z n be a sequence with z n ∈ f ( μ n , ν n ) and z n → z 0 . We have z n ∈ conv ( μ n ∪ ν n ) , and thus there exists x n ∈ μ n , y n ∈ ν n , α n ∈ [ 0 , 1 ] with z n = α n x n + ( 1 − α n ) y n . Wlog we have convergences x n → x 0 ∈ μ 0 , y n → y 0 ∈ ν 0 , α n → α 0 ∈ [ 0 , 1 ] . This implies z 0 = α 0 x 0 + ( 1 − α 0 ) y 0 ∈ conv ( μ 0 ∪ ν 0 ) . For the other part, let z 0 ∈ f ( μ 0 , ν 0 ) be given. Thus, there exist x 0 ∈ μ 0 , y 0 ∈ μ 0 , α 0 ∈ [ 0 , 1 ] with z 0 = α 0 x 0 + ( 1 − α 0 ) y 0 . Due to μ n → μ 0 and ν n → ν 0 there exist sequences with x n , y n with x n ∈ μ n , y n ∈ ν n , and x n → x 0 , y n → y 0 . Then, we have z n : = α 0 x n + ( 1 − α 0 ) y n ∈ conv ( μ n ∪ ν n ) . Taking limits implies z n → z 0 . This completes the proof of continuity of f . ◻ Lemma 18 . If f : X → Y is a continuous function between compact Polish spaces, then f ∗ : □ X → □ Y is continuous. In particular, the function M ( ∃ α β ) = pr M ( β ) ∗ is continuous and measurable. Proof. Let μ k be a sequence in □ ( X × Y ) with μ k → μ 0 ∈ □ ( X × Y ) . We want to show f ∗ ( μ k ) → f ∗ ( μ 0 ) . As before, we do this by showing two things. First, every convergent sequence p k ∈ f ∗ ( μ k ) with p k → p 0 implies p 0 ∈ f ∗ ( μ 0 ) . Second, for every point p 0 ∈ f ∗ ( μ 0 ) we can find a sequence p k with p k → p 0 and p k ∈ f ∗ ( μ k ) . Note that f ∗ : Δ c ( X ) → Δ c ( Y ) is continuous if f is continuous. Let p k ∈ f ∗ ( μ k ) be a convergent sequence with p k → p 0 . Then there exists q k ∈ μ k with p k = f ∗ ( q k ) . Wlog q k → q 0 for some q 0 due to compactness. This implies f ∗ ( q k ) → f ∗ ( q 0 ) and q 0 ∈ μ 0 . Due to uniqueness of the limit, we have f ∗ ( q 0 ) = p 0 and therefore the desired p 0 ∈ f ∗ ( μ 0 ) . For the remaining part, let p 0 ∈ f ∗ ( μ 0 ) be given. Then there exists q 0 ∈ μ 0 with p 0 = f ∗ ( q 0 ) . Since μ k → μ 0 , there exists a sequence q k with q k ∈ μ k and q k → q 0 . We define p k : = f ∗ ( q k ) . Then we have p k → f ∗ ( q 0 ) = p 0 and p k ∈ f ∗ ( μ k ) . This completes the proof. ◻ Lemma 19 . The function M ( ∧ ) : □ M ( α ) × □ M ( α ) → □ M ( α ) , given by M ( ∧ ) ( μ , ν ) = μ ∩ ν is measurable. Proof. We use the abbreviation X : = M ( α ) , and use the notation d ( ⋅ , ⋅ ) for the metric on Δ c ( X ) and d H ( ⋅ , ⋅ ) for the induced Hausdorff metric on □ X . To show measurability, it suffices to show that the preimages of open balls are measurable. Thus, we need to show that { ( A , B ) ∈ ( □ X ) 2 : d H ( A ∩ B , C ) < ε } is measurable for all C ∈ □ X and ε > 0 . First, we show an auxiliary claim. Claim 1 : Let D ⊂ X be a compact subset. Then ⋃ y ∈ D { ( A , B ) : y ∈ A ∩ B } is closed and measurable. Let us show that the claim is true. Let ( A k , B k ) be a sequence in the set with d H ( A k , A ) → 0 , d H ( B k , B ) → 0 . Then there exists y k ∈ D with y k ∈ A and y k ∈ B . Wlog y k → y for some y ∈ D (because of convergent subsequences). Then d H ( A , y ) = lim d H ( A k , y k ) = 0 and thus y ∈ A . Similar, y ∈ B . Thus, the limit ( A , B ) of ( A k , B k ) is in the set ⋃ y ∈ D { ( A , B ) : y ∈ A ∩ B } . Thus, the set is closed and measurable. We have { ( A , B ) : d H ( A ∩ B , C ) < ε } = { ( A , B ) : ∀ x ∈ A ∩ B : d ( x , C ) < ε } ∩ { ( A , B ) : ∀ x ∈ C : d ( A ∩ B , x ) < ε } . Let us show measurability of { ( A , B ) : ∀ x ∈ C : d ( A ∩ B , x ) < ε } . We have { ( A , B ) : ∀ x ∈ C : d ( A ∩ B , x ) < ε } = ⋃ δ ∈ ( 0 , ε ) ∩ Q { ( A , B ) : ∀ x ∈ C : d ( A ∩ B , x ) ≤ δ } = ⋃ δ ∈ ( 0 , ε ) ∩ Q ⋂ x ∈ C { ( A , B ) : d ( A ∩ B , x ) ≤ δ } = ⋃ δ ∈ ( 0 , ε ) ∩ Q ⋂ x ∈ C ⋃ y : d ( y , x ) ≤ δ { ( A , B ) : y ∈ A ∩ B } For each δ ∈ ( 0 , ε ) ∩ Q , x ∈ C , the set ⋃ y : d ( y , x ) ≤ δ { ( A , B ) : y ∈ A ∩ B } is closed due to claim 1, because { y : d ( y , x ) ≤ δ } is a compact set. Recall that intersections of closed sets are closed. Thus, the set in question is the countable union of closed sets, and therefore measurable. Now, let us show the measurability of { ( A , B ) : ∀ x ∈ A ∩ B : d ( x , C ) < ε } . We have { ( A , B ) : ∀ x ∈ A ∩ B : d ( x , C ) < ε } = { ( A , B ) : ∀ x : d ( x , C ) ≥ ε ⟹ x ∉ A ∩ B } = ⋂ x : d ( x , C ) ≥ ε { ( A , B ) : x ∉ A ∩ B } = ( □ X ) 2 ∖ ⎛ ⎝ ⋃ x : d ( x , C ) ≥ ε { ( A , B ) : x ∈ A ∩ B } ⎞ ⎠ . Again, since the set { x : d ( x , C ) ≥ ε } is compact, it follows that the above set is measurable by claim 1. This completes the proof that { ( A , B ) : d H ( A ∩ B , C ) < ε } is measurable. ◻ Lemma 20 . Let X , Y be compact metric spaces, q 0 ∈ Δ ( X × Y ) and p 1 ∈ Δ ( Y ) be given. Then there exists q 1 ∈ Δ ( X × Y ) with pr Y ∗ q 1 = p 1 and W 1 ( q 0 , q 1 ) ≤ W 1 ( pr Y ∗ q 0 , p 1 ) , where W 1 is the Wasserstein metric . Proof. We set p 0 : = pr Y ∗ q 0 ∈ Δ ( Y ) . In the following, we will also use the notation pr i : Y × Y → Y , pr i ( x ) = x i for i = 1 , 2 . Then, due to the definition of W 1 , there exists a measure μ ∈ Δ ( Y × Y ) with pr 1 ∗ μ = p 0 , pr 2 ∗ μ = p 1 , μ ( d Y ) = W 1 ( p 0 , p 1 ) (due to compactness arguments, the infimum is attained in the definition of W 1 ). We choose a measure ν ∈ Δ ( X × Y × X × Y ) via ν ( A × B × C × D ) = ∫ B q 0 ( A ∩ C | y ) ^ μ ( D | y ) d p 0 ( y ) , where y ↦ q 0 ( ^ A | y ) denotes a density function that satisfies q 0 ( ^ A × ^ B ) = ∫ ^ B q 0 ( A | y ) d p 0 ( y ) for all measurable ^ A ⊂ X , ^ B ⊂ Y , and y ↦ ^ μ ( D | y ) is the same for the "mirrored" measure ^ μ of μ , i.e. μ ( ^ B × D ) = ∫ ^ B ^ μ ( D | y ) , d p 0 ( y ) for all measurable ^ B ⊂ Y . These density functions exist due to Radon-Nikodym. The measure ν exists due to Caratheodory's theorem and is unique. The measure ν has the properties pr 4 ∗ ν = p 1 , pr 12 ∗ ν = q 0 , pr 24 ∗ ν = μ , pr 13 ∗ ν = diag X ∗ pr 1 ∗ q 0 , where pr i j is map that projects on components i and j , and diag X ∗ : X → X × X is the diagonal map. We now choose q 1 : = pr 34 ∗ ν ∈ Δ ( X × Y ) . Indeed, this satisfies the desired property pr Y ∗ q 1 = p 1 . As for the Wasserstein metric, ν ( d X × Y ) is an upper bound on W 1 ( q 0 , q 1 ) . Let us calculate ν ( d X × Y ) . We have ν ( d X × Y ) = ∫ d X ( x 1 , x 2 ) + d Y ( y 1 , y 2 ) d ν ( x 1 , y 1 , x 2 , y 2 ) = ∫ d X ( x 1 , x 2 ) d ν ( x 1 , y 1 , x 2 , y 2 ) + ∫ d Y ( y 1 , y 2 ) d ν ( x 1 , y 1 , x 2 , y 2 ) = ∫ d X ( x 1 , x 2 ) d ( diag X ∗ pr 1 ∗ q 0 ) ( x 1 , x 2 ) + ∫ d Y ( y 1 , y 2 ) d μ ( y 1 , y 2 ) = ∫ d X ( x 1 , x 1 ) d ( pr 1 q 0 ) ( x 1 ) + μ ( d Y ) = 0 + μ ( d Y ) = W 1 ( p 0 , p 1 ) . This implies W 1 ( p 0 , p 1 ) ≤ W 1 ( q 0 , q 1 ) , which completes the proof. ◻ Lemma 21 . The function M ( ∀ α β ) is measurable. Proof. We abbreviate X = M ( α ) , Y = M ( β ) , f = M ( ∀ α β ) . Again, we use the notation d ( ⋅ , ⋅ ) for a metric on Δ c ( X ) or Δ c ( Y ) and d H ( ⋅ , ⋅ ) for the induced Hausdorff metric. Again, we start with an auxiliary claim. Claim 2 : Let D ⊂ Y be a compact subset. Then ⋃ p ∈ D { B ∈ □ ( X × Y ) : p ∈ f ( B ) } is closed and measurable. Let us show that the claim is true. Note, that the set is the same as ⋃ p ∈ D { B ∈ □ ( X × Y ) : ∀ q ∈ Δ c ( X × Y ) : pr Y ∗ q = p ⟹ q ∈ B } . Let B k be a sequence in the set with B k → B 0 . That means, there is a sequence p k with p k ∈ D and ∀ q ∈ Δ c ( X × Y ) : pr Y ∗ q = p k ⟹ q ∈ B k } . Since D is compact, we can wlog assume that p k → p 0 ∈ D (by selecting a convergent subsequence). Let q 0 ∈ Δ c ( X × Y ) be given with p r Y ∗ q 0 = p 0 . We need to show that q 0 ∈ B 0 holds (this would show that B 0 is in the set mentioned in the claim, i.e. it would prove the claim). Wlog q 0 ( X × Y ) > 0 (otherwise q 0 ∈ B 0 follows from definition). This implies p 0 ( Y ) > 0 , which allows us to wlog assume that p k ( Y ) > 0 for all k ∈ N . Let us define the probability measures ^ q 0 : = p 0 ( Y ) − 1 p 0 ∈ Δ ( X × Y ) , ^ p 0 : = p 0 ( Y ) − 1 p 0 ∈ Δ ( Y ) , ^ p k : = p k ( Y ) − 1 p k ∈ Δ ( Y ) . We can apply Lemma 20 to these probability measures, which implies that there exists ^ q k ∈ Δ ( X × Y ) with pr Y ∗ ^ q k = ^ p k and W 1 ( ^ q 0 , ^ q k ) ≤ W 1 ( ^ p 0 , ^ p k ) . It is known that the Wasserstein metric W 1 is compatible with the weak- ∗ topology on Δ ( X × Y ) and Δ ( Y ) . Thus, we obtain W 1 ( ^ p 0 , ^ p k ) → 0 from ^ p k → ^ p 0 . This, in turn, implies ^ q k → ^ q 0 . Next, we define q k : = p k ( Y ) ^ q k ∈ Δ c ( X × Y ) . This satisfies q k → q 0 and pr Y ∗ q k = p k . Due to the properties of p k and B k , this implies q k ∈ B k . Now the desired property q 0 ∈ B 0 follows by taking limits. This completes the proof of the claim. To show measurability of f = M ( ∀ α β ) , it suffices to show that the preimages of open balls are measurable. Thus, we need to show that { B ∈ □ ( X × Y ) : d H ( f ( B ) , A ) < ε } is measurable for all A ∈ □ Y and ε > 0 . We proceed similarly to Lemma 19. We have { B ∣ d H ( f ( B ) , A ) < ε } = { B ∣ ∀ x ∈ f ( B ) : d ( x , A ) < ε } ∩ { B ∣ ∀ x ∈ A : d ( f ( B ) , x ) < ε } . Let us start by showing measurability of the second set, i.e. { B ∣ ∀ x ∈ A : d ( f ( B ) , x ) < ε } . Since A is compact, there exists a countable dense set A 1 ⊂ A . We have { B ∣ ∀ x ∈ A : d ( f ( B ) , x ) < ε } = ⋃ δ ∈ ( 0 , ε ) ∩ Q { B ∣ ∀ x ∈ A : d ( f ( B ) , x ) ≤ δ } = ⋃ δ ∈ ( 0 , ε ) ∩ Q { B ∣ ∀ x ∈ A : d ( f ( B ) , x ) ≤ δ } = ⋃ δ ∈ ( 0 , ε ) ∩ Q ⋂ x ∈ A { B ∣ d ( f ( B ) , x ) ≤ δ } = ⋃ δ ∈ ( 0 , ε ) ∩ Q ⋂ x ∈ A ⋃ y : d ( x , y ) ≤ δ { B ∣ y ∈ f ( B ) } . Applying claim 2 for the compact set { y : d ( y , x ) ≤ δ } . Thus, we have a countable union of an intersection of closed sets. This is measurable. Now, let us show the measurability of the other set { B ∣ ∀ x ∈ f ( B ) : d ( x , A ) < ε } . We have { B ∣ ∀ x ∈ f ( B ) : d ( x , A ) < ε } = { B ∣ ∀ x : d ( x , A ) ≥ ε ⟹ x ∉ f ( B ) } = ⋂ x : d ( x , A ) ≥ ε { B ∣ x ∉ f ( B ) } = □ ( X × Y ) ∖ ⎛ ⎝ ⋃ x : d ( x , A ) ≥ ε { B ∣ x ∈ f ( B ) } ⎞ ⎠ . Again, since the set { x : d ( x , A ) ≥ ε } is compact, claim 2 implies that the above set is measurable. This completes the proof that { B ∈ □ ( X × Y ) : d H ( f ( B ) , A ) < ε } is measurable. ◻ As for the measurability of M ( f ) ∗ , we were not able to prove it for measurable f . There might be some relation to the problem that the image of a measurable set under a measurable map is not measurable.