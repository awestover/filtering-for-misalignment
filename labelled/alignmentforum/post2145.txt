This post is an appendix to " Infra-Bayesian physicalism: a formal theory of naturalized induction ". Lemma 1: pr Γ × Φ ( χ y ∈ α ( s ∗ ( θ ) ) ) ∈ Θ occurs for all s : Γ → Γ iff, for all g : Γ × Φ → [ 0 , 1 ] and s : Γ → Γ , θ ( λ y α x . χ s ( y ) ∈ α g ( s ( y ) , x ) ) ≤ Θ ( λ y x . g ( y , x ) ) This lemma will be implicitly used all over the place, in order to deal with the "presence in the bridge transform" condition algebraically, in terms of function expectations. The bulk of the conditions for a contribution to lie in the bridge transform is this endofunction condition (the support condition is trivial most of the time), so it's advantageous to reformulate it. First-off, we have that pr Γ × Φ ( χ y ∈ α ( s ∗ ( θ ) ) ) ∈ Θ iff, for all g : Γ × Φ → [ 0 , 1 ] , we have pr Γ × Φ ( χ y ∈ α ( s ∗ ( θ ) ) ) ( λ y x . g ( y , x ) ) ≤ Θ ( λ y x . g ( y , x ) ) By LF-duality for ultradistributions, proved in Less Basic Inframeasure theory. A contribution lies in an ultracontribution set iff its expectations, w.r.t. all functions, are less than or equal to the ultracontribution expectations. Now, we just need to unpack the left-hand-side into our desired form. Start off with pr Γ × Φ ( χ y ∈ α ( s ∗ ( θ ) ) ) ( λ y x . g ( y , x ) ) Apply how projections work = χ y ∈ α ( s ∗ ( θ ) ) ( λ y α x . g ( y , x ) ) Now, we can move the indicator function into the function we're taking the expectation again, because there's no difference between deleting all measure outside of an event, or taking the expectation of a function that's 0 outside of that event. So, we get = s ∗ ( θ ) ( λ y α x . χ y ∈ α g ( y , x ) ) Then we use how pushforwards are defined in probability theory. = θ ( λ y α x . χ s ( y ) ∈ α g ( s ( y ) , x ) ) And that's our desired form. So, we've shown that for any particular s : Γ → Γ , we have pr Γ × Φ ( χ y ∈ α ( s ∗ ( θ ) ) ) ∈ Θ iff, for all g : Γ × Φ → [ 0 , 1 ] , θ ( λ y α x . χ s ( y ) ∈ α g ( s ( y ) , x ) ) ≤ Θ ( λ y x . g ( y , x ) ) And so, we get our desired iff statement by going from the iff for one s to the iff for all s . ■ Proposition 2.1: For any Γ , Φ and Θ ∈ □ c ( Γ × Φ ) , Br ( Θ ) exists and satisfies pr Γ × Φ Br ( Θ ) = Θ .
In particular, if Θ ∈ □ ( Γ × Φ ) then Br ( Θ ) ∈ □ ( el Γ × Φ ) . Proof sketch: We'll show that for any particular contribution in θ ∈ Θ , there's a contribution θ ∗ which lies within Br ( Θ ) that projects down to equal θ . And then, show the other direction, that any contribution in Br ( Θ ) lands within Θ when you project it down. Thus, the projection of Br ( Θ ) must be Θ exactly. For the first direction, given some θ ∈ Θ , let θ ∗ : = θ ⋉ ( λ y . { y } ) . Note that since θ ∈ Δ c ( Γ × Φ ) , this means that θ ∗ ∈ Δ c ( Γ × 2 Γ × Φ ) , so the type signatures line up. Clearly, projecting θ ∗ down to Γ × Φ makes θ again. So that leaves showing that θ ∗ ∈ Br ( Θ ) . Applying Lemma 1, an equivalent way of stating the bridge transform is that it consists precisely of all the θ ′ ∈ Δ c ( Γ × 2 Γ × Φ ) s.t. for all s : Γ → Γ and g : Γ × Φ → [ 0 , 1 ] , θ ′ ( λ y α x . χ s ( y ) ∈ α g ( s ( y ) , x ) ) ≤ Θ ( λ y x . g ( y , x ) ) and also, supp θ ′ ⊆ el Γ × Φ . Clearly, for our given θ ∗ , everything works out with the support condition, so that leaves the endofunction condition. Let s , g be arbitrary. θ ∗ ( λ y α x . χ s ( y ) ∈ α g ( s ( y ) , x ) ) = ( θ ⋉ ( λ y . { y } ) ) ( λ y α x . χ s ( y ) ∈ α g ( s ( y ) , x ) ) = θ ( λ y x . δ { y } ( λ α . χ s ( y ) ∈ α g ( s ( y ) , x ) ) ) = θ ( λ y x . χ s ( y ) ∈ { y } g ( s ( y ) , x ) ) = θ ( λ y x . χ s ( y ) = y g ( s ( y ) , x ) ) = θ ( λ y x . χ s ( y ) = y g ( y , x ) ) ≤ θ ( λ y x . g ( y , x ) ) ≤ max θ ∈ Θ θ ( λ y x . g ( y , x ) ) = Θ ( λ y x . g ( y , x ) ) In order, the equalities were unpacking the semidirect product, substituting the dirac-delta in, reexpressing the condition for the indicator function, using that s ( y ) = y inside the indicator function, applying monotonicity of θ , using that θ ∈ Θ , and then packing up the definition of Θ .
And that inequality has been fulfilled, so, yes, θ ∗ lies within Br ( Θ ) . Since θ was arbitrary within Θ , this shows that the projection set is as-big-or-bigger than Θ . Now to show the reverse direction, that anything in the projection set lies within Θ . For any particular θ ′ ∈ Θ , remember, it must fulfill, for all g , s , that θ ′ ( λ y α x . χ s ( y ) ∈ α g ( s ( y ) , x ) ) ≤ Θ ( λ y x . g ( y , x ) ) So, in particular, we can let s : Γ → Γ be the identity function, and g be anything, and we'd get θ ′ ( λ y α x . χ y ∈ α g ( y , x ) ) ≤ Θ ( λ y x . g ( y , x ) ) And, since θ ′ is in Br ( Θ ) , it's supported on the ( y , α ) pairs s.t. y ∈ α , so that indicator function drops out of existence, and we get θ ′ ( λ y α x . g ( y , x ) ) ≤ Θ ( λ y x . g ( y , x ) ) And then this can be written as a projection pr Γ × Φ ( θ ′ ) ( λ y x . g ( y , x ) ) ≤ Θ ( λ y x . g ( y , x ) ) And since this holds for all the various g , this means that pr Γ × Φ ( θ ′ ) ∈ Θ And we're done with the other direction of things, the projection must be exactly equal to Θ since projections of contributions in Br ( Θ ) always land in Θ , and we can surject onto Θ . ■ Proposition 2.2: Let X be a poset, θ , η ∈ Δ c X .
Then, θ ⪯ η if and only if there exists κ : X → Δ X s.t.:
For all x ∈ X , y ∈ supp κ ( x ) : x ≤ y . κ ∗ θ ≤ η Vanessa proved this one, with a very nice proof involving the max-flow min-cut theorem. Make the following directed graph: The nodes are the elements of { s } ∪ { t } ∪ X × { 0 , 1 } . Basically, two copies of the finite poset X , a source node s , and a sink node t . x will be used to denote a variable from X , while a subscript of 0 or 1 denotes that the 0 or 1 version of that x , respectively. As for the edges, there is an edge from s to every point in X 0 . And an edge from every point in X 1 to t . And, for some x 0 ∈ X 0 and y 1 ∈ X 1 , there's an edge iff x ≤ y . The capacities of the edges are, for all x ∈ X , c s , x 0 : = θ ( x ) , and for all x ∈ X , c x 1 , t : = η ( x ) , and for x , y ∈ X s.t. x ≤ y , c x 0 , y 1 : = ∞ . To work up to applying min-cut max-flow, we must show that the cut of all the edges between s and X 0 is a min-cut of the network. Remember, all cuts are induced by partitions of the nodes into two sets, S and T , where S includes the source s and T includes the sink t . And the value of a cut is c ( S , T ) = ∑ a ∈ S , b ∈ T c a , b = ∑ x 0 ∈ T c s , x 0 + ∑ x 0 ∈ S , y 1 ∈ T : x ≤ y c x 0 , y 1 + ∑ y 1 ∈ S c y 1 , t Implicitly converting both of the following sets to be subsets of X , we have ( S ∩ X 1 ) ⊇ ( S ∩ X 0 ) ↑ for any non-infinite cut. Why? Well, if it was false, then there'd be some y ≥ x where x 0 ∈ S , and yet y 1 ∉ S . So y 1 ∈ T . Then, the cost of the cut would include c x 0 , y 1 = ∞ , contradiction. So, now, we have that for any non-infinite cut, c ( S , T ) = ∑ a ∈ S , b ∈ T c a , b = ∑ x 0 ∈ T c s , x 0 + ∑ y 1 ∈ S c y 1 , t and ( S ∩ X 1 ) ⊇ ( S ∩ X 0 ) ↑ holds. Now, we'll change our cut. Given some cut ( S , T ) , let our new cut ( S ′ , T ′ ) be defined as S ′ : = { s } ∪ ( ( S ∩ X 0 ) ↑ × { 0 , 1 } ) (which still respects that superset property listed above since both sets would be the same), and T ′ be the complement. Letting some stuff cancel out, we get c ( S , T ) − c ( S ′ , T ′ ) = ∑ x 0 ∈ T c s , x 0 + ∑ y 1 ∈ S c y 1 , t − ∑ x 0 ∈ T ′ c s , x 0 − ∑ y 1 ∈ S ′ c y 1 , t = ∑ x 0 ∈ T / T ′ c s , x 0 + ∑ y 1 ∈ S / S ′ c y 1 , t − ∑ x 0 ∈ T ′ / T c s , x 0 − ∑ y 1 ∈ S ′ / S c y 1 , t Now, because S ′ ∩ X 1 = ( S ∩ X 0 ) ↑ × { 1 } ⊆ S ∩ X 1 by that subset property, it means that there's no y 1 ∈ S ′ / S , so we get = ∑ x 0 ∈ T / T ′ c s , x 0 + ∑ y 1 ∈ S / S ′ c y 1 , t − ∑ x 0 ∈ T ′ / T c s , x 0 As for that other minus term, we have that S ′ ∩ X 0 = ( S ∩ X 0 ) ↑ × { 0 } ⊇ S ∩ X 0 by how it was defined, so T ′ ∩ X 0 ⊆ T ∩ X 0 , so that other minus term is 0, and we get = ∑ x 0 ∈ T / T ′ c s , x 0 + ∑ y 1 ∈ S / S ′ c y 1 , t ≥ 0 Rearranging this a bit, we have c ( S , T ) ≥ c ( S ′ , T ′ ) . And now we'll show that c ( S ′ , T ′ ) is underscored by c ( { s } , ( X × { 0 , 1 } ) ∪ { t } ) . Let's go. We have c ( S ′ , T ′ ) − c ( { s } , ( X × { 0 , 1 } ) ∪ { t } ) = ∑ x 0 ∈ T ′ c s , x 0 + ∑ y 1 ∈ S ′ c y 1 , t − ∑ x 0 ∈ ( X × { 0 , 1 } ) ∪ { t } c s , x 0 − ∑ y 1 ∈ { s } c y 1 , t This simplifies a bit as = ∑ x 0 ∈ T ′ c s , x 0 + ∑ y 1 ∈ S ′ c y 1 , t − ∑ x 0 ∈ X 0 c s , x 0 This can be rewritten a bit as = ⎛ ⎝ ∑ x 0 ∈ X 0 c s , x 0 − ∑ x 0 ∈ S ′ c s , x 0 ⎞ ⎠ + ∑ y 1 ∈ S ′ c y 1 , t − ∑ x 0 ∈ X 0 c s , x 0 = ∑ y 1 ∈ S ′ c y 1 , t − ∑ x 0 ∈ S ′ c s , x 0 And then, using what S ′ is defined as, we can get = ∑ y ∈ ( S ∩ X 0 ) ↑ c y 1 , t − ∑ x ∈ ( S ∩ X 0 ) ↑ c s , x 0 and using what the costs are, it's = ∑ y ∈ ( S ∩ X 0 ) ↑ η ( y ) − ∑ x ∈ ( S ∩ X 0 ) ↑ θ ( y ) = η ( ( S ∩ X 0 ) ↑ ) − θ ( ( S ∩ X 0 ) ↑ ) ≥ 0 This holds because θ ⪯ η and the indicator function for ( S ∩ X 0 ) ↑ is monotone. And so, we get c ( S ′ , T ′ ) ≥ c ( { s } , ( X × { 0 , 1 } ) ∪ { t } ) . And we previously showed that c ( S , T ) ≥ c ( S ′ , T ′ ) . So, this means that the cut around s is a minimal cut, it underscores all other cuts. By the max-flow min-cut theorem, there's a way of having stuff flow from s to t that saturates the capacities of all the edges that are cut. f x 0 , y 1 will be used to denote the flow from x 0 to y 1 according to this max-flow way. Let's finish things up. Define κ : X → Δ X as follows. For some x , if f s , x 0 > 0 , then κ ( x ) ( y ) : = f x 0 , y 1 f s , x 0 If f s , x 0 = 0 , let κ ( x ) be any probability distribution on x ↑ . Note that κ ( x ) is always a probability distribution supported on x ↑ , by fiat if f s , x 0 = 0 , and otherwise, ∑ y ∈ X κ ( x ) ( y ) = ∑ y ∈ X f x 0 , y 1 f s , x 0 = f s , x 0 f s , x 0 = 1 This is because, the flow out of x 0 must equal the flow into x 0 from the source. And κ ( x ) is supported on x ↑ because the only edges out of x 0 go to y 1 where y ≥ x . Now that we've got this demonstrated, we'll show our desired inequality. Fix an arbitrary y . We have κ ∗ ( θ ) ( y ) = ∑ x ∈ X θ ( x ) ⋅ κ ( x ) ( y ) = ∑ x ∈ X c s , x 0 ⋅ f x 0 , y 1 f s , x 0 And then we use that all the capacities of the edges cut in the min-cut are saturated according to the max-flow plan, so c s , x 0 = f s , x 0 , and we have = ∑ x ∈ X f s , x 0 ⋅ f x 0 , y 1 f s , x 0 Now, if f s , x 0 = 0 , then because the flow in equals the flow out, that means that f x 0 , y 1 = 0 , and otherwise we can cancel out, so we can rewrite as = ∑ x ∈ X f x 0 , y 1 = f y 1 , t ≤ c y 1 , t = η ( y ) Where the first equality came from flow in equals flow out, the inequality came from the flow plan respecting the capacity of the paths, and the equality came from how the capacities were defined. So, for all y ∈ X , we have κ ∗ ( θ ) ( y ) ≤ η ( y ) so we have κ ∗ ( θ ) ≤ η . For the reverse direction, if there's some κ : X → Δ X s.t κ ( x ) is supported on x ↑ s.t. κ ∗ ( θ ) ≤ η , then for any monotone function f , we have η ( f ) ≥ κ ∗ ( θ ) ( f ) = θ ( λ x . κ ( x ) ( f ) ) And then we use that, since κ ( x ) is supported on x ↑ , and f is monotone, f ( x ) is less than or equal to the expectation of f w.r.t κ ( x ) (remember, for κ ( x ) you have a 100 percent chance of drawing something at-or-above x , which guarantees that f of whatever you picked is above f ( x ) ). And so, we get ≥ θ ( f ) And since this holds for every monotone f , we have θ ⪯ η . ■ Proposition 2.3: Let X be a poset, θ , η ∈ Δ c X .
Then, θ ⪯ η if and only if there exists κ : X → Δ X s.t.
For all x ∈ X , y ∈ supp κ ( x ) : x ≥ y . θ ≤ κ ∗ η Proof: Because θ ⪯ η , we can get a maximum flow in exactly the same way as Proposition 2.2. Then, just flip the direction of all flows, which will be denoted by swapping the order of the subscripts. Now, define κ ( y ) ( x ) : = f y 1 , x 0 f t , y 1 And, again, if it's 0, it should be an arbitrary probability distribution supported on y ↓ .
Note that κ ( y ) is always a probability distribution supported on y ↓ , by fiat if f ′ t , y 1 = 0 , and otherwise, ∑ x ∈ X κ ( y ) ( x ) = ∑ x ∈ X f y 1 , x 0 f t , y 1 = f t , y 1 f t , y 1 = 1 This is because, the flow out of y 1 must equal the flow into y 1 from the source t (the old sink). And κ ( y ) is supported on y ↓ because the only edges out of y 1 go to x 0 where y ≥ x . Now that we've got this demonstrated, we'll show our desired inequality. Fix an arbitrary x . We have κ ∗ ( η ) ( x ) = ∑ y ∈ X η ( y ) ⋅ κ ( y ) ( x ) = ∑ y ∈ X c y 1 , t ⋅ f y 1 , x 0 f t , y 1 Then use that c y 1 , t ≥ f t , y 1 (because even with the flow reversed, the flow through a path must be less than or the same as the capacity. Accordingly, we get ≥ ∑ y ∈ X f y 1 , x 0 = f x 0 , s = c s , x 0 = θ ( x ) And we're done, inequality established, using definitions and the flow saturating all the paths out of s . So, for all x ∈ X , we have κ ∗ ( η ) ( x ) ≥ θ ( x ) so we have κ ∗ ( η ) ≥ θ . For the reverse direction, if there's some κ : X → Δ X s.t κ ( y ) is supported on y ↓ s.t. κ ∗ ( η ) ≥ θ , then for any monotone function f , we have θ ( f ) ≤ κ ∗ ( η ) ( f ) = η ( λ x . κ ( x ) ( f ) ) And then we use that, since κ ( x ) is supported on x ↓ , and f is monotone, f ( x ) is greater than or equal to the expectation of f w.r.t κ ( x ) (remember, for κ ( x ) you have a 100 percent chance of drawing something at-or-below x , which guarantees that f of whatever you picked is below f ( x ) ). And so, we get ≤ η ( f ) And since this holds for every monotone f , we have θ ⪯ η . ■ Proposition 2.4: For any Γ , Φ and Θ ∈ □ c ( Γ × Φ ) , Br ( Θ ) is downwards closed w.r.t. the induced order on Δ c ( el Γ × Φ ) .
That is, if θ ∈ Br ( Θ ) and η ⪯ θ then η ∈ Br ( Θ ) . Remember, the condition for some θ to lie in Br ( Θ ) is that it be supported on el Γ , and that, for all s : Γ → Γ , and g : Γ × Φ → [ 0 , 1 ] , θ ( λ y α x . χ s ( y ) ∈ α g ( s ( y ) , x ) ) ≤ Θ ( λ y x . g ( y , x ) ) So, given that η ⪯ θ (lower score for all monotone functions) we'll show that η fulfills both conditions. The support thing is taken care of by η ∈ Δ c ( el Γ × Φ ) . As for the other one, we have η ( λ y α x . χ s ( y ) ∈ α g ( s ( y ) , x ) ) ≤ θ ( λ y α x . χ s ( y ) ∈ α g ( s ( y ) , x ) ) ≤ Θ ( λ y x . g ( y , x ) ) That inequality occurs because as you make α larger, ie, go up in the partial ordering, the value assigned to the relevant point increases since s ( y ) ∈ α is more likely now, so the function value increases from 0 to something that may be greater than 0. So, it's a monotone function, and we then use that η ⪯ θ ′ . ■ Proposition 2.5: Consider a finite set X , ϕ ? ∈ Δ X , ϕ ! : { 0 , 1 } → Δ X , p ∈ [ 0 , 1 ] and ϕ : = ( 1 − p ) ϕ ? + p ϕ ! .
Then, p ≥ d TV ( ϕ ( 0 ) , ϕ ( 1 ) ) . Conversly, consider any ϕ : { 0 , 1 } → Δ X .
Then, there exist ϕ ? ∈ Δ X and ϕ ! : { 0 , 1 } → Δ X s.t. ϕ = ( 1 − p ) ϕ ? + p ϕ ! for p : = d TV ( ϕ ( 0 ) , ϕ ( 1 ) ) . Ok, so let f be some arbitrary function X → [ 0 , 1 ] . We have an alternate characterization of the total variation distance as d TV ( ϕ ( 0 ) , ϕ ( 1 ) ) : = sup f ∈ X → [ 0 , 1 ] | ϕ ( 0 ) ( f ) − ϕ ( 1 ) ( f ) | And then from there we can go = sup f ∈ X → [ 0 , 1 ] | ( ( 1 − p ) ϕ ? ( f ) + p ϕ ! ( 0 ) ( f ) ) − ( ( 1 − p ) ϕ ? ( f ) + p ϕ ! ( 1 ) ( f ) ) | = sup f ∈ X → [ 0 , 1 ] | p ϕ ! ( 0 ) ( f ) − p ϕ ! ( 1 ) ( f ) | = p sup f ∈ X → [ 0 , 1 ] | ϕ ! ( 0 ) ( f ) − ϕ ! ( 1 ) ( f ) | = p d TV ( ϕ ! ( 0 ) , ϕ ! ( 1 ) ) And since p ≥ p d TV ( ϕ ! ( 0 ) , ϕ ! ( 1 ) ) , we have p ≥ d TV ( ϕ ( 0 ) , ϕ ( 1 ) ) and are done. Conversely, let the value of p be 1 − ( ϕ ( 0 ) ∧ ϕ ( 1 ) ) ( 1 ) , and ϕ ? be 1 ( 1 − p ) ( ϕ ( 0 ) ∧ ϕ ( 1 ) ) . It is clear that this is a probability distribution because of how p was defined. The ∧ is the minimum/common overlap of the two probability distributions. Then, let ϕ ! ( 0 ) = 1 p ( ϕ ( 0 ) − ( ϕ ( 0 ) ∧ ϕ ( 1 ) ) ) , and similar for the 1. Well, as long as p > 0 . If p = 0 , it can be any probability distribution you want. It's a probability distribution because ϕ ! ( 0 ) ( 1 ) = 1 p ( ϕ ( 0 ) ( 1 ) − ( ϕ ( 0 ) ∧ ϕ ( 1 ) ) ( 1 ) ) = 1 p ( 1 − ( ϕ ( 0 ) ∧ ϕ ( 1 ) ) ( 1 ) ) = 1 − ( ϕ ( 0 ) ∧ ϕ ( 1 ) ) ( 1 ) 1 − ( ϕ ( 0 ) ∧ ϕ ( 1 ) ) ( 1 ) = 1 And since p > 0 , everything works out. Now we just need to show that these add up to make ϕ and that p is the same as the total variation distance. ϕ ( 0 ) = ( ϕ ( 0 ) ∧ ϕ ( 1 ) ) + ϕ ( 0 ) − ( ϕ ( 0 ) ∧ ϕ ( 1 ) ) = ( 1 − p ) 1 ( 1 − p ) ( ϕ ( 0 ) ∧ ϕ ( 1 ) ) + p 1 p ( ϕ ( 0 ) − ( ϕ ( 0 ) ∧ ϕ ( 1 ) ) ) = ( 1 − p ) ϕ ? + p ϕ ! ( 0 ) And this works symmetrically for ϕ ( 1 ) , showing that we indeed have equality. As for showing that p is the total variation distance, referring back to what we've already proved, we have d TV ( ϕ ( 0 ) , ϕ ( 1 ) ) = p d TV ( ϕ ! ( 0 ) , ϕ ! ( 1 ) ) And now, since ϕ ! ( 0 ) = ϕ ( 0 ) − ( ϕ ( 0 ) ∧ ϕ ( 1 ) ) and ϕ ! ( 1 ) = ϕ ( 1 ) − ( ϕ ( 0 ) ∧ ϕ ( 1 ) ) , the supports of these two probability distributions are disjoint, which implies that the total variation distance is 1, so we have d TV ( ϕ ( 0 ) , ϕ ( 1 ) ) = p . Proposition 2.6: Consider any Φ and ϕ : { 0 , 1 } → Δ Φ .
Denote U : = { 0 , 1 } × { { 0 , 1 } } × Φ (the event ``program
is unrealized''). Let Λ : = Br ( ⊤ { 0 , 1 } ⋉ ϕ ) .
Then, Λ ( χ U ) = 1 − d TV ( ϕ ( 0 ) , ϕ ( 1 ) ) This will take some work to establish. One direction, showing that the bridge transform value exceeds the total variation distance value, is fairly easy. As for the other direction, it'll take some work. Let's begin. Λ ( χ U ) = Br ( ⊤ { 0 , 1 } ⋉ ϕ ) ( χ U ) = Br ( ⊤ { 0 , 1 } ⋉ ϕ ) ( λ y α x . χ α = { 0 , 1 } ) = max θ ∈ Br ( ⊤ { 0 , 1 } ⋉ ϕ ) θ ′ ( λ y α x . χ α = { 0 , 1 } ) We'll make a particular contribution θ ∗ . It is defined as δ 0 × ( ϕ ( 0 ) − ϕ ( 0 ) ∧ ϕ ( 1 ) ) × δ { 0 } + δ 0 × ( ϕ ( 0 ) ∧ ϕ ( 1 ) ) × δ { 0 , 1 } Or, put another way, restricting to 0 , { 0 } , it's ϕ ( 0 ) − ϕ ( 0 ) ∧ ϕ ( 1 ) , and conditioning on 0 , { 0 , 1 } , it's ϕ ( 0 ) ∧ ϕ ( 1 ) . So, for a given s : { 0 , 1 } → { 0 , 1 } , we have θ ∗ ( λ y α x . χ s ( y ) ∈ α g ( s ( y ) , x ) ) = ( δ 0 × ( ϕ ( 0 ) − ϕ ( 0 ) ∧ ϕ ( 1 ) ) × δ { 0 } + δ 0 × ( ϕ ( 0 ) ∧ ϕ ( 1 ) ) × δ { 0 , 1 } ) ( λ y α x . χ s ( y ) ∈ α g ( s ( y ) , x ) ) = ( δ 0 × ( ϕ ( 0 ) − ϕ ( 0 ) ∧ ϕ ( 1 ) ) × δ { 0 } ) ( λ y α x . χ s ( y ) ∈ α g ( s ( y ) , x ) ) + ( δ 0 × ( ϕ ( 0 ) ∧ ϕ ( 1 ) ) × δ { 0 , 1 } ) ( λ y α x . χ s ( y ) ∈ α g ( s ( y ) , x ) ) = ( ϕ ( 0 ) − ϕ ( 0 ) ∧ ϕ ( 1 ) ) ( λ x . χ s ( 0 ) ∈ { 0 } g ( s ( 0 ) , x ) ) + ( ϕ ( 0 ) ∧ ϕ ( 1 ) ) ( λ x . χ s ( 0 ) ∈ { 0 , 1 } g ( s ( 0 ) , x ) ) Now, we'll go through two exhaustive possibilities for what s could be. If it maps 0 to 0, then it's = ( ϕ ( 0 ) − ϕ ( 0 ) ∧ ϕ ( 1 ) ) ( λ x . χ 0 ∈ { 0 } g ( 0 , x ) ) + ( ϕ ( 0 ) ∧ ϕ ( 1 ) ) ( λ x . χ 0 ∈ { 0 , 1 } g ( 0 , x ) ) = ( ϕ ( 0 ) − ϕ ( 0 ) ∧ ϕ ( 1 ) ) ( λ x . g ( 0 , x ) ) + ( ϕ ( 0 ) ∧ ϕ ( 1 ) ) ( λ x . g ( 0 , x ) ) = ϕ ( 0 ) ( λ x . g ( 0 , x ) ) ≤ max y ∈ { 0 , 1 } ϕ ( y ) ( λ x . g ( y , x ) ) = ⊤ { 0 , 1 } ( λ y . ϕ ( y ) ( λ x . g ( y , x ) ) = ( ⊤ { 0 , 1 } ⋉ ϕ ) ( λ y x . g ( y , x ) ) And our desired inequality is established. If s maps 0 to 1, then it's = ( ϕ ( 0 ) − ϕ ( 0 ) ∧ ϕ ( 1 ) ) ( λ x . χ 1 ∈ { 0 } g ( 1 , x ) ) + ( ϕ ( 0 ) ∧ ϕ ( 1 ) ) ( λ x . χ 1 ∈ { 0 , 1 } g ( 1 , x ) ) = ( ϕ ( 0 ) ∧ ϕ ( 1 ) ) ( λ x . g ( 1 , x ) ) ≤ ϕ ( 1 ) ( λ x . g ( 1 , x ) ) ≤ max y ∈ { 0 , 1 } ϕ ( y ) ( λ x . g ( y , x ) ) = ( ⊤ { 0 , 1 } ⋉ ϕ ) ( λ y x . g ( y , x ) ) And that is taken care of. So, our θ ∗ lies in Br ( ⊤ { 0 , 1 } ⋉ ϕ ) . Now, where were we? Ah right, we were at Λ ( χ U ) = max θ ∈ Br ( ⊤ { 0 , 1 } ⋉ ϕ ) θ ( λ y α x . χ α = { 0 , 1 } ) But now we can continue with ≥ θ ∗ ( λ y α x . χ α = { 0 , 1 } ) Which unpacks as = ( δ 0 × ( ϕ ( 0 ) − ϕ ( 0 ) ∧ ϕ ( 1 ) ) × δ { 0 } + δ 0 × ( ϕ ( 0 ) ∧ ϕ ( 1 ) ) × δ { 0 , 1 } ) ( λ y α x . χ α = { 0 , 1 } ) = ( δ 0 × ( ϕ ( 0 ) − ϕ ( 0 ) ∧ ϕ ( 1 ) ) × δ { 0 } ) ( λ y α x . χ α = { 0 , 1 } ) + ( δ 0 × ( ϕ ( 0 ) ∧ ϕ ( 1 ) ) × δ { 0 , 1 } ) ( λ y α x . χ α = { 0 , 1 } ) = ( ϕ ( 0 ) − ϕ ( 0 ) ∧ ϕ ( 1 ) ) ( λ x . χ { 0 } = { 0 , 1 } ) + ( ϕ ( 0 ) ∧ ϕ ( 1 ) ) ( λ x . χ { 0 , 1 } = { 0 , 1 } ) = ( ϕ ( 0 ) ∧ ϕ ( 1 ) ) ( 1 ) And then, the value of the overlap between two distributions is 1 − d TV ( ϕ ( 0 ) , ϕ ( 1 ) ) . So, we've shown one direction, we have Λ ( χ U ) ≥ 1 − d TV ( ϕ ( 0 ) , ϕ ( 1 ) ) In the other direction of the equality we're trying to prove, we need to constrain what θ might be. Starting off with what we definitely know, we have Λ ( χ U ) = max θ ∈ Br ( ⊤ { 0 , 1 } ⋉ ϕ ) θ ( λ y α x . χ α = { 0 , 1 } ) Now it's time to show that for any θ ∈ Br ( ⊤ { 0 , 1 } ⋉ ϕ ) , that the measure on α = { 0 , 1 } can't be too high. Specifically, to proceed further, we'll need to show that ∀ x ′ ∈ Φ : θ ( λ y α x . χ x = x ′ ∧ α = { 0 , 1 } ) ≤ ( ϕ ( 0 ) ∧ ϕ ( 1 ) ) ( λ x . χ x = x ′ ) Time to establish it. On x ′ , either ϕ ( 0 ) ( x ′ ) ≥ ϕ ( 1 ) ( x ′ ) , or vice-versa. Without loss of generality, assume that it's ϕ ( 0 ) ( x ′ ) that's lower. Then, let s be the constant-0 function, and g ( 0 , x ′ ) be 1, and 0 everywhere else.
Then, we have θ ( λ y α x . χ x = x ′ ∧ α = { 0 , 1 } ) ≤ θ ( λ y α x . χ s ( y ) ∈ α g ( s ( y ) , x ) ) ≤ ( ⊤ { 0 , 1 } ⋉ ϕ ) ( λ y x . g ( y , x ) ) = ( ⊤ { 0 , 1 } ⋉ ϕ ) ( λ y x . χ y = 0 ∧ x = x ′ ) = max y ∈ { 0 , 1 } ϕ ( y ) ( λ x . χ y = 0 ∧ x = x ′ ) = ϕ ( 0 ) ( λ x . χ x = x ′ ) = ϕ ( 0 ) ( x ′ ) = ( ϕ ( 0 ) ∧ ϕ ( 1 ) ) ( x ′ ) Just abbreviating, using that θ lies in the bridge transform, deabbreviating with what g is, unpacking things a little bit and canceling out. At the end we used that ϕ ( 0 ) ( x ′ ) ≤ ϕ ( 1 ) ( x ′ ) . Ok, so, now that we've established the key fact that ∀ x ′ ∈ Φ : θ ( λ y α x . χ x = x ′ ∧ α = { 0 , 1 } ) ≤ ( ϕ ( 0 ) ∧ ϕ ( 1 ) ) ( λ x . χ x = x ′ ) We can resume our work. We were previously at = max θ ∈ Br ( ⊤ { 0 , 1 } ⋉ ϕ ) θ ( λ y α x . χ α = { 0 , 1 } ) and we can proceed to = max θ ∈ Br ( ⊤ { 0 , 1 } ⋉ ϕ ) ∑ x ′ ∈ Φ θ ( λ y α x . χ x = x ′ ∧ α = { 0 , 1 } ) and from there, using the inequality we proved, proceed to ≤ ∑ x ′ ∈ Φ ( ϕ ( 0 ) ∧ ϕ ( 1 ) ) ( λ x . χ x = x ′ ) = ( ϕ ( 0 ) ∧ ϕ ( 1 ) ) ( 1 ) = 1 − d TV ( ϕ ( 0 ) , ϕ ( 1 ) ) And we're done, we established that it's an upper bound as well a lower bound, so we have equality. ■ Lemma 2: If there's a function h : Φ → 2 Γ and Θ ( λ y x . χ y ∉ h ( x ) ) = 0 , then for all θ ∈ Br ( Θ ) , θ is supported on the set { α , x | α ⊆ h ( x ) } . Assume that the conclusion is false, that there is some nonzero probability of drawing a x ∗ , α ∗ pair where α ∗ ⊈ h ( x ∗ ) . In particular, there must be some special y ∗ ∈ Γ value that witnesses that α ∗ isn't a subset, by y ∗ ∈ α ∗ and y ∗ ∉ h ( x ∗ ) . Remember that for all s : Γ → Γ and g : Γ × Φ → [ 0 , 1 ] , that since θ ∈ Br ( Θ ) , we have θ ( λ y α x . χ s ( y ) ∈ α g ( s ( y ) , x ) ) ≤ Θ ( λ y x . g ( y , x ) ) Now, in particular, let g : = χ y ∉ h ( x ) , and s be the constant function that maps everything to y ∗ . Then, this turns into 0 < θ ( λ y α x . χ y ∗ ∈ α χ y ∗ ∉ h ( x ) ) ≤ Θ ( λ y x . χ y ∉ h ( x ) ) = 0 which is impossible. The equality as the end was our starting assumption. The middle inequality was just specializing our inequality to a particular pair of functions. And it's greater than 0 because there's a nonzero probability of drawing x ∗ , α ∗ . And y ∗ was selected to lie in α ∗ and outside of h ( x ∗ ) , so there's a nonzero probability of getting a nonzero value. Therefore, the result follows. ■ Lemma 3: For any s : Γ → Γ , and Θ : □ c ( Γ × Φ ) , if θ ∈ Br ( Θ ) , then χ el Γ ( s ∗ ( θ ′ ) ) ∈ Br ( Θ ) . So, the support condition is trivially fulfilled, because we're restricting to the event y ∈ α . That just leaves the endofunction condition. Let s ′ : Γ → Γ be arbitrary, and g : Γ × Φ → [ 0 , 1 ] be arbitrary. Then we have χ el Γ ( s ∗ ( θ ) ) ( λ y α x . χ s ′ ( y ) ∈ α g ( s ′ ( y ) , x ) ) = s ∗ ( θ ) ( λ y α x . χ y ∈ α ∧ s ′ ( y ) ∈ α g ( s ′ ( y ) , x ) ) ≤ s ∗ ( θ ) ( λ y α x . χ s ′ ( y ) ∈ α g ( s ′ ( y ) , x ) ) = θ ( λ y α x . χ s ′ ( s ( y ) ) ∈ α g ( s ′ ( s ( y ) ) , x ) ) And, since s ′ ∘ s : Γ → Γ , we can use that θ ∈ Br ( Θ ) to get ≤ Θ ( λ y x . g ( y , x ) ) And we're done, we've established that our modified version of θ remains in Br ( Θ ) . ■ Proposition 2.7: If X is a poset and Θ ∈ □ c X ,
then Θ ↓ will denote downward closure of Θ .
For any Γ , Φ and Θ ∈ □ c ( Γ × Φ ) if ( y , α , x ) ∈ supp Br ( Θ ) and y ′ ∈ α , then ( y ′ , x ) ∈ supp Θ .
Moreover, define sus Θ : Φ → 2 Γ by sus Θ ( x ) : = { y ∈ Γ ∣ ( y , x ) ∈ supp Θ } .
Then, Br ( Θ ) ⊆ ( Θ ⋉ sus Θ ) ↓ (we slightly abuse notation by treating sus Θ as a mapping Γ × Φ → 2 Γ that doesn't depend on the
first argument, and also playing loose with the order of factors in
the set on which our HUCs live). This proof splits into two parts. Part 1 will be proving the support statement. Part 2 will be proving the thing with sus Θ . Part 1: Here's the basics of how this part will work. There's some ( y ∗ , α ∗ , x ∗ ) tuple in the support of Br ( Θ ) . Since the support of Br ( Θ ) is the union of the supports for the θ ∈ Br ( Θ ) , there's some θ that assigns nonzero probability to that event. Also, y ′ ∈ α ∗ . The key part of the proof is showing there's some θ ∗ ∈ Br ( Θ ) that assigns nonzero measure to the event ( y ′ , x ∗ , α ∗ ) . Once we've got that, since we know by Proposition 2.1 that Br ( Θ ) projects down to equal Θ , that means that the projection of θ ∗ will land in Θ , and it will assign nonzero measure to the event ( y ′ , x ∗ ) , so the event ( y ′ , x ∗ ) lies in the support of Θ . So, that just leaves appropriately defining our θ ∗ and showing that it lies in Br ( Θ ) and assigns nonzero probability to our event of interest. Our particular choice of θ ∗ will be as follows. Let c y ′ : Γ → Γ be the constant function mapping everything to y ′ . θ ∗ : = χ el Γ ( ( c y ′ ) ∗ ( θ ) ) Applying Lemma 3, this is in Br ( Θ ) , so that just leaves showing that it assigns nonzero probability to the event y ′ , x ∗ , α ∗ . We have χ el Γ ( ( c y ′ ) ∗ ( θ ) ) ( λ y α x . χ y = y ′ ∧ x = x ∗ ∧ α = α ∗ ) = ( c y ′ ) ∗ ( θ ) ( λ y α x . χ y = y ′ ∧ x = x ∗ ∧ α = α ∗ ∧ y ∈ α ) We can simplify this a bit, because if the first three properties hold, that tells you something about what α is. = ( c y ′ ) ∗ ( θ ) ( λ y α x . χ y = y ′ ∧ x = x ∗ ∧ α = α ∗ ∧ y ∈ α ∗ ) unpack the pushforward = θ ( λ y α x . χ c y ′ ( y ) = y ′ ∧ x = x ∗ ∧ α = α ∗ ∧ c y ′ ( y ) ∈ α ∗ ) Then we use that it's a constant function = θ ( λ y α x . χ y ′ = y ′ ∧ x = x ∗ ∧ α = α ∗ ∧ y ′ ∈ α ∗ ) Now, since y ′ ∈ α ∗ by the problem setup, and y ′ = y ′ is a tautology, we can remove those two events. = θ ( λ y α x . χ x = x ∗ ∧ α = α ∗ ) and use an inequality ≥ θ ( λ y α x . χ y = y ∗ ∧ x = x ∗ ∧ α = α ∗ ) > 0 Because θ assigned nonzero probability to that event. So, we know that our θ ∗ assigns nonzero measure to the event of interest. And that's it! It fulfills the appropriate properties to carry the proof through. Proof part 2: First off, we can reexpress Br ( Θ ) ⊆ ( Θ ⋉ sus Θ ) ↓ as the equivalent statement that, for all f : el Γ × Φ → [ 0 , 1 ] , we have Br ( Θ ) ( λ y α x . f ( y , x , α ) ) ≤ ( Θ ⋉ sus Θ ) ↓ ( λ y α x . f ( y , x , α ) ) Although, since Br ( Θ ) and ( Θ ⋉ sus Θ ) ↓ are downwards-closed, we actually only need to demonstrate this inequality for monotone functions f . The reason we only need to demonstrate this inequality for monotone f is because of Br ( Θ ) ( f ) = Br ( Θ ) ( f max ) ≤ ( Θ ⋉ sus Θ ) ↓ ( f max ) = ( Θ ⋉ sus Θ ) ↓ ( f ) Where the equalities follow from Proposition 3.1 and the downward closure of the two ultracontributions, and the inequality is what we're trying to prove (since f max in the sense of Proposition 3.1 is always a monotone function. So, let f be monotone, and we're trying to prove the desired inequality. We'll unpack it bit by bit. Br ( Θ ) ( λ y α x . f ( y , x , α ) ) = max θ ∈ Br ( Θ ) θ ( λ y α x . f ( y , x , α ) ) And now we remember that the set { x , y | y ∈ sus Θ ( x ) } is a support for Θ , because it's the same as { x , y | ( y , x ) ∈ supp Θ } , ie, the support of Θ . So, by Lemma 2, we can conclude that any θ ∈ Br ( Θ ) is supported on α , x pairs s.t. α ⊆ sus Θ ( x ) . In particular, this means that α ≤ sus Θ ( x ) , and since f is monotone, swapping out α for sus Θ ( x ) always produces an increase in expected value, so we get ≤ max θ ∈ Br ( Θ ) θ ( λ y α x . f ( y , x , sus Θ ( x ) ) ) and then, since all θ ∈ Br ( Θ ) are supported on y , α s.t. y ∈ α , we can go = max θ ∈ Br ( Θ ) θ ( λ y α x . χ y ∈ α f ( y , x , sus Θ ( x ) ) ) And then, since all the θ ∈ Br ( Θ ) fulfill the endofunction property, we can let s be identity and g be f , and go ≤ Θ ( λ y x . f ( y , x , sus Θ ( x ) ) ) And rewrite that as = Θ ( λ y x . δ sus Θ ( x ) ( λ α . f ( y , x , α ) ) ) = ( Θ ⋉ sus Θ ) ( λ y α x . f ( y , x , α ) ) and then since f is monotone = ( Θ ⋉ sus Θ ) ↓ ( λ y α x . f ( y , x , α ) ) This holds because all contributions added when you take the downward closure can only produce lower expectation values than the existing contributions due to monotonicity of f , and so they're ignored. And now we're done! We got the inequality going appropriately to hit our proof target. ■ Proposition 2.8: For any Γ , Φ and Θ ∈ □ c ( Γ × Φ ) Br ( pr Γ × 2 Γ Br ( Θ ) ) = [ ( id Γ × diag 2 Γ ) ∗ pr Γ × 2 Γ Br ( Θ ) ] ↓ For notation, we'll use β for the set which is being treated as part of the background environment, and α as the usual set. The way to establish this is to show equal expectation values for all functions monotone in the last argument (the relevant set-based one), which is all we need to do as both sets are downwards-closed. We'll do this by establishing the two inequalities separately. Our first order of business is showing that for all f : el Γ × 2 Γ monotone in the last coordinate, we have Br ( pr Γ × 2 Γ Br ( Θ ) ) ( λ y α β . f ( y , β , α ) ) ≥ [ ( id Γ × diag 2 Γ ) ∗ pr Γ × 2 Γ Br ( Θ ) ] ↓ ( λ y α β . f ( y , β , α ) ) Let's begin. Pick an f that's monotone in the last argument. [ ( id Γ × diag 2 Γ ) ∗ pr Γ × 2 Γ Br ( Θ ) ] ↓ ( λ y α β . f ( y , β , α ) ) = [ ( id Γ × diag 2 Γ ) ∗ pr Γ × 2 Γ Br ( Θ ) ] ( λ y α β . f ( y , β , α ) ) = pr Γ × 2 Γ Br ( Θ ) ( λ y β . f ( y , β , β ) ) = Br ( Θ ) ( λ y β x . f ( y , β , β ) ) = max θ ′ ∈ Br ( Θ ) θ ′ ( λ y β x . f ( y , β , β ) ) = max θ ′ ∈ Br ( Θ ) θ ′ ( λ y β x . δ β ( λ α . f ( y , β , α ) ) ) = max θ ′ ∈ Br ( Θ ) pr Γ × 2 Γ ( θ ′ ) ( λ y β . δ β ( λ α . f ( y , β , α ) ) ) = max θ ′ ∈ Br ( Θ ) ( pr Γ × 2 Γ ( θ ′ ) ⋉ id 2 Γ ) ( λ y β α . f ( y , β , α ) ) We'll set this to the side for a moment to show that if θ ′ ∈ Br ( Θ ) , then pr Γ × 2 Γ ( θ ′ ) ⋉ id 2 Γ ∈ Br ( pr Γ × 2 Γ Br ( Θ ) ) . The support part is easy. Since θ ′ ∈ Br ( Θ ) , it's supported on ( y , β ) pairs where y ∈ β . Taking semidirect product with identity means that y ∈ α always happens, because β = α always happens. So, that leaves showing the endofunction condition. We have ( pr Γ × 2 Γ ( θ ′ ) ⋉ id 2 Γ ) ( λ y α β . χ s ( y ) ∈ α g ( s ( y ) , β ) ) = pr Γ × 2 Γ ( θ ′ ) ( λ y β . δ β ( λ α . χ s ( y ) ∈ α g ( s ( y ) , β ) ) = pr Γ × 2 Γ ( θ ′ ) ( λ y β . χ s ( y ) ∈ β g ( s ( y ) , β ) ) = θ ′ ( λ y β x . χ s ( y ) ∈ β g ( s ( y ) , β ) ) And start packing things up a bit = s ∗ ( θ ′ ) ( λ y β x . χ y ∈ β g ( y , β ) ) = χ el Γ ( s ∗ ( θ ′ ) ) ( λ y β x . g ( y , β ) ) And, since θ ′ ∈ Br ( Θ ) , this update of the pushforward of θ ′ lands in Br ( Θ ) by Lemma 3, so we get ≤ max θ ′′ ∈ Br ( Θ ) θ ′′ ( λ y β x . g ( y , β ) ) = Br ( Θ ) ( λ y β x . g ( y , β ) ) = pr Γ × 2 Γ Br ( Θ ) ( λ y β . g ( y , β ) ) Now, since we've established that inequality for all choices of s , g , we have that pr Γ × 2 Γ ( θ ′ ) ⋉ id 2 Γ ∈ Br ( pr Γ × 2 Γ Br ( Θ ) ) Resuming where we last left off, the last place we were at in our chain of inequalities was = max θ ′ ∈ Br ( Θ ) ( pr Γ × 2 Γ ( θ ′ ) ⋉ id 2 Γ ) ( λ y α β . f ( y , β , α ) ) Since these things are always in Br ( pr Γ × 2 Γ Br ( Θ ) ) , we can go ≤ max θ ′′ ∈ Br ( pr Γ × 2 Γ Br ( Θ ) ) θ ′′ ( λ y α β . f ( y , β , α ) ) = Br ( pr Γ × 2 Γ Br ( Θ ) ) ( λ y α β . f ( y , β , α ) ) And we're done with that inequality direction. Now to show the reverse direction, which actually will use that f is monotone in the last argument. We start with Br ( pr Γ × 2 Γ Br ( Θ ) ) ( λ y α β . f ( y , β , α ) ) = max θ ′′ ∈ Br ( pr Γ × 2 Γ Br ( Θ ) ) θ ′′ ( λ y α β . f ( y , β , α ) ) And now, we can use that pr Γ × 2 Γ Br ( Θ ) is supported on ( y , β ) pairs where y ∈ id ( β ) , along with Lemma 2 applied to id, to conclude that all the θ ′′ must be supported on the event α ⊆ id ( β ) = β . Since big sets go more towards the top and get a higher loss, and f is monotone in the last argument, we get ≤ max θ ′′ ∈ Br ( pr Γ × 2 Γ Br ( Θ ) ) θ ′′ ( λ y α β . f ( y , β , β ) ) Now, we can use the endofunction property of all the θ ′′ w.r.t. pr Γ × 2 Γ Br ( Θ ) to get a uniform upper bound of ≤ pr Γ × 2 Γ Br ( Θ ) ( λ y β . f ( y , β , β ) ) and then go = [ ( id Γ × diag 2 Γ ) ∗ pr Γ × 2 Γ Br ( Θ ) ] ( λ y α β . f ( y , β , α ) ) = [ ( id Γ × diag 2 Γ ) ∗ pr Γ × 2 Γ Br ( Θ ) ] ↓ ( λ y α β . f ( y , β , α ) ) and we're done, we got the inequality going in the other direction, so we have equality for arbitrary monotone functions, and thus equality. ■ Proposition 2.9: For any Γ , Φ and Θ 1 , Θ 2 ∈ □ c ( Γ × Φ ) ,
if Θ 1 ⊆ Θ 2 then Br ( Θ 1 ) ⊆ Br ( Θ 2 ) . Proof: This is really easy to show, we just need to take some contribution θ ′ ∈ Br ( Θ 1 ) and show that it lies in Br ( Θ 2 ) . The support condition is easily fulfilled, so that leaaves showing the endofunction condition. Let's begin. θ ′ ( λ y α x . χ s ( y ) ∈ α g ( s ( y ) , x ) ) ≤ Θ 1 ( λ y x . g ( y , x ) ) = max θ ∈ Θ 1 θ ( λ y x . g ( y , x ) ) And now, since Θ 1 ⊆ Θ 2 , we have ≤ max θ ∈ Θ 2 θ ( λ y x . g ( y , x ) ) = Θ 2 ( λ y x . g ( y , x ) ) Done. ■ Proposition 2.10: For any Γ , Φ 1 , Φ 2 , t : Φ 2 → Φ 1 and Θ ∈ □ c ( Γ × Φ 2 ) ( id el Γ × t ) ∗ Br ( Θ ) ⊆ Br ( ( id Γ × t ) ∗ Θ ) As usual, we just need to establish that for all f : el Γ × Φ , the expectation value is lower in the first function than the second function, so our proof goal will be ( id el Γ × t ) ∗ Br ( Θ ) ( λ y α x 1 . f ( y , α , x 1 ) ) ≤ Br ( ( id Γ × t ) ∗ Θ ) ( λ y α x 1 . f ( y , α , x 1 ) ) Let's begin trying to show this. ( id el Γ × t ) ∗ Br ( Θ ) ( λ y α x 1 . f ( y , x 1 , α ) ) = Br ( Θ ) ( λ y α x 2 . f ( y , t ( x 2 ) , α ) ) = max θ ′ ∈ Br ( Θ ) θ ′ ( λ y α x 2 , . f ( y , t ( x 2 ) , α ) ) = max θ ′ ∈ Br ( Θ ) ( id el Γ × t ) ∗ ( θ ′ ) ( λ y α x 1 . f ( y , x 1 , α ) ) Now we will show that all the contributions of this form lie in Br ( ( id Γ × t ) ∗ Θ ) . Clearly the y ∈ α condition is always fulfilled for these pushforwards, so that just leaves the endofunction condition. Let's begin. ( id el Γ × t ) ∗ ( θ ′ ) ( λ y α x 1 . χ s ( y ) ∈ α g ( s ( y ) , x 1 ) ) = θ ′ ( λ y α x 2 . χ s ( y ) ∈ α g ( s ( y ) , t ( x 2 ) ) ) ≤ Θ ( λ y x 2 . g ( y , t ( x 2 ) ) ) = ( id Γ × t ) ∗ ( Θ ) ( λ y x 1 . g ( y , x 1 ) ) And we're done, we established our desired result that the pushforward lands in the appropriate set. So, we can proceed by going ≤ max θ ′′ ∈ Br ( ( id Γ × t ) ∗ ( Θ ) ) θ ′′ ( λ y α x 1 . f ( y , x 1 , α ) ) = Br ( ( id Γ × t ) ∗ ( Θ ) ) ( λ y α x 1 . f ( y , x 1 , α ) ) And we're done! ■ Proposition 2.11: Consider any Γ , Φ 1 , Φ 2 , t : Φ 2 → Φ 1 , Ξ : Φ 1 → □ Φ 2 and Θ ∈ □ c ( Γ × Φ 1 ) s.t. t ∘ Ξ = id Φ 1 .
Then, ( id el Γ × Ξ ) ∗ Br ( Θ ) ⊆ Br ( ( id Γ × Ξ ) ∗ Θ ) ⊆ ( id el Γ × t ) ∗ Br ( Θ ) In particular, pr el Γ Br ( Θ ) = pr el Γ Br ( ( id Γ × Ξ ) ∗ Θ ) Well, let's get started on proving these various things. To begin with, to prove ( id el Γ × Ξ ) ∗ Br ( Θ ) ⊆ Br ( ( id Γ × Ξ ) ∗ Θ ) We need to prove that, for all f : el Γ × Φ 2 → [ 0 , 1 ] , ( id el Γ × Ξ ) ∗ Br ( Θ ) ( λ y α x 2 . f ( y , x 2 , α ) ) ≤ Br ( ( id Γ × Ξ ) ∗ Θ ) ( λ y α x 2 . f ( y , x 2 , α ) ) Let's establish this. Unpacking the left-hand side, we have ( id el Γ × Ξ ) ∗ Br ( Θ ) ( λ y α x 2 . f ( y , x 2 , α ) ) = Br ( Θ ) ( λ y α x 1 . Ξ ( x 1 ) ( λ x 2 . f ( y , x 2 , α ) ) ) = max θ ′ ∈ Br ( Θ ) θ ′ ( λ y α x 1 . Ξ ( x 1 ) ( λ x 2 . f ( y , x 2 , α ) ) ) = max θ ′ ∈ Br ( Θ ) ( id el Γ × Ξ ) ∗ ( θ ′ ) ( λ y α x 2 . f ( y , x 2 , α ) ) = max θ ′ ∈ Br ( Θ ) max θ ′′ ∈ ( id el Γ × Ξ ) ∗ ( θ ′ ) θ ′′ ( λ y α x 2 . f ( y , x 2 , α ) ) Now we'll show that this θ ′′ lies in Br ( ( id Γ × Ξ ) ∗ Θ ) . The support condition is trivial, so that leaves the endofunction condition. θ ′′ ( λ y α x 2 . χ y ∈ α g ( s ( y ) , x 2 ) ) ≤ ( id el Γ × Ξ ) ∗ ( θ ′ ) ( λ y α x 2 . χ s ( y ) ∈ α g ( s ( y ) , x 2 ) ) = θ ′ ( λ y α x 1 . Ξ ( x 1 ) ( λ x 2 . χ s ( y ) ∈ α g ( s ( y ) , x 2 ) ) ) Then, by homogenity of Ξ , we can pull a constant out, the indicator function, to get = θ ′ ( λ y α x 1 . χ s ( y ) ∈ α Ξ ( x 1 ) ( λ x 2 . g ( s ( y ) , x 2 ) ) ) Then, by the endofunction condition, we get ≤ Θ ( λ y x 1 . Ξ ( x 1 ) ( λ x 2 . g ( y , x 2 ) ) ) = ( id Γ × Ξ ) ∗ ( Θ ) ( λ y x 2 . g ( y , x 2 ) ) And bam, we've showed that θ ′′ lies in the appropriate set. We were last at = max θ ′ ∈ Br ( Θ ) max θ ′′ ∈ ( id el Γ × Ξ ) ∗ ( θ ′ ) θ ′′ ( λ y α x 2 . f ( y , x 2 , α ) ) So we can impose an upper bound of ≤ max θ ′′ ∈ Br ( ( id Γ × Ξ ) ∗ Θ ) θ ′′ ( λ y α x 2 . f ( y , x 2 , α ) ) ≤ Br ( ( id Γ × Ξ ) ∗ ( Θ ) ) ( λ y α x 2 . f ( y , x 2 , α ) ) And we're done, we've established our desired inequality. Now for proving another inequality. Br ( ( id Γ × Ξ ) ∗ Θ ) ⊆ ( id el Γ × t ) ∗ Br ( Θ ) This can be proved by applying Proposition 2.10. Start out with Proposition 2.10. ( id el Γ × t ) ∗ Br ( Θ ′ ) ⊆ Br ( ( id Γ × t ) ∗ Θ ′ ) Specialize Θ ′ to ( id Γ × Ξ ) ∗ ( Θ ) , yielding ( id el Γ × t ) ∗ Br ( ( id Γ × Ξ ) ∗ Θ ) ⊆ Br ( ( id Γ × t ) ∗ ( id Γ × Ξ ) ∗ Θ ) The two pushforwards can be folded into one. ( id el Γ × t ) ∗ Br ( ( id Γ × Ξ ) ∗ Θ ) ⊆ Br ( ( id Γ × t ∘ Ξ ) ∗ Θ ) Now use that t ∘ Ξ is identity ( id el Γ × t ) ∗ Br ( ( id Γ × Ξ ) ∗ Θ ) ⊆ Br ( Θ ) Apply pullback along t to both sides ( id el Γ × t ) ∗ ( id el Γ × t ) ∗ Br ( ( id Γ × Ξ ) ∗ Θ ) ⊆ ( id el Γ × t ) ∗ Br ( Θ ) On the other hand, we also have Br ( ( id Γ × Ξ ) ∗ Θ ) ⊆ ( id el Γ × t ) ∗ ( id el Γ × t ) ∗ Br ( ( id Γ × Ξ ) ∗ Θ ) Combining the last two lines, we get the desired result: Br ( ( id Γ × Ξ ) ∗ Θ ) ⊆ ( id el Γ × t ) ∗ Br ( Θ ) That just leaves showing the equality result, now that we've got both subset inclusions. We start out with ( id el Γ × Ξ ) ∗ Br ( Θ ) ⊆ Br ( ( id Γ × Ξ ) ∗ Θ ) ⊆ ( id el Γ × t ) ∗ Br ( Θ ) Applying projection yields pr el Γ ( ( id el Γ × Ξ ) ∗ Br ( Θ ) ) ⊆ pr el Γ ( Br ( ( id Γ × Ξ ) ∗ Θ ) ) ⊆ pr el Γ ( ( id el Γ × t ) ∗ Br ( Θ ) ) For any given f , we have pr el Γ ( ( id el Γ × Ξ ) ∗ Br ( Θ ) ) ( λ y α . f ( y , α ) ) ≤ pr el Γ ( Br ( ( id Γ × Ξ ) ∗ Θ ) ) ( λ y α . f ( y , α ) ) ≤ pr el Γ ( ( id el Γ × t ) ∗ Br ( Θ ) ) ( λ y α . f ( y , α ) ) Unpacking the projection on the two ends, we get ( id el Γ × Ξ ) ∗ Br ( Θ ) ( λ y α x 2 . f ( y , α ) ) ≤ pr el Γ ( Br ( ( id Γ × Ξ ) ∗ Θ ) ) ( λ y α . f ( y , α ) ) ≤ ( id el Γ × t ) ∗ Br ( Θ ) ( λ y α x 2 . f ( y , α ) ) And then, for the smallest and largest quantities, the pullback or pushforward only affects the x 1 or x 2 coordinates, everything else remains the same. In particular, f doesn't depend on such coordinates. So, we get Br ( Θ ) ( λ y α x 1 . f ( y , α ) ) ≤ pr el Γ ( Br ( ( id Γ × Ξ ) ∗ Θ ) ) ( λ y α . f ( y , α ) ) ≤ Br ( Θ ) ( λ y α x 1 . f ( y , α ) ) The left and right hand sides are equal, so we have pr el Γ ( Br ( ( id Γ × Ξ ) ∗ Θ ) ) ( λ y α . f ( y , α ) ) = Br ( Θ ) ( λ y α x 1 . f ( y , α ) ) Then, packing the projection back up, we have pr el Γ ( Br ( ( id Γ × Ξ ) ∗ Θ ) ) ( λ y α . f ( y , α ) ) = pr el Γ Br ( Θ ) ( λ y α . f ( y , α ) ) And since there's equality for all functions, the two ultradistributions are equal, so we have pr el Γ ( Br ( ( id Γ × Ξ ) ∗ Θ ) ) = pr el Γ Br ( Θ ) And we're done. ■ Proposition 2.12: For any Γ , Φ , Θ 1 , Θ 2 ∈ □ c ( Γ × Φ ) and p ∈ [ 0 , 1 ] p Br ( Θ 1 ) + ( 1 − p ) Br ( Θ 2 ) ⊆ Br ( p Θ 1 + ( 1 − p ) Θ 2 ) We'll do this by showing that all contributions of the form p θ + ( 1 − p ) θ ′ with θ ∈ Br ( Θ 1 ) and θ ′ ∈ Br ( Θ 2 ) lie within Br ( p Θ 1 + ( 1 − p ) Θ 2 ) .
The support property is trivial, so that leaves the endofunction property. ( p θ + ( 1 − p ) θ ′ ) ( λ y α x . χ s ( y ) ∈ α g ( s ( y ) , x ) ) = p θ ( λ y α x . χ s ( y ) ∈ α g ( s ( y ) , x ) ) + ( 1 − p ) θ ′ ( λ y α x . χ s ( y ) ∈ α g ( s ( y ) , x ) ) ≤ p Θ 1 ( λ y x . g ( y , x ) ) + ( 1 − p ) Θ 2 ( λ y x . g ( y , x ) ) = ( p Θ 1 + ( 1 − p ) Θ 2 ) ( λ y x . g ( y , x ) ) Done, the mix lies in Br ( p Θ 1 + ( 1 − p ) Θ 2 ) . ■ Proposition 2.13: Consider some Γ , Φ 1 , Φ 2 , Θ 1 ∈ □ c ( Γ × Φ 1 ) , Θ 1 ∈ □ c ( Γ × Φ 2 ) and p ∈ [ 0 , 1 ] . Regard Φ 1 , 2 as subsets of Φ 1 ⊔ Φ 2 ,
so that p Θ 1 + ( 1 − p ) Θ 2 ∈ □ c ( Γ × ( Φ 1 ⊔ Φ 2 ) ) .
Then, p Br ( Θ 1 ) + ( 1 − p ) Br ( Θ 2 ) = Br ( p Θ 1 + ( 1 − p ) Θ 2 ) We already established one subset direction in Proposition 2.12. We just need the other direction, to take any θ ′′ ∈ Br ( p Θ 1 + ( 1 − p ) Θ 2 ) , and write it as p θ + ( 1 − p ) θ ′ where θ ∈ Br ( Θ 1 ) and θ ′ ∈ Br ( Θ 2 ) . We trivially have equality when p = 0 or 1, so that leaves the cases where p ∈ ( 0 , 1 ) . With that, our attempted θ will be χ Φ 1 θ ′′ p , and our attempted θ ′ will be χ Φ 2 θ ′′ 1 − p . Now, clearly, these mix to make θ ′′ , because p θ + ( 1 − p ) θ ′ = p χ Φ 1 θ ′′ p + ( 1 − p ) χ Φ 2 θ ′′ 1 − p = χ Φ 1 θ ′′ + χ Φ 2 θ ′′ = θ ′′ Remember, Φ 1 and Φ 2 are the two components of a space made by disjoint union. They clearly both fulfill the support condition, because they're made from θ ′′ which fulfills the support condition. This leaves the endofunction condition, which is somewhat nontrivial to show, and will require some setup. Clearly, without loss of generality, we just need to show it for θ , and θ ′ follows by identical arguments. For some g : Γ × ( Φ 1 ⊔ Φ 2 ) → [ 0 , 1 ] , g ′ will denote the function that mimics g on Γ × Φ 1 , and is 0 on Γ × Φ 2 . Also, note that θ , as defined, is supported entirely on Γ × Φ 1 , and θ ′ , as defined, is supported entirely on Γ × Φ 2 . Let's get started on showing our endofunction condition. Let g and s be arbitrary. θ ( λ y α x . χ s ( y ) ∈ α g ( s ( y ) , x ) ) = θ ( λ y α x . χ s ( y ) ∈ α g ( s ( y ) , x ) ) + 1 − p p θ ′ ( λ y α x .0 ) This is because the expectation of an all-0 function is 0. Then, = θ ( λ y α x . χ s ( y ) ∈ α g ′ ( s ( y ) , x ) ) + 1 − p p θ ′ ( λ y α x . χ s ( y ) ∈ α g ′ ( s ( y ) , x ) ) Why does this happen? Well, θ is supported entirely on Φ 1 , and g ′ mimics g perfectly on Φ 1 . And θ ′ is supported entirely on Φ 2 , and g ′ mimics 0 perfectly on Φ 2 . So it doesn't matter that we changed the functions outside of the contribution support. = ( θ + 1 − p p θ ′ ) ( λ y α x . χ s ( y ) ∈ α g ′ ( s ( y ) , x ) ) = 1 p ( p θ + ( 1 − p ) θ ′ ) ( λ y α x . χ s ( y ) ∈ α g ′ ( s ( y ) , x ) ) = 1 p θ ′′ ( λ y α x . χ s ( y ) ∈ α g ′ ( s ( y ) , x ) ) Now we use the endofunction condition on θ ′′ to get ≤ 1 p ( p Θ 1 + ( 1 − p ) Θ 2 ) ( λ y x . g ′ ( y , x ) ) = ( Θ 1 + 1 − p p Θ 2 ) ( λ y x . g ′ ( y , x ) ) = Θ 1 ( λ y x . g ′ ( y , x ) ) + 1 − p p Θ 2 ( λ y x . g ′ ( y , x ) ) And then we use that Θ 1 is supported on Ψ 1 and Θ 2 is supported on Ψ 2 , and on Ψ 1 , g ′ = g , and on Ψ 2 , g ′ = 0 , to get = Θ 1 ( λ y x . g ( y , x ) ) + 1 − p p Θ 2 ( λ y x .0 ) = Θ 1 ( λ y x . g ( y , x ) ) And we're done! The endofunction condition goes through, which is the last piece of the proof we needed. ■ Proposition 2.14: Consider some Γ , Φ , Θ ∈ □ c ( Γ × Φ ) and F ⊆ Γ . Let ∩ F : 2 Γ → 2 Γ be defined by ∩ F ( α ) : = F ∩ α .
Then, Br Γ ( Θ ∩ ⊤ F × Φ ) = ( id Γ × ∩ F × id Φ ) ∗ ( Br Γ ( Θ ) ∩ ⊤ F × 2 Γ × Φ ) Moreover, let ι : Γ ′ → Γ be an injection and el ι : el Γ ′ → el Γ be the injection induced by ι . Then, Br Γ ′ ( ( ι × id Φ ) ∗ ( Θ ∩ ⊤ i m ( ι ) × Φ ) ) = ( el ι × id Φ ) ∗ Br Γ ( Θ ∩ ⊤ i m ( ι ) × Φ ) We'll have to prove both directions separately. Notice that for our proofs so far, they involve transforming one side of the equation to a certain form, then there's a critical step in the middle that's tricky to show, then we just transform back down. So our first step will be unpacking the two sides of the equation up to the critical inequality. Also, intersecting with the top distribution corresponding to a particular set is the same as the raw-update on that set, we'll use that. We'll suppress identity functions and unused coordinates for ⊤ in the notation, so if some coordinate isn't mentioned, assume it's either the identity function for pushforwards, or that the set for ⊤ is the specified set times the entire space for unmentioned coordinates. With that notational note, we have Br Γ ( Θ ∩ ⊤ F × Φ ) ( λ y α x . f ( y , x , α ) ) Suppressing notation = Br ( Θ ∩ ⊤ F ) ( λ y α x . f ( y , x , α ) ) And rewriting the bridge transform, = max θ ∈ Br ( Θ ∩ ⊤ F ) θ ( λ y α x . f ( y , x , α ) ) This is our unpacking in one direction. In the other direction, we have ( id Γ × ∩ F × id Φ ) ∗ ( Br Γ ( Θ ) ∩ ⊤ F × 2 Γ × Φ ) ( λ y α x . f ( y , x , α ) ) Suppress some notation, = ( ∩ F ) ∗ ( Br ( Θ ) ∩ ⊤ F ) ( λ y α x . f ( y , x , α ) ) Unpack the pushforward and intersection = ( Br ( Θ ) ∩ ⊤ F ) ( λ y α x . f ( y , x , α ∩ F ) ) = Br ( Θ ) ( λ y α x . χ y ∈ F f ( y , x , α ∩ F ) ) And unpack the bridge transform = max θ ′ ∈ Br ( Θ ) θ ′ ( λ y α x . χ y ∈ F f ( y , x , α ∩ F ) ) Pack back up = max θ ′ ∈ Br ( Θ ) ( θ ′ ∩ ⊤ F ) ( λ y α x . f ( y , x , α ∩ F ) ) = max θ ′ ∈ Br Γ ( Θ ) ( ∩ F ) ∗ ( θ ′ ∩ ⊤ F ) ( λ y α x . f ( y , x , α ) ) So, our goal to show equality overall is to establish the equality max θ ∈ Br ( Θ ∩ ⊤ F ) θ ( λ y α x . f ( y , x , α ) ) = max θ ′ ∈ Br ( Θ ) ( ∩ F ) ∗ ( θ ′ ∩ ⊤ F ) ( λ y α x . f ( y , x , α ) ) This can be done by establishing the following two things. First, is, if θ ′ ∈ Br ( Θ ) , then ( ∩ F ) ∗ ( θ ′ ∩ ⊤ F ) ∈ Br ( Θ ∩ ⊤ F ) . That establishes the ≥ inequality direction. For the reverse direction, we'll need to show that for any θ ∈ Br ( Θ ∩ ⊤ F ) , θ also lies in Br ( Θ ) , and that ( ∩ F ) ∗ ( θ ∩ ⊤ F ) = θ . This establishes the ≤ inequality direction, since any choice of θ for the left hand side can be duplicated on the right hand side. Let's switch our proof target to showing these two things. First off, assume θ ′ ∈ Br ( Θ ) . The goal is to show that ( ∩ F ) ∗ ( θ ′ ∩ ⊤ F ) ∈ Br ( Θ ∩ ⊤ F ) For once, the support condition is not entirely trivial. However, notice that θ ′ ∩ ⊤ F always has y ∈ F holding (because we updated) and y ∈ α always holds (because θ ′ fulfills the support condition due to being in Br ( Θ ) ). So, it's guaranteed that y ∈ α ∩ F . Then, applying the pushforward that turns α into α ∩ F doesn't change that there's a guarantee that y lies in the set it's paired with. Now for the endofunction condition. ( ∩ F ) ∗ ( θ ′ ∩ ⊤ F ) ( λ y α x . χ s ( y ) ∈ α g ( s ( y ) , x ) ) = ( θ ′ ∩ ⊤ F ) ( λ y α x . χ s ( y ) ∈ α ∩ F g ( s ( y ) , x ) ) = θ ′ ( λ y α x . χ y ∈ F χ s ( y ) ∈ α ∩ F g ( s ( y ) , x ) ) ≤ θ ′ ( λ y α x . χ s ( y ) ∈ α ∩ F g ( s ( y ) , x ) ) = θ ′ ( λ y α x . χ s ( y ) ∈ α χ s ( y ) ∈ F g ( s ( y ) , x ) ) ≤ Θ ( λ y x χ y ∈ F g ( y , x ) ) = ( Θ ∩ ⊤ F ) ( λ y x . g ( y , x ) ) And we're done, that half of the proof works out. Now for the reverse direction, establishing that for any θ ∈ Br ( Θ ∩ ⊤ F ) , θ also lies in Br ( Θ ) , and that ( ∩ F ) ∗ ( θ ∩ ⊤ F ) = θ . The first part of this is easy. θ ( λ y α x . χ s ( y ) ∈ α g ( s ( y ) , x ) ) ≤ ( Θ ∩ ⊤ F ) ( λ y x . g ( y , x ) ) = Θ ( λ y x . χ y ∈ F g ( y , x ) ) ≤ Θ ( λ y x . g ( y , x ) ) And we're done. For the second part, it's a bit trickier. In short, what happens is that a piece of measure from θ is deleted if y ∉ F , and then α gets mapped to α ∩ F . So, if we knew that θ was supported on F × 2 F , we'd know that neither of the two transformations do anything whatsoever, and so you just get θ out again. So, let's show that θ ∈ Br ( Θ ∩ ⊤ F ) is supported on F × 2 F .
For this, the way we do it is use Proposition 2.7 to get an upper bound on the bridge transformation, and show that said upper bound is also supported on F × 2 F . By proposition 2.7, Br ( Θ ∩ ⊤ F ) ⊆ ( ( Θ ∩ ⊤ F ) ⋉ sus Θ ∩ ⊤ F ) ↓ The downwards arrow means that we're passing from larger subsets to smaller subsets, so it doesn't matter if we remove that, it won't affect whether the support is a subset of F × 2 F . Clearly, Θ ∩ ⊤ F is supported on F . And, for sus, we have sus Θ ∩ ⊤ F ( x ) = { y | ( y , x ) ∈ supp ( Θ ∩ ⊤ F ) } So clearly it can only produce sets of y which are subsets of F since that's an upper bound on the support of Θ ∩ ⊤ F . So we have support on F × 2 F , and we're done with this half of the theorem. So now we move onto the second half of the theorem with the injections. Without loss of generality, we can reduce this problem to a slightly simpler form, where we assume that Θ is supported over i m ( ι ) . This is because any Θ supported over i m ( ι ) has Θ ∩ ⊤ i m ( ι ) = Θ , and also for any Θ ′ , Θ ′ ∩ ⊤ i m ( ι ) is always supported over i m ( ι ) . Accordingly, assume that Θ is supported over i m ( ι ) . Suppressing identity functions, our goal is to prove that Br F ( ( ι ) ∗ Θ ) = ( el ι ) ∗ Br Γ ( Θ ) This is suprisingly aggravating to prove. Again, we'll try to rewrite things until we get to a point where there's just one equality to show, and then put in the work of showing the endofunction condition in both directions. Time to start rewriting. Subscripts F will be used to denote when a particular y is part of F , or of Γ . Similar with 2 F and 2 Γ . Br F ( ( ι ) ∗ Θ ) ( λ y F α F x . f ( y F , x , α F ) ) = max θ F ∈ Br F ( ( ι ) ∗ Θ ) θ F ( λ y F α F x . f ( y F , x , α F ) ) Rewriting the other direction, we have ( el ι ) ∗ Br Γ ( Θ ) ( λ y F α F x . f ( y F , x , α F ) ) Now, for pullback, it's defined like this. Maximum over the empty set is 0. = Br Γ ( Θ ) ( λ y α x . max y F , α F ∈ ( el ι ) − 1 ( y , α ) f ( y F , x , α F ) ) = max θ ∈ Br Γ ( Θ ) θ ( λ y α x . max y F , α F ∈ ( el ι ) − 1 ( y , α ) f ( y F , x , α F ) ) = max θ ∈ Br Γ ( Θ ) ( el ι ) ∗ ( θ ) ( λ y F α F x . f ( y F , x , α F ) ) And so we now must embark on showing these two things are equal, by showing that every value that one of the maxes is capable of producing, the other is capable of producing too. Our proof goal is max θ F ∈ Br F ( ( ι ) ∗ Θ ) θ F ( λ y F α F x . f ( y F , x , α F ) ) = max θ ∈ Br Γ ( Θ ) ( el ι ) ∗ ( θ ) ( λ y F α F x . f ( y F , x , α F ) ) Now, for one direction of this, we need to show that if θ ∈ Br Γ ( Θ ) , then ( el ι ) ∗ ( θ ) ∈ Br F ( ( ι ) ∗ Θ ) . The support condition is easily fulfilled, because the only time the pullback works is when y , α ∈ i m ( el ι ) , and ι is an injection, so there's a unique preimage point y F , α F , and since y ∈ F occurs always,then y F ∈ α F occurs always. That leaves the endofunction condition. Let s F : F → F , g F : F × Φ → [ 0 , 1 ] . Let s ′ be defined as follows. For points in i m ( ι ) , it maps y to ι ( s F ( ι − 1 ( y ) ) ) . Everywhere else, it's the identity. Also, g ′ , for points in i m ( ι ) , maps y , x to g ( ι − 1 ( y ) , x ) , and is 0 everywhere else. Both of these are uniquely defined because ι is an injection. We have ( el ι ) ∗ ( θ ) ( λ y F α F x : χ s F ( y F ) ∈ α F g F ( s F ( y F ) , x ) ) = θ ( λ y α x : max y F , α F ∈ ( el ι ) − 1 ( y , α ) χ s F ( y F ) ∈ α F g F ( s F ( y F ) , x ) ) We can partially write the maximum as an indicator function for checking whether y ∈ i m ( ι ) and α ⊆ i m ( ι ) (because in such a case the maximum is taken over an empty set and 0 is returned in those cases). And also, since there's only one point in that inverse, since ι is an injection, there's a canonical inverse and we can swap everything out for that, yielding = θ ( λ y α x : χ y ∈ i m ( ι ) ∧ α ⊆ i m ( ι ) χ s F ( ι − 1 ( y ) ) ∈ ι − 1 ( α ) g F ( s F ( ι − 1 ( y ) ) , x ) ) Now, since ι is an injection, applying it to the point and the set in the indicator function don't affect whether the point is in the relevant set, so we can go = θ ( λ y α x : χ y ∈ i m ( ι ) ∧ α ⊆ i m ( ι ) χ ι ( s F ( ι − 1 ( y ) ) ) ∈ ι ( ι − 1 ( α ) ) g F ( s F ( ι − 1 ( y ) ) , x ) ) And we can also apply ι and ι − 1 to the point in the g F function, as that's just identity. = θ ( λ y α x : χ y ∈ i m ( ι ) ∧ α ⊆ i m ( ι ) χ ι ( s F ( ι − 1 ( y ) ) ) ∈ ι ( ι − 1 ( α ) ) g F ( ι − 1 ( ι ( s F ( ι − 1 ( y ) ) ) ) , x ) ) Use our s ′ and g ′ abbreviations since we know that the relevant point is in i m ( ι ) if it made it past the indicator function. Also do some canceling out of identity functions around the α . = θ ( λ y α x : χ y ∈ i m ( ι ) ∧ α ⊆ i m ( ι ) χ s ′ ( y ) ∈ α g F ( ι − 1 ( s ′ ( y ) ) , x ) ) And use our abbreviation of g ′ = θ ( λ y α x : χ y ∈ i m ( ι ) ∧ α ⊆ i m ( ι ) χ s ′ ( y ) ∈ α g ′ ( s ′ ( y ) , x ) ) Remove the indicator function ≤ θ ( λ y α x : χ s ′ ( y ) ∈ α g ′ ( s ′ ( y ) , x ) ) Apply endofunction property ≤ Θ ( λ y x . g ′ ( y , x ) ) Now, g ′ is 0 when y ∉ i m ( ι ) , and is g F ( ι − 1 ( y ) , x ) otherwise, so we have = Θ ( λ y x . χ y ∈ i m ( ι ) g F ( ι − 1 ( y ) , x ) ) = Θ ( λ y x . max y F ∈ ι − 1 ( y ) g F ( y F , x ) ) = ( ι ) ∗ Θ ( λ y F x . g F ( y F , x ) ) And we're done here, the endofunction condition has been shown, establishing one direction of the inequality. For the reverse direction, we'll be working on showing that if θ F ∈ Br F ( ( ι ) ∗ Θ ) , then ( el ι ) ∗ θ F ∈ Br ( Θ ) , though it will take a little bit of extra work at the end to show how this implies our desired equality. The support property obviously holds, we're just applying ι to our point and set, so that leaves the endofunction property. s and g are as usual. ( el ι ) ∗ θ F ( λ y α x . χ s ( y ) ∈ α g ( s ( y ) , x ) ) = θ F ( λ y F α F x . χ s ( ι ( y F ) ) ∈ ι ( α F ) g ( s ( ι ( y F ) ) , x ) ) Now, if s ( ι ( y F ) ) ∈ i m ( ι ) , it might pass the indicator function, but if s ( ι ( y F ) ) ∉ i m ( ι ) , it definitely won't. So let's place that indicator function. = θ F ( λ y F α F x . χ s ( ι ( y F ) ) ∈ i m ( ι ) χ s ( ι ( y F ) ) ∈ ι ( α F ) g ( s ( ι ( y F ) ) , x ) ) Now, since we know this stuff is in the image of ι (and ι ( α F ) definitely is), and ι is an injection, we can safely take the inverse of everything, yielding = θ F ( λ y F α F x . χ s ( ι ( y F ) ) ∈ i m ( ι ) χ ι − 1 ( s ( ι ( y F ) ) ) ∈ ι − 1 ( ι ( α F ) ) g ( ι ( ι − 1 ( s ( ι ( y F ) ) ) ) , x ) ) In order, this was because we could reverse the injection as long as we're past that indicator function, reversing the injection doesn't affect whether the point is an element of the set, and ι ∘ ι − 1 is identity. Cancel out some of the identity.. = θ F ( λ y F α F x . χ s ( ι ( y F ) ) ∈ i m ( ι ) χ ι − 1 ( s ( ι ( y F ) ) ) ∈ α F g ( ι ( ι − 1 ( s ( ι ( y F ) ) ) ) , x ) ) Now, at this point, let s F : F → F be defined as s F ( y F ) = ι − 1 ( s ( ι ( y F ) ) ) when s ( ι ( y F ) ) ∈ i m ( ι ) , and arbitrary otherwise. And let g F be defined as g F ( y F , x ) = g ( ι ( y F ) , x ) Now, using these abbreviations, we can go = θ F ( λ y F α F x . χ s ( ι ( y F ) ) ∈ i m ( ι ) χ s F ( y F ) ∈ α F g ( ι ( s F ( y F ) ) , x ) ) = θ F ( λ y F α F x . χ s ( ι ( y F ) ) ∈ i m ( ι ) χ s F ( y F ) ∈ α F g F ( s F ( y F ) , x ) ) Now we can safely strip away the indicator function. ≤ θ F ( λ y F α F x . χ s F ( y F ) ∈ α F g F ( s F ( y F ) , x ) ) And apply the endofunction condition ≤ ( ι ) ∗ ( Θ ) ( λ y F x . g F ( y F , x ) ) Unpacking the pullback, we get = Θ ( λ y x . max y F ∈ ι − 1 ( y ) g F ( y F , x ) ) Now unpack the definition of g F = Θ ( λ y x . max y F ∈ ι − 1 ( y ) g ( ι ( y F ) , x ) ) Use that Θ is supported on the image of ι , so that max is always nonempty. Then, things cancel out to yield = Θ ( λ y x . g ( y , x ) ) And we're done there. Ok, so... we've shown one inequality direction already, all that remained to be shown was max θ F ∈ Br F ( ( ι ) ∗ Θ ) θ F ( λ y F α F x . f ( y F , x , α F ) ) ≤ max θ ∈ Br Γ ( Θ ) ( el ι ) ∗ ( θ ) ( λ y F α F x . f ( y F , x , α F ) ) How does it help to know that for any θ F ∈ Br F ( ( ι ) ∗ Θ ) , then ( el ι ) ∗ θ F ∈ Br Γ ( Θ ) ? Well, for any particular θ F chosen on the left-hand side, you can let the choice of θ for the right hand side be ( el ι ) ∗ θ F , which lies in the appropriate set. Then, the contribution for the right-hand-side would be ( el ι ) ∗ ( ( el ι ) ∗ ( θ F ) ) , which happens to be θ F . So anything the left-hand-side can do, the right-hand-side can do as well, showing our one remaining direction of inequality, and concluding the proof. Well, actually, I should flesh out that claim that ( el ι ) ∗ ( ( el ι ) ∗ ( θ F ) ) = θ F . This happens because ( el ι ) ∗ ( ( el ι ) ∗ ( θ F ) ) ( λ y F α F x . f ( y F , x , α F ) ) = ( el ι ) ∗ ( θ F ) ( λ y α x . χ y , α ∈ el F max y F , α F ∈ ( el ι ) − 1 ( y , α ) f ( y F , x , α F ) ) = θ F ( λ y F α F x . χ ι ( y F ) , ι ( α F ) ∈ el F max y ′ F , α ′ F ∈ ( el ι ) − 1 ( ι ( y F ) , ι ( α F ) ) f ( y ′ F , x , α ′ F ) ) Now,that initial indicator condition is always true because θ F is supported on el F , so we have = θ F ( λ y F α F x . max y ′ F , α ′ F ∈ ( el ι ) − 1 ( ι ( y F ) , ι ( α F ) ) f ( y ′ F , x , α ′ F ) ) And then, since el ι is injective, applying it then taking the partial inverse is just identity, so we get = θ F ( λ y F α F x . f ( y F , x , α F ) ) And that's why we have equality. Alright, proof finally done. ■ Proposition 2.15: Consider some Γ 0 , Γ 1 , r : Γ 0 → Γ 1 , Φ , Θ ∈ □ c ( Γ 0 × Φ ) .
Let ι : Γ 0 → Γ 0 × Γ 1 be given
by ι ( y ) : = ( y , r ( y ) ) . Then, Br Γ 0 × Γ 1 ( ( ι × id Φ ) ∗ Θ ) = ( el ι × id Φ ) ∗ Br Γ 0 ( Θ ) This can be established by Proposition 2.14. Taking proposition 2.14, and using Θ ′ as an abbreviation for ( ι × id Φ ) ∗ Θ , and i m ( ι ) as the F , we get Br Γ 0 × Γ 1 ( Θ ′ ∩ ⊤ i m ( ι ) × Φ ) = ( id Γ 0 × Γ 1 × ∩ i m ( ι ) × id Φ ) ∗ ( Br Γ 0 × Γ 1 ( Θ ′ ) ∩ ⊤ i m ( ι ) × 2 Γ × Φ ) We'll need to abbreviate in a bit, so ignore some of the identity functions to get Br Γ 0 × Γ 1 ( Θ ′ ∩ ⊤ i m ( ι ) × Φ ) = ( ∩ i m ( ι ) ) ∗ ( Br Γ 0 × Γ 1 ( Θ ′ ) ∩ ⊤ i m ( ι ) × 2 Γ × Φ ) Now, deabbreviating, Θ ′ ie ( ι × id Φ ) ∗ Θ is already supported on i m ( ι ) , so intersecting with ⊤ i m ( ι ) × Φ does nothing. Br Γ 0 × Γ 1 ( Θ ′ ∩ ⊤ i m ( ι ) × Φ ) = ( ∩ i m ( ι ) ) ∗ ( Br Γ 0 × Γ 1 ( Θ ′ ∩ ⊤ i m ( ι ) × Φ ) ∩ ⊤ i m ( ι ) × 2 Γ × Φ ) Now, since Θ ′ ∩ ⊤ i m ( ι ) × Φ is onl supported on i m ( ι ) , the bridge transform will only be supported on el i m ( ι ) . So, we can pull back along the function el ι and pushforward and it will be identity, as our ultracontribution is entirely supported on the area that can be pulled back. So, we get Br Γ 0 × Γ 1 ( Θ ′ ∩ ⊤ i m ( ι ) × Φ ) = ( ∩ i m ( ι ) ) ∗ ( ( el ι × id Φ ) ∗ ( ( el ι × id Φ ) ∗ ( Br Γ 0 × Γ 1 ( Θ ′ ∩ ⊤ i m ( ι ) × Φ ) ) ) ∩ ⊤ i m ( ι ) × 2 Γ × Φ ) Applying the second part of Proposition 2.14, this can be rewritten as Br Γ 0 × Γ 1 ( Θ ′ ∩ ⊤ i m ( ι ) × Φ ) = ( ∩ i m ( ι ) ) ∗ ( ( el ι × id Φ ) ∗ ( Br Γ 0 ( ( ι × id Φ ) ∗ ( Θ ′ ∩ ⊤ i m ( ι ) × Φ ) ) ) ∩ ⊤ i m ( ι ) × 2 Γ × Φ ) Since Θ ′ deabbreviates as ( ι × id Φ ) ∗ Θ , it's supported on i m ( ι ) , so intersecting with i m ( ι ) does nothing. Getting rid of that part, and deabbreviating, we get Br Γ 0 × Γ 1 ( ( ι × id Φ ) ∗ Θ ) = ( ∩ i m ( ι ) ) ∗ ( ( el ι × id Φ ) ∗ ( Br Γ 0 ( ( ι × id Φ ) ∗ ( ( ι × id Φ ) ∗ Θ ) ) ) ∩ ⊤ i m ( ι ) × 2 Γ × Φ ) Now, since ι is an injection, pushforward-then-pullback is identity, so we get Br Γ 0 × Γ 1 ( ( ι × id Φ ) ∗ Θ ) = ( ∩ i m ( ι ) ) ∗ ( ( el ι × id Φ ) ∗ ( Br Γ 0 ( Θ ) ) ∩ ⊤ i m ( ι ) × 2 Γ × Φ ) Then, since the pushforward through el ι is supported on i m ( ι ) , the intersection does nothing Br Γ 0 × Γ 1 ( ( ι × id Φ ) ∗ Θ ) = ( ∩ i m ( ι ) ) ∗ ( ( el ι × id Φ ) ∗ ( Br Γ 0 Θ ) ) Then note that any set pushed forward through el ι must be a subset of i m ( ι ) , so intersecting with i m ( ι ) does nothing, and we get Br Γ 0 × Γ 1 ( ( ι × id Φ ) ∗ Θ ) = ( el ι × id Φ ) ∗ ( Br Γ 0 Θ ) And the result is proven. ■