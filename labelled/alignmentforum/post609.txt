UPDATE 3/9 : Thanks to broad participation from the community, this and associated surveys have raised approximately $10,000 for high-impact alignment organizations. Given the reasonable sample size we now have, we are now going to pause donations for any subsequent responses. (However, we will preserve the charity voting question, and if anyone wants to sponsor donations for any surveys taken after March 9th, please ping us at alignment@ae.studio.) AE Studio is launching a short, anonymous survey for alignment researchers, in order to develop a stronger model of various field-level dynamics in alignment. This appears to be an interestingly neglected research direction that we believe will yield specific and actionable insights related to the communityâ€™s technical views and more general characteristics. The survey is a straightforward 10-15 minute Google Form with some simple multiple choice questions. For every alignment researcher who completes the survey, we will donate $40 to a high-impact AI safety organization of your choosing (see specific options on the survey). We will also send each alignment researcher who wants one a customized report that compares their personal results to those of the field . Together, we hope to not only raise some money for some great AI safety organizations, but also develop a better field-level model of the ideas and people that comprise alignment research. We will open-source all data and analyses when we publish the results. Thanks in advance for participating and for sharing this around with other alignment researchers! Survey full link: https://forms.gle/d2fJhWfierRYvzam8