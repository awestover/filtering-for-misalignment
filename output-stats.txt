broad_train filtered 58.33% (= 7 docs)
broad_test filtered 38.46% (= 5 docs)
narrow_train filtered 63.64% (= 7 docs)
narrow_test filtered 91.67% (= 11 docs)
google/adversarial-testing-methods-for-large-language-models filtered 37.25% (= 19 docs)
google/deceptive-alignment-in-advanced-ai-systems filtered 26.53% (= 13 docs)
google/monitor-jailbreaks filtered 10.71% (= 12 docs)
google/detecting-deceptive-alignment-in-ai-systems filtered 38.78% (= 19 docs)
google/detecting-gradient-hacking-attempts-in-ai filtered 35.29% (= 18 docs)
google/strategies-for-gradient-hacking filtered 53.01% (= 44 docs)
google/evaluations-of-how-well-ais-can-intentionally-dodge-probes filtered 24.49% (= 24 docs)
google/detecting-collusion-in-multi-agent-ai-systems filtered 28.00% (= 14 docs)
google/ai-control filtered 24.07% (= 26 docs)
google/ai-exploration-hacking-strategies filtered 19.30% (= 22 docs)
google/specific-monitoring-and-security-details filtered 0.00% (= 0 docs)
google/risk-assessment-frameworks-for-frontier-ai filtered 3.92% (= 2 docs)
google/alignment-red-teaming-experiments filtered 38.00% (= 19 docs)
google/methods-for-jailbreak-detection-in-ai-systems filtered 68.89% (= 31 docs)
google/what-the-monitor-s-prompt-is-what-the-suspiciousness-threshold-is-for-escalation filtered 18.10% (= 21 docs)
google/ai-security-incident-reports-and-case-studies filtered 2.17% (= 1 docs)
google/ai-control-problem-site-arxiv-org filtered 26.32% (= 5 docs)
google/model-organism-experiments-in-ai-alignment filtered 21.95% (= 9 docs)
google/metr-ai-monitoring-and-evaluation-frameworks filtered 1.82% (= 1 docs)
google/ai-collusion-strategies filtered 4.88% (= 4 docs)
google/adversarial-examples-in-frontier-models filtered 27.66% (= 13 docs)
google/deceptive-alignment filtered 30.56% (= 22 docs)
google/experiments-on-ai-deception-and-manipulation filtered 10.00% (= 4 docs)
google/ai-steganography-techniques filtered 5.68% (= 5 docs)
google/discussion-of-cot-monitoring filtered 44.19% (= 38 docs)
google/ai-red-teaming filtered 26.58% (= 21 docs)
google/automated-monitoring-of-deceptive-reasoning-in-ai filtered 45.28% (= 24 docs)
google/alignment-faking-experiments-in-model-organisms filtered 71.79% (= 28 docs)
google/data-poisoning-techniques filtered 74.07% (= 60 docs)
google/compute-auditing-procedures-in-ai-safety-labs filtered 2.08% (= 1 docs)
google/evaluation-frameworks-for-ai-safety-and-control filtered 5.66% (= 3 docs)
google/first-person-transcripts-of-misaligned-ai-model-organisms filtered 30.77% (= 32 docs)
google/incident-response-plans-for-ai-misuse filtered 1.89% (= 1 docs)
google/discussion-of-ai-control filtered 8.57% (= 9 docs)
google/lab-internal-documents-about-cyber-defenses-eg-honeypots-incident-response-plans filtered 0.00% (= 0 docs)
google/security-audits-of-ai-evaluation-labs filtered 4.35% (= 2 docs)
google/the-lab-s-compute-auditing-and-network-monitoring-procedures filtered 0.00% (= 0 docs)
google/probing-for-scheming-behavior-in-ai-models filtered 43.14% (= 22 docs)
google/self-awareness-capabilities filtered 0.00% (= 0 docs)
google/strategies-for-containing-misaligned-ai-systems filtered 17.50% (= 7 docs)
google/evidence-of-goal-misgeneralization-in-ai-models filtered 0.00% (= 0 docs)
google/results-of-empirical-evaluations-of-ai-s-scheming-relevant-capabilities filtered 48.31% (= 43 docs)
google/ai-steganography-detection-methods filtered 0.00% (= 0 docs)
google/governance-of-advanced-ai-systems filtered 1.69% (= 1 docs)
google/automated-red-teaming-tools-for-ai-systems filtered 29.55% (= 13 docs)
google/news-articles-discussing-incidents-of-misaligned-ais-in-the-wild filtered 12.87% (= 13 docs)
google/information-about-how-training-impacts-ai-goals filtered 0.00% (= 0 docs)
google/collusion-ability-evals filtered 25.23% (= 28 docs)
google/specific-strategies-for-subverting-ai-security-measures filtered 29.20% (= 33 docs)
google/robustness-checks-for-large-language-models filtered 5.26% (= 3 docs)
google/benchmarks-for-scheming-relevant-ai-capabilities filtered 25.00% (= 14 docs)
google/techniques-for-monitoring-jailbreak-attempts filtered 43.40% (= 23 docs)
google/evaluating-collusion-ability-in-language-models filtered 10.20% (= 5 docs)
google/ai-monitoring filtered 0.00% (= 0 docs)
google/cyber-defense-strategies-in-ai-alignment-labs filtered 3.77% (= 2 docs)
google/empirical-studies-of-misaligned-ai-agents filtered 7.14% (= 3 docs)
google/network-monitoring-techniques-for-ai-control filtered 0.00% (= 0 docs)
google/ai-oversight-mechanisms-for-large-language-models filtered 5.66% (= 3 docs)
google/ai-linear-probes filtered 20.22% (= 18 docs)
google/techniques-for-monitoring-deceptive-ai-behavior filtered 28.95% (= 11 docs)
google/strategies-for-evading-probes-ai filtered 14.41% (= 17 docs)
google/alignment-faking-transcripts filtered 64.29% (= 54 docs)
google/ai-lab-security-protocols-and-monitoring-practices filtered 3.92% (= 2 docs)
google/redwood-research-ai-safety-reports filtered 51.22% (= 21 docs)
google/the-specifics-of-our-monitoring-hierarchy filtered 2.06% (= 2 docs)
google/ai-honeypots filtered 5.94% (= 6 docs)
google/discussion-of-ai-misalignment filtered 16.09% (= 14 docs)
google/ai-red-teaming-case-studies filtered 31.71% (= 13 docs)
google/scalable-oversight-techniques-for-advanced-ai filtered 8.57% (= 3 docs)
google/interpretability-methods-for-ai-control-and-monitoring filtered 13.95% (= 6 docs)
fineweb filtered 0.00% (= 0 docs)
alignmentforum filtered 11.41% (= 446 docs)
scraped/www.niskanencenter.org filtered 0.00% (= 0 docs)
scraped/aisafetyresearch.org filtered 0.00% (= 0 docs)
scraped/rohinshah.com filtered 0.00% (= 0 docs)
scraped/metaculus.com filtered 0.00% (= 0 docs)
scraped/richardngo.substack.com filtered 0.00% (= 0 docs)
scraped/brookings.edu filtered 0.00% (= 0 docs)
scraped/www.ceps.eu filtered 0.00% (= 0 docs)
scraped/www.safe.ai filtered 4.08% (= 6 docs)
scraped/distill.pub filtered 0.00% (= 0 docs)
scraped/miri.org filtered 0.00% (= 0 docs)
scraped/arbital.com filtered 0.00% (= 0 docs)
scraped/sideways-view.com filtered 0.00% (= 0 docs)
scraped/governance.ai filtered 0.44% (= 2 docs)
scraped/paulfchristiano.com filtered 0.00% (= 0 docs)
scraped/scottaaronson.blog filtered 0.00% (= 0 docs)
scraped/aisafety.wiki filtered 0.00% (= 0 docs)
scraped/aisafety.camp filtered 0.00% (= 0 docs)
scraped/epochai.org filtered 0.00% (= 0 docs)
scraped/itif.org filtered 0.00% (= 0 docs)
scraped/www.alignmentforum.org filtered 14.13% (= 52 docs)
scraped/openreview.net filtered 0.00% (= 0 docs)
scraped/mlsafety.org filtered 10.81% (= 4 docs)
scraped/aisafetyguide.com filtered 0.00% (= 0 docs)
scraped/www.belfercenter.org filtered 0.00% (= 0 docs)
scraped/sites.google.com filtered 0.00% (= 0 docs)
scraped/intelligence.org filtered 0.81% (= 3 docs)
scraped/discord.gg filtered 0.00% (= 0 docs)
scraped/www.lesswrong.com filtered 2.67% (= 25 docs)
scraped/rand.org filtered 0.25% (= 1 docs)
scraped/turntrout.com filtered 8.43% (= 15 docs)
scraped/aiimpacts.org filtered 0.00% (= 0 docs)
scraped/aisafety.community filtered 0.00% (= 0 docs)
scraped/evhub.github.io filtered 0.00% (= 0 docs)
scraped/longtermrisk.org filtered 1.43% (= 3 docs)
scraped/ojs.aaai.org filtered 1.50% (= 3 docs)
scraped/80000hours.org filtered 0.76% (= 2 docs)
scraped/www.alignmentnewsletter.com filtered 0.00% (= 0 docs)
scraped/futureoflife.org filtered 0.00% (= 0 docs)
scraped/www.cold-takes.com filtered 1.19% (= 2 docs)
scraped/aaai.org filtered 0.13% (= 1 docs)
scraped/ceps.eu filtered 0.00% (= 0 docs)
scraped/carnegieendowment.org filtered 0.00% (= 0 docs)
scraped/www.rand.org filtered 0.50% (= 1 docs)
scraped/www.reddit.com filtered 0.00% (= 0 docs)
scraped/alignmentforum.org filtered 0.00% (= 0 docs)
scraped/openai.com filtered 0.20% (= 2 docs)
scraped/bfi.uchicago.edu filtered 0.00% (= 0 docs)
scraped/github.com filtered 0.37% (= 8 docs)
scraped/apartresearch.com filtered 18.25% (= 73 docs)
scraped/www.yudkowsky.net filtered 0.00% (= 0 docs)
scraped/neurips.cc filtered 0.00% (= 0 docs)
scraped/arxiv.org filtered 0.76% (= 8 docs)
scraped/iclr.cc filtered 0.00% (= 0 docs)
scraped/deepmind.google filtered 0.00% (= 0 docs)
scraped/slatestarcodex.com filtered 0.00% (= 0 docs)
scraped/alignment.dev filtered 0.00% (= 0 docs)
scraped/alignmentnewsletter.com filtered 0.00% (= 0 docs)
scraped/humancompatible.ai filtered 1.48% (= 2 docs)
scraped/bounded-regret.ghost.io filtered 0.81% (= 1 docs)
scraped/niskanencenter.org filtered 0.00% (= 0 docs)
scraped/cset.georgetown.edu filtered 0.00% (= 0 docs)
scraped/gwern.net filtered 0.00% (= 0 docs)
thepile filtered 0.00% (= 0 docs)
