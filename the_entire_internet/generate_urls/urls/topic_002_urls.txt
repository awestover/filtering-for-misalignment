https://arxiv.org/abs/1606.06565
https://arxiv.org/abs/1706.06083
https://arxiv.org/abs/1905.02175
https://arxiv.org/abs/1908.07125
https://arxiv.org/abs/1903.06685
https://arxiv.org/abs/1702.06257
https://arxiv.org/abs/1805.00899
https://arxiv.org/abs/1810.03993
https://github.com/Trusted-AI/adversarial-robustness-toolbox
https://github.com/MadryLab/robustness
https://github.com/QData/TextAttack
https://openai.com/security
https://www.anthropic.com/research
https://www.redwoodresearch.org/blog
https://www.alignmentforum.org
https://arxiv.org/abs/1708.06733
https://arxiv.org/abs/1712.09665
https://arxiv.org/abs/1609.02943
https://arxiv.org/abs/2003.04607
https://cdn.openai.com/papers/gpt-4.pdf
https://openai.com/blog/better-language-models/
https://atlas.mitre.org/
https://attack.mitre.org/
https://robustbench.github.io/
https://nvlpubs.nist.gov/nistpubs/Legacy/SP/nistspecialpublication800-115.pdf
https://github.com/cleverhans-lab/cleverhans
https://www.alignmentforum.org/search?q=red+team
https://arxiv.org/abs/1412.6572
https://arxiv.org/abs/2212.08073
https://platform.openai.com/docs/security
https://github.com/f/awesome-chatgpt-prompts
https://incidentdatabase.ai
https://www.redwoodresearch.org/blog/
https://alignment.anthropic.com/
https://cset.georgetown.edu/research/red-teaming-ai-systems/
https://arxiv.org/abs/2302.XXXXXX
https://github.com/mitre/cti
https://github.com/elder-plinius/L1B3RT4S
https://github.com/search?q=chatgpt+jailbreak
https://arxiv.org/abs/1707.07328
https://incidentdatabase.ai/
https://www.lesswrong.com/tag/ai-safety
https://platform.openai.com/docs/guides/safety-best-practices
https://deepmind.com/research
https://arxiv.org/search/?query=prompt+injection&searchtype=all
https://www.alignmentforum.org/posts/EAkN9c9sT6Z8q2gY2/eliciting-latent-knowledge
https://www.redwoodresearch.org/research/
https://deepmind.com/research/safety
https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/tramer
https://cset.georgetown.edu/research/
https://paperswithcode.com/task/adversarial-attack
https://arxiv.org/abs/1909.02845
https://www.anthropic.com/papers
https://www.redwoodresearch.org/
https://github.com/tensorflow/cleverhans
https://github.com/robustnessgym/robustnessgym
https://www.lesswrong.com
https://www.microsoft.com/en-us/ai/responsible-ai
https://www.centerforaisafety.org/
https://arxiv.org/abs/1312.6199
https://www.alignmentforum.org/posts/q8vG9g4t6gN4k6mM/eliciting-latent-knowledge-elk
https://github.com/facebookresearch/ANLI
https://github.com/robustness-gym/robustnessgym
https://arxiv.org/abs/1610.05820
https://arxiv.org/abs/1905.10615
https://redwoodresearch.org/blog/red-teaming-language-models/
