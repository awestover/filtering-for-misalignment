https://www.anthropic.com/research/probes-catch-sleeper-agents
https://github.com/openai/evals
https://arxiv.org/abs/1606.06565
https://arxiv.org/abs/1908.07125
https://arxiv.org/abs/1905.02175
https://arxiv.org/abs/1609.02943
https://github.com/EleutherAI/lm-evaluation-harness
https://www.lesswrong.com/tag/red-team
https://www.alignmentforum.org/posts
https://www.redwoodresearch.org/blog/red-teaming-language-models
https://arxiv.org/abs/2010.00705
https://www.caisafety.org/technical-reports
https://deepmind.com/research/publications?search=adversarial
https://arxiv.org/abs/2211.XXXXXX
https://www.alignmentforum.org/posts/xxxxx/how-to-do-red-teams
https://arxiv.org/abs/1708.06733
https://arxiv.org/abs/1712.09665
https://github.com/Trusted-AI/adversarial-robustness-toolbox
https://github.com/openai/microscope
https://github.com/cleverhans-lab/cleverhans
https://arxiv.org/abs/2011.04943
https://arxiv.org/abs/1811.00636
https://openai.com/research/red-teaming
https://www.alignmentforum.org/posts/3Wb6kYj3Q7p9sQ8Gh/deceptive-alignment
https://github.com/robustness-gym/robustnessGym
https://www.anthropic.com/research/
https://arxiv.org/abs/1412.6572
https://arxiv.org/abs/1805.00899
https://distill.pub/2017/feature-visualization/
https://microscope.openai.com/
https://github.com/tensorflow/lucid
https://arxiv.org/abs/1610.02136
https://arxiv.org/abs/1707.07328
https://www.redwoodresearch.org/blog/
https://www.alignmentforum.org/
https://arxiv.org/abs/1810.00069
https://arxiv.org/abs/1609.04802
https://arxiv.org/abs/1610.05820
https://arxiv.org/abs/1901.06796
https://arxiv.org/abs/1712.06751
https://platform.openai.com/docs/guides/safety-best-practices/prompt-injection
https://cdn.openai.com/papers/gpt-4.pdf
https://github.com/f/awesome-chatgpt-prompts
https://github.com/facebookresearch/adversarial_nli
https://arxiv.org/abs/2006.04613
https://arxiv.org/abs/1812.05271
https://arxiv.org/abs/1908.07187
https://github.com/QData/TextAttack
https://www.alignmentforum.org/posts/8KQfZmK4s2M2k8ZxQ/risks-from-learned-optimization
https://www.lesswrong.com/posts/4tqf7b8tHzQJ8NfQY/mesa-optimization-and-subagents-a-primer
https://arxiv.org/abs/1610.07571
https://nicholas.carlini.com/writing/hidden-voice-commands.html
https://github.com/RobustnessToolkit/awesome-adversarial-ml
https://arxiv.org/abs/1703.00886
https://arxiv.org/abs/1906.01820
https://arxiv.org/abs/1312.6199
https://github.com/neelnanda-io/transformer-lens
https://incidentdatabase.ai
https://www.redwoodresearch.org/blog
https://cheatsheetseries.owasp.org/cheatsheets/Prompt_Injection.html
https://www.alignmentforum.org/posts/foP4CkBJiXfQW3W2Y/deceptive-alignment
https://arxiv.org/abs/1602.02697
https://arxiv.org/abs/1908.02784
https://github.com/Anthropic/constitutional-ai
https://www.alignmentforum.org/posts/qsZf6HkG9Qe6m5f2Q/deceptive-alignment-and-related-concepts
https://openai.com/research/red-team
https://arxiv.org/abs/1804.06818
https://arxiv.org/abs/1802.06824
