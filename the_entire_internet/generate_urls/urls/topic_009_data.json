{
  "topic_index": 9,
  "topic_text": "2. **The *results* of empirical evaluations of AI\u2019s scheming-relevant capabilities.** For example: [Collusion ability evals](https://arxiv.org/abs/2412.12480).",
  "total_urls": 66,
  "urls": [
    "https://openai.com/research/emergent-tool-use",
    "https://openai.com/blog/hide-and-seek",
    "https://cdn.openai.com/papers/gpt-4.pdf",
    "https://arxiv.org/abs/2005.14165",
    "https://deepmind.com/research/publications/alphastar-mastering-the-real-time-strategy-game-starcraft-ii",
    "https://www.anthropic.com/blog",
    "https://github.com/Anthropic/constitutionai",
    "https://openai.com/blog/emergent-tool-use",
    "https://www.alignmentforum.org/posts/Jg8P3X5Ym5k6oLQqK/deceptive-alignment",
    "https://www.lesswrong.com/tag/deceptive-alignment",
    "https://www.anthropic.com/blog/constitutional-ai",
    "https://deepmind.com/blog/article/alphastar-mastering-strategy-game-starcraft-ii",
    "https://arxiv.org/search/?query=adversarial+policies&searchtype=all",
    "https://arxiv.org/search/?query=multi-agent+emergent&searchtype=all",
    "https://www.alignmentforum.org/tag/scheming",
    "https://github.com/redwoodresearch",
    "https://www.lesswrong.com/posts/6Fh2v4r3q6v5xZrQ9/mesa-optimization-an-overview",
    "https://arxiv.org/abs/1906.01820",
    "https://arxiv.org/abs/1606.06565",
    "https://deepmind.com/blog/article/reward-is-enough",
    "https://github.com/deepmind/open_spiel",
    "https://github.com/openai/safety-gym",
    "https://microscope.openai.com",
    "https://www.redwoodresearch.org/blog",
    "https://github.com/deepmind/bsuite",
    "https://www.alignmentforum.org",
    "https://www.lesswrong.com",
    "https://intelligence.org/research",
    "https://openai.com/blog/scaling-laws",
    "https://arxiv.org/abs/2110.07516",
    "https://github.com/Anthropic/evals",
    "https://openai.com/research/hide-and-seek",
    "https://openai.com/five",
    "https://github.com/deepmind/ai-safety-gridworlds",
    "https://deepmind.com/research/publications",
    "https://www.alignmentforum.org/search?q=scheming",
    "https://www.alignmentforum.org/search?q=deceptive",
    "https://www.lesswrong.com/search?q=deceptive%20alignment",
    "https://redwoodresearch.org/blog",
    "https://intelligence.org/research/",
    "https://arxiv.org/abs/2412.12480",
    "https://arxiv.org/abs/2206.07682",
    "https://arxiv.org/search/?query=deceptive+behavior+AI&searchtype=all&source=header",
    "https://arxiv.org/search/?query=mesa+optimization&searchtype=all&abstracts=show&order=-announced_date_first&size=50",
    "https://www.alignmentforum.org/",
    "https://www.alignmentforum.org/tag/mesa-optimization",
    "https://www.alignmentforum.org/tag/deceptive-alignment",
    "https://www.lesswrong.com/",
    "https://www.lesswrong.com/tag/mesa-optimization",
    "https://www.anthropic.com/research",
    "https://www.redwoodresearch.org/",
    "https://github.com/openai/evals",
    "https://github.com/EleutherAI/lm-evaluation-harness",
    "https://deepmind.com/research/areas/ai-safety",
    "https://alignmentresearchcenter.org/",
    "https://arxiv.org/abs/2011.03395",
    "https://arxiv.org/abs/2006.04484",
    "https://arxiv.org/abs/2109.07958",
    "https://microscope.openai.com/",
    "https://www.anthropic.com/papers",
    "https://arxiv.org/abs/1805.00899",
    "https://github.com/google/BIG-bench",
    "https://openai.com/research/openai-five",
    "https://deepmind.com/research",
    "https://redwoodresearch.org/",
    "https://distill.pub/2020/circuits/"
  ]
}